diff --git a/rl-starter-files/.DS_Store b/rl-starter-files/.DS_Store
deleted file mode 100644
index f967011..0000000
Binary files a/rl-starter-files/.DS_Store and /dev/null differ
diff --git a/rl-starter-files/Minigrid/minigrid/__init__.py b/rl-starter-files/Minigrid/minigrid/__init__.py
deleted file mode 100644
index de0044e..0000000
--- a/rl-starter-files/Minigrid/minigrid/__init__.py
+++ /dev/null
@@ -1,1136 +0,0 @@
-from __future__ import annotations
-
-from gymnasium.envs.registration import register
-
-from minigrid import minigrid_env, wrappers
-from minigrid.core import roomgrid
-from minigrid.core.world_object import Wall
-
-__version__ = "2.3.0"
-
-
-try:
-    import sys
-
-    from farama_notifications import notifications
-
-    if "minigrid" in notifications and __version__ in notifications["minigrid"]:
-        print(notifications["minigrid"][__version__], file=sys.stderr)
-except Exception:  # nosec
-    pass
-
-
-def register_minigrid_envs():
-    # BlockedUnlockPickup
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-BlockedUnlockPickup-v0",
-        entry_point="minigrid.envs:BlockedUnlockPickupEnv",
-    )
-
-    # LavaCrossing
-    # ----------------------------------------
-    register(
-        id="MiniGrid-LavaCrossingS9N1-v0",
-        entry_point="minigrid.envs:CrossingEnv",
-        kwargs={"size": 9, "num_crossings": 1},
-    )
-
-    register(
-        id="MiniGrid-LavaCrossingS9N2-v0",
-        entry_point="minigrid.envs:CrossingEnv",
-        kwargs={"size": 9, "num_crossings": 2},
-    )
-
-    register(
-        id="MiniGrid-LavaCrossingS9N3-v0",
-        entry_point="minigrid.envs:CrossingEnv",
-        kwargs={"size": 9, "num_crossings": 3},
-    )
-
-    register(
-        id="MiniGrid-LavaCrossingS11N5-v0",
-        entry_point="minigrid.envs:CrossingEnv",
-        kwargs={"size": 11, "num_crossings": 5},
-    )
-
-    # SimpleCrossing
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-SimpleCrossingS9N1-v0",
-        entry_point="minigrid.envs:CrossingEnv",
-        kwargs={"size": 9, "num_crossings": 1, "obstacle_type": Wall},
-    )
-
-    register(
-        id="MiniGrid-SimpleCrossingS9N2-v0",
-        entry_point="minigrid.envs:CrossingEnv",
-        kwargs={"size": 9, "num_crossings": 2, "obstacle_type": Wall},
-    )
-
-    register(
-        id="MiniGrid-SimpleCrossingS9N3-v0",
-        entry_point="minigrid.envs:CrossingEnv",
-        kwargs={"size": 9, "num_crossings": 3, "obstacle_type": Wall},
-    )
-
-    register(
-        id="MiniGrid-SimpleCrossingS11N5-v0",
-        entry_point="minigrid.envs:CrossingEnv",
-        kwargs={"size": 11, "num_crossings": 5, "obstacle_type": Wall},
-    )
-
-    # DistShift
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-DistShift1-v0",
-        entry_point="minigrid.envs:DistShiftEnv",
-        kwargs={"strip2_row": 2},
-    )
-
-    register(
-        id="MiniGrid-DistShift2-v0",
-        entry_point="minigrid.envs:DistShiftEnv",
-        kwargs={"strip2_row": 5},
-    )
-
-    # DoorKey
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-DoorKey-5x5-v0",
-        entry_point="minigrid.envs:DoorKeyEnv",
-        kwargs={"size": 5},
-    )
-
-    register(
-        id="MiniGrid-DoorKey-6x6-v0",
-        entry_point="minigrid.envs:DoorKeyEnv",
-        kwargs={"size": 6},
-    )
-
-    register(
-        id="MiniGrid-DoorKey-8x8-v0",
-        entry_point="minigrid.envs:DoorKeyEnv",
-        kwargs={"size": 8},
-    )
-
-    register(
-        id="MiniGrid-DoorKey-16x16-v0",
-        entry_point="minigrid.envs:DoorKeyEnv",
-        kwargs={"size": 16},
-    )
-
-    # Dynamic-Obstacles
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-Dynamic-Obstacles-5x5-v0",
-        entry_point="minigrid.envs:DynamicObstaclesEnv",
-        kwargs={"size": 5, "n_obstacles": 2},
-    )
-
-    register(
-        id="MiniGrid-Dynamic-Obstacles-Random-5x5-v0",
-        entry_point="minigrid.envs:DynamicObstaclesEnv",
-        kwargs={"size": 5, "agent_start_pos": None, "n_obstacles": 2},
-    )
-
-    register(
-        id="MiniGrid-Dynamic-Obstacles-6x6-v0",
-        entry_point="minigrid.envs:DynamicObstaclesEnv",
-        kwargs={"size": 6, "n_obstacles": 3},
-    )
-
-    register(
-        id="MiniGrid-Dynamic-Obstacles-Random-6x6-v0",
-        entry_point="minigrid.envs:DynamicObstaclesEnv",
-        kwargs={"size": 6, "agent_start_pos": None, "n_obstacles": 3},
-    )
-
-    register(
-        id="MiniGrid-Dynamic-Obstacles-8x8-v0",
-        entry_point="minigrid.envs:DynamicObstaclesEnv",
-    )
-
-    register(
-        id="MiniGrid-Dynamic-Obstacles-16x16-v0",
-        entry_point="minigrid.envs:DynamicObstaclesEnv",
-        kwargs={"size": 16, "n_obstacles": 8},
-    )
-
-    # Empty
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-Empty-5x5-v0",
-        entry_point="minigrid.envs:EmptyEnv",
-        kwargs={"size": 5},
-    )
-
-    register(
-        id="MiniGrid-Empty-Random-5x5-v0",
-        entry_point="minigrid.envs:EmptyEnv",
-        kwargs={"size": 5, "agent_start_pos": None},
-    )
-
-    register(
-        id="MiniGrid-Empty-6x6-v0",
-        entry_point="minigrid.envs:EmptyEnv",
-        kwargs={"size": 6},
-    )
-
-    register(
-        id="MiniGrid-Empty-Random-6x6-v0",
-        entry_point="minigrid.envs:EmptyEnv",
-        kwargs={"size": 6, "agent_start_pos": None},
-    )
-
-    register(
-        id="MiniGrid-Empty-8x8-v0",
-        entry_point="minigrid.envs:EmptyEnv",
-    )
-
-    register(
-        id="MiniGrid-Empty-16x16-v0",
-        entry_point="minigrid.envs:EmptyEnv",
-        kwargs={"size": 16},
-    )
-
-    # Fetch
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-Fetch-5x5-N2-v0",
-        entry_point="minigrid.envs:FetchEnv",
-        kwargs={"size": 5, "numObjs": 2},
-    )
-
-    register(
-        id="MiniGrid-Fetch-6x6-N2-v0",
-        entry_point="minigrid.envs:FetchEnv",
-        kwargs={"size": 6, "numObjs": 2},
-    )
-
-    register(id="MiniGrid-Fetch-8x8-N3-v0", entry_point="minigrid.envs:FetchEnv")
-
-    # FourRooms
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-FourRooms-v0",
-        entry_point="minigrid.envs:FourRoomsEnv",
-    )
-
-    # GoToDoor
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-GoToDoor-5x5-v0",
-        entry_point="minigrid.envs:GoToDoorEnv",
-    )
-
-    register(
-        id="MiniGrid-GoToDoor-6x6-v0",
-        entry_point="minigrid.envs:GoToDoorEnv",
-        kwargs={"size": 6},
-    )
-
-    register(
-        id="MiniGrid-GoToDoor-8x8-v0",
-        entry_point="minigrid.envs:GoToDoorEnv",
-        kwargs={"size": 8},
-    )
-
-    # GoToObject
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-GoToObject-6x6-N2-v0",
-        entry_point="minigrid.envs:GoToObjectEnv",
-    )
-
-    register(
-        id="MiniGrid-GoToObject-8x8-N2-v0",
-        entry_point="minigrid.envs:GoToObjectEnv",
-        kwargs={"size": 8, "numObjs": 2},
-    )
-
-    # KeyCorridor
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-KeyCorridorS3R1-v0",
-        entry_point="minigrid.envs:KeyCorridorEnv",
-        kwargs={"room_size": 3, "num_rows": 1},
-    )
-
-    register(
-        id="MiniGrid-KeyCorridorS3R2-v0",
-        entry_point="minigrid.envs:KeyCorridorEnv",
-        kwargs={"room_size": 3, "num_rows": 2},
-    )
-
-    register(
-        id="MiniGrid-KeyCorridorS3R3-v0",
-        entry_point="minigrid.envs:KeyCorridorEnv",
-        kwargs={"room_size": 3, "num_rows": 3},
-    )
-
-    register(
-        id="MiniGrid-KeyCorridorS4R3-v0",
-        entry_point="minigrid.envs:KeyCorridorEnv",
-        kwargs={"room_size": 4, "num_rows": 3},
-    )
-
-    register(
-        id="MiniGrid-KeyCorridorS5R3-v0",
-        entry_point="minigrid.envs:KeyCorridorEnv",
-        kwargs={"room_size": 5, "num_rows": 3},
-    )
-
-    register(
-        id="MiniGrid-KeyCorridorS6R3-v0",
-        entry_point="minigrid.envs:KeyCorridorEnv",
-        kwargs={"room_size": 6, "num_rows": 3},
-    )
-
-    # LavaGap
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-LavaGapS5-v0",
-        entry_point="minigrid.envs:LavaGapEnv",
-        kwargs={"size": 5},
-    )
-
-    register(
-        id="MiniGrid-LavaGapS6-v0",
-        entry_point="minigrid.envs:LavaGapEnv",
-        kwargs={"size": 6},
-    )
-
-    register(
-        id="MiniGrid-LavaGapS7-v0",
-        entry_point="minigrid.envs:LavaGapEnv",
-        kwargs={"size": 7},
-    )
-
-    # LockedRoom
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-LockedRoom-v0",
-        entry_point="minigrid.envs:LockedRoomEnv",
-    )
-
-    # Memory
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-MemoryS17Random-v0",
-        entry_point="minigrid.envs:MemoryEnv",
-        kwargs={"size": 17, "random_length": True},
-    )
-
-    register(
-        id="MiniGrid-MemoryS13Random-v0",
-        entry_point="minigrid.envs:MemoryEnv",
-        kwargs={"size": 13, "random_length": True},
-    )
-
-    register(
-        id="MiniGrid-MemoryS13-v0",
-        entry_point="minigrid.envs:MemoryEnv",
-        kwargs={"size": 13},
-    )
-
-    register(
-        id="MiniGrid-MemoryS11-v0",
-        entry_point="minigrid.envs:MemoryEnv",
-        kwargs={"size": 11},
-    )
-
-    register(
-        id="MiniGrid-MemoryS9-v0",
-        entry_point="minigrid.envs:MemoryEnv",
-        kwargs={"size": 9},
-    )
-
-    register(
-        id="MiniGrid-MemoryS7-v0",
-        entry_point="minigrid.envs:MemoryEnv",
-        kwargs={"size": 7},
-    )
-
-    # MultiRoom
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-MultiRoom-N2-S4-v0",
-        entry_point="minigrid.envs:MultiRoomEnv",
-        kwargs={"minNumRooms": 2, "maxNumRooms": 2, "maxRoomSize": 4},
-    )
-
-    register(
-        id="MiniGrid-MultiRoom-N4-S5-v0",
-        entry_point="minigrid.envs:MultiRoomEnv",
-        kwargs={"minNumRooms": 6, "maxNumRooms": 6, "maxRoomSize": 5},
-    )
-
-    register(
-        id="MiniGrid-MultiRoom-N6-v0",
-        entry_point="minigrid.envs:MultiRoomEnv",
-        kwargs={"minNumRooms": 6, "maxNumRooms": 6},
-    )
-
-    register(
-    id="MiniGrid-MultiRoom-N7-S4-v0",
-    entry_point="minigrid.envs:MultiRoomEnv",
-    kwargs={"minNumRooms": 7, "maxNumRooms": 7, "maxRoomSize": 4},
-    )
-
-    # ObstructedMaze
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-ObstructedMaze-1Dl-v0",
-        entry_point="minigrid.envs:ObstructedMaze_1Dlhb",
-        kwargs={"key_in_box": False, "blocked": False},
-    )
-
-    register(
-        id="MiniGrid-ObstructedMaze-1Dlh-v0",
-        entry_point="minigrid.envs:ObstructedMaze_1Dlhb",
-        kwargs={"key_in_box": True, "blocked": False},
-    )
-
-    register(
-        id="MiniGrid-ObstructedMaze-1Dlhb-v0",
-        entry_point="minigrid.envs:ObstructedMaze_1Dlhb",
-    )
-
-    register(
-        id="MiniGrid-ObstructedMaze-2Dl-v0",
-        entry_point="minigrid.envs:ObstructedMaze_Full",
-        kwargs={
-            "agent_room": (2, 1),
-            "key_in_box": False,
-            "blocked": False,
-            "num_quarters": 1,
-            "num_rooms_visited": 4,
-        },
-    )
-
-    register(
-        id="MiniGrid-ObstructedMaze-2Dlh-v0",
-        entry_point="minigrid.envs:ObstructedMaze_Full",
-        kwargs={
-            "agent_room": (2, 1),
-            "key_in_box": True,
-            "blocked": False,
-            "num_quarters": 1,
-            "num_rooms_visited": 4,
-        },
-    )
-
-    register(
-        id="MiniGrid-ObstructedMaze-2Dlhb-v0",
-        entry_point="minigrid.envs:ObstructedMaze_Full",
-        kwargs={
-            "agent_room": (2, 1),
-            "key_in_box": True,
-            "blocked": True,
-            "num_quarters": 1,
-            "num_rooms_visited": 4,
-        },
-    )
-
-    register(
-        id="MiniGrid-ObstructedMaze-1Q-v0",
-        entry_point="minigrid.envs:ObstructedMaze_Full",
-        kwargs={
-            "agent_room": (1, 1),
-            "key_in_box": True,
-            "blocked": True,
-            "num_quarters": 1,
-            "num_rooms_visited": 5,
-        },
-    )
-
-    register(
-        id="MiniGrid-ObstructedMaze-2Q-v0",
-        entry_point="minigrid.envs:ObstructedMaze_Full",
-        kwargs={
-            "agent_room": (2, 1),
-            "key_in_box": True,
-            "blocked": True,
-            "num_quarters": 2,
-            "num_rooms_visited": 11,
-        },
-    )
-
-    register(
-        id="MiniGrid-ObstructedMaze-Full-v0",
-        entry_point="minigrid.envs:ObstructedMaze_Full",
-    )
-
-    # ObstructedMaze-v1
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-ObstructedMaze-2Dlhb-v1",
-        entry_point="minigrid.envs.obstructedmaze_v1:ObstructedMaze_Full",
-        kwargs={
-            "agent_room": (2, 1),
-            "key_in_box": True,
-            "blocked": True,
-            "num_quarters": 1,
-            "num_rooms_visited": 4,
-        },
-    )
-
-    register(
-        id="MiniGrid-ObstructedMaze-1Q-v1",
-        entry_point="minigrid.envs.obstructedmaze_v1:ObstructedMaze_Full",
-        kwargs={
-            "agent_room": (1, 1),
-            "key_in_box": True,
-            "blocked": True,
-            "num_quarters": 1,
-            "num_rooms_visited": 5,
-        },
-    )
-
-    register(
-        id="MiniGrid-ObstructedMaze-2Q-v1",
-        entry_point="minigrid.envs.obstructedmaze_v1:ObstructedMaze_Full",
-        kwargs={
-            "agent_room": (2, 1),
-            "key_in_box": True,
-            "blocked": True,
-            "num_quarters": 2,
-            "num_rooms_visited": 11,
-        },
-    )
-
-    register(
-        id="MiniGrid-ObstructedMaze-Full-v1",
-        entry_point="minigrid.envs.obstructedmaze_v1:ObstructedMaze_Full",
-    )
-
-    # Playground
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-Playground-v0",
-        entry_point="minigrid.envs:PlaygroundEnv",
-    )
-
-    # PutNear
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-PutNear-6x6-N2-v0",
-        entry_point="minigrid.envs:PutNearEnv",
-    )
-
-    register(
-        id="MiniGrid-PutNear-8x8-N3-v0",
-        entry_point="minigrid.envs:PutNearEnv",
-        kwargs={"size": 8, "numObjs": 3},
-    )
-
-    # RedBlueDoors
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-RedBlueDoors-6x6-v0",
-        entry_point="minigrid.envs:RedBlueDoorEnv",
-        kwargs={"size": 6},
-    )
-
-    register(
-        id="MiniGrid-RedBlueDoors-8x8-v0",
-        entry_point="minigrid.envs:RedBlueDoorEnv",
-    )
-
-    # Unlock
-    # ----------------------------------------
-
-    register(id="MiniGrid-Unlock-v0", entry_point="minigrid.envs:UnlockEnv")
-
-    # UnlockPickup
-    # ----------------------------------------
-
-    register(
-        id="MiniGrid-UnlockPickup-v0",
-        entry_point="minigrid.envs:UnlockPickupEnv",
-    )
-
-    # BabyAI - Language based levels - GoTo
-    # ----------------------------------------
-
-    register(
-        id="BabyAI-GoToRedBallGrey-v0",
-        entry_point="minigrid.envs.babyai:GoToRedBallGrey",
-    )
-
-    register(
-        id="BabyAI-GoToRedBall-v0",
-        entry_point="minigrid.envs.babyai:GoToRedBall",
-    )
-
-    register(
-        id="BabyAI-GoToRedBallNoDists-v0",
-        entry_point="minigrid.envs.babyai:GoToRedBallNoDists",
-    )
-
-    register(
-        id="BabyAI-GoToObj-v0",
-        entry_point="minigrid.envs.babyai:GoToObj",
-    )
-
-    register(
-        id="BabyAI-GoToObjS4-v0",
-        entry_point="minigrid.envs.babyai:GoToObj",
-        kwargs={"room_size": 4},
-    )
-
-    register(
-        id="BabyAI-GoToObjS6-v0",
-        entry_point="minigrid.envs.babyai:GoToObj",
-        kwargs={"room_size": 4},
-    )
-
-    register(
-        id="BabyAI-GoToLocal-v0",
-        entry_point="minigrid.envs.babyai:GoToLocal",
-    )
-
-    register(
-        id="BabyAI-GoToLocalS5N2-v0",
-        entry_point="minigrid.envs.babyai:GoToLocal",
-        kwargs={"room_size": 5, "num_dists": 2},
-    )
-
-    register(
-        id="BabyAI-GoToLocalS6N2-v0",
-        entry_point="minigrid.envs.babyai:GoToLocal",
-        kwargs={"room_size": 6, "num_dists": 2},
-    )
-
-    register(
-        id="BabyAI-GoToLocalS6N3-v0",
-        entry_point="minigrid.envs.babyai:GoToLocal",
-        kwargs={"room_size": 6, "num_dists": 3},
-    )
-
-    register(
-        id="BabyAI-GoToLocalS6N4-v0",
-        entry_point="minigrid.envs.babyai:GoToLocal",
-        kwargs={"room_size": 6, "num_dists": 4},
-    )
-
-    register(
-        id="BabyAI-GoToLocalS7N4-v0",
-        entry_point="minigrid.envs.babyai:GoToLocal",
-        kwargs={"room_size": 7, "num_dists": 4},
-    )
-
-    register(
-        id="BabyAI-GoToLocalS7N5-v0",
-        entry_point="minigrid.envs.babyai:GoToLocal",
-        kwargs={"room_size": 7, "num_dists": 5},
-    )
-
-    register(
-        id="BabyAI-GoToLocalS8N2-v0",
-        entry_point="minigrid.envs.babyai:GoToLocal",
-        kwargs={"room_size": 8, "num_dists": 2},
-    )
-
-    register(
-        id="BabyAI-GoToLocalS8N3-v0",
-        entry_point="minigrid.envs.babyai:GoToLocal",
-        kwargs={"room_size": 8, "num_dists": 3},
-    )
-
-    register(
-        id="BabyAI-GoToLocalS8N4-v0",
-        entry_point="minigrid.envs.babyai:GoToLocal",
-        kwargs={"room_size": 8, "num_dists": 4},
-    )
-
-    register(
-        id="BabyAI-GoToLocalS8N5-v0",
-        entry_point="minigrid.envs.babyai:GoToLocal",
-        kwargs={"room_size": 8, "num_dists": 5},
-    )
-
-    register(
-        id="BabyAI-GoToLocalS8N6-v0",
-        entry_point="minigrid.envs.babyai:GoToLocal",
-        kwargs={"room_size": 8, "num_dists": 6},
-    )
-
-    register(
-        id="BabyAI-GoToLocalS8N7-v0",
-        entry_point="minigrid.envs.babyai:GoToLocal",
-        kwargs={"room_size": 8, "num_dists": 7},
-    )
-
-    register(
-        id="BabyAI-GoTo-v0",
-        entry_point="minigrid.envs.babyai:GoTo",
-    )
-
-    register(
-        "BabyAI-GoToOpen-v0",
-        entry_point="minigrid.envs.babyai:GoTo",
-        kwargs={"doors_open": True},
-    )
-
-    register(
-        id="BabyAI-GoToObjMaze-v0",
-        entry_point="minigrid.envs.babyai:GoTo",
-        kwargs={"num_dists": 1, "doors_open": False},
-    )
-
-    register(
-        id="BabyAI-GoToObjMazeOpen-v0",
-        entry_point="minigrid.envs.babyai:GoTo",
-        kwargs={"num_dists": 1, "doors_open": True},
-    )
-
-    register(
-        id="BabyAI-GoToObjMazeS4R2-v0",
-        entry_point="minigrid.envs.babyai:GoTo",
-        kwargs={"num_dists": 1, "room_size": 4, "num_rows": 2, "num_cols": 2},
-    )
-
-    register(
-        id="BabyAI-GoToObjMazeS4-v0",
-        entry_point="minigrid.envs.babyai:GoTo",
-        kwargs={"num_dists": 1, "room_size": 4},
-    )
-
-    register(
-        id="BabyAI-GoToObjMazeS5-v0",
-        entry_point="minigrid.envs.babyai:GoTo",
-        kwargs={"num_dists": 1, "room_size": 5},
-    )
-
-    register(
-        id="BabyAI-GoToObjMazeS6-v0",
-        entry_point="minigrid.envs.babyai:GoTo",
-        kwargs={"num_dists": 1, "room_size": 6},
-    )
-
-    register(
-        id="BabyAI-GoToObjMazeS7-v0",
-        entry_point="minigrid.envs.babyai:GoTo",
-        kwargs={"num_dists": 1, "room_size": 7},
-    )
-
-    register(
-        id="BabyAI-GoToImpUnlock-v0",
-        entry_point="minigrid.envs.babyai:GoToImpUnlock",
-    )
-
-    register(
-        id="BabyAI-GoToSeq-v0",
-        entry_point="minigrid.envs.babyai:GoToSeq",
-    )
-
-    register(
-        id="BabyAI-GoToSeqS5R2-v0",
-        entry_point="minigrid.envs.babyai:GoToSeq",
-        kwargs={"room_size": 5, "num_rows": 2, "num_cols": 2, "num_dists": 4},
-    )
-
-    register(
-        id="BabyAI-GoToRedBlueBall-v0",
-        entry_point="minigrid.envs.babyai:GoToRedBlueBall",
-    )
-
-    register(
-        id="BabyAI-GoToDoor-v0",
-        entry_point="minigrid.envs.babyai:GoToDoor",
-    )
-
-    register(
-        id="BabyAI-GoToObjDoor-v0",
-        entry_point="minigrid.envs.babyai:GoToObjDoor",
-    )
-
-    # BabyAI - Language based levels - Open
-    # ----------------------------------------
-
-    register(
-        id="BabyAI-Open-v0",
-        entry_point="minigrid.envs.babyai:Open",
-    )
-
-    register(
-        id="BabyAI-OpenRedDoor-v0",
-        entry_point="minigrid.envs.babyai:OpenRedDoor",
-    )
-
-    register(
-        id="BabyAI-OpenDoor-v0",
-        entry_point="minigrid.envs.babyai:OpenDoor",
-    )
-
-    register(
-        id="BabyAI-OpenDoorDebug-v0",
-        entry_point="minigrid.envs.babyai:OpenDoor",
-        kwargs={"debug": True, "select_by": None},
-    )
-
-    register(
-        id="BabyAI-OpenDoorColor-v0",
-        entry_point="minigrid.envs.babyai:OpenDoor",
-        kwargs={"select_by": "color"},
-    )
-
-    register(
-        id="BabyAI-OpenDoorLoc-v0",
-        entry_point="minigrid.envs.babyai:OpenDoor",
-        kwargs={"select_by": "loc"},
-    )
-
-    register(
-        id="BabyAI-OpenTwoDoors-v0",
-        entry_point="minigrid.envs.babyai:OpenTwoDoors",
-    )
-
-    register(
-        id="BabyAI-OpenRedBlueDoors-v0",
-        entry_point="minigrid.envs.babyai:OpenTwoDoors",
-        kwargs={"first_color": "red", "second_color": "blue"},
-    )
-
-    register(
-        id="BabyAI-OpenRedBlueDoorsDebug-v0",
-        entry_point="minigrid.envs.babyai:OpenTwoDoors",
-        kwargs={
-            "first_color": "red",
-            "second_color": "blue",
-            "strict": True,
-        },
-    )
-
-    register(
-        id="BabyAI-OpenDoorsOrderN2-v0",
-        entry_point="minigrid.envs.babyai:OpenDoorsOrder",
-        kwargs={"num_doors": 2},
-    )
-
-    register(
-        id="BabyAI-OpenDoorsOrderN4-v0",
-        entry_point="minigrid.envs.babyai:OpenDoorsOrder",
-        kwargs={"num_doors": 4},
-    )
-
-    register(
-        id="BabyAI-OpenDoorsOrderN2Debug-v0",
-        entry_point="minigrid.envs.babyai:OpenDoorsOrder",
-        kwargs={"debug": True, "num_doors": 2},
-    )
-
-    register(
-        id="BabyAI-OpenDoorsOrderN4Debug-v0",
-        entry_point="minigrid.envs.babyai:OpenDoorsOrder",
-        kwargs={"debug": True, "num_doors": 4},
-    )
-
-    # BabyAI - Language based levels - Pickup
-    # ----------------------------------------
-
-    register(
-        id="BabyAI-Pickup-v0",
-        entry_point="minigrid.envs.babyai:Pickup",
-    )
-
-    register(
-        id="BabyAI-UnblockPickup-v0",
-        entry_point="minigrid.envs.babyai:UnblockPickup",
-    )
-
-    register(
-        id="BabyAI-PickupLoc-v0",
-        entry_point="minigrid.envs.babyai:PickupLoc",
-    )
-
-    register(
-        id="BabyAI-PickupDist-v0",
-        entry_point="minigrid.envs.babyai:PickupDist",
-    )
-
-    register(
-        id="BabyAI-PickupDistDebug-v0",
-        entry_point="minigrid.envs.babyai:PickupDist",
-        kwargs={"debug": True},
-    )
-
-    register(
-        id="BabyAI-PickupAbove-v0",
-        entry_point="minigrid.envs.babyai:PickupAbove",
-    )
-
-    # BabyAI - Language based levels - PutNext
-    # ----------------------------------------
-
-    register(
-        id="BabyAI-PutNextLocal-v0",
-        entry_point="minigrid.envs.babyai:PutNextLocal",
-    )
-
-    register(
-        id="BabyAI-PutNextLocalS5N3-v0",
-        entry_point="minigrid.envs.babyai:PutNextLocal",
-        kwargs={"room_size": 5, "num_objs": 3},
-    )
-
-    register(
-        id="BabyAI-PutNextLocalS6N4-v0",
-        entry_point="minigrid.envs.babyai:PutNextLocal",
-        kwargs={"room_size": 6, "num_objs": 4},
-    )
-
-    register(
-        id="BabyAI-PutNextS4N1-v0",
-        entry_point="minigrid.envs.babyai:PutNext",
-        kwargs={"room_size": 4, "objs_per_room": 1},
-    )
-
-    register(
-        id="BabyAI-PutNextS5N2-v0",
-        entry_point="minigrid.envs.babyai:PutNext",
-        kwargs={"room_size": 5, "objs_per_room": 2},
-    )
-
-    register(
-        id="BabyAI-PutNextS5N1-v0",
-        entry_point="minigrid.envs.babyai:PutNext",
-        kwargs={"room_size": 5, "objs_per_room": 1},
-    )
-
-    register(
-        id="BabyAI-PutNextS6N3-v0",
-        entry_point="minigrid.envs.babyai:PutNext",
-        kwargs={"room_size": 6, "objs_per_room": 3},
-    )
-
-    register(
-        id="BabyAI-PutNextS7N4-v0",
-        entry_point="minigrid.envs.babyai:PutNext",
-        kwargs={"room_size": 7, "objs_per_room": 4},
-    )
-
-    register(
-        id="BabyAI-PutNextS5N2Carrying-v0",
-        entry_point="minigrid.envs.babyai:PutNext",
-        kwargs={"room_size": 5, "objs_per_room": 2, "start_carrying": True},
-    )
-
-    register(
-        id="BabyAI-PutNextS6N3Carrying-v0",
-        entry_point="minigrid.envs.babyai:PutNext",
-        kwargs={"room_size": 6, "objs_per_room": 3, "start_carrying": True},
-    )
-
-    register(
-        id="BabyAI-PutNextS7N4Carrying-v0",
-        entry_point="minigrid.envs.babyai:PutNext",
-        kwargs={"room_size": 7, "objs_per_room": 4, "start_carrying": True},
-    )
-
-    # BabyAI - Language based levels - Unlock
-    # ----------------------------------------
-
-    register(
-        id="BabyAI-Unlock-v0",
-        entry_point="minigrid.envs.babyai:Unlock",
-    )
-
-    register(
-        id="BabyAI-UnlockLocal-v0",
-        entry_point="minigrid.envs.babyai:UnlockLocal",
-    )
-
-    register(
-        id="BabyAI-UnlockLocalDist-v0",
-        entry_point="minigrid.envs.babyai:UnlockLocal",
-        kwargs={"distractors": True},
-    )
-
-    register(
-        id="BabyAI-KeyInBox-v0",
-        entry_point="minigrid.envs.babyai:KeyInBox",
-    )
-
-    register(
-        id="BabyAI-UnlockPickup-v0",
-        entry_point="minigrid.envs.babyai:UnlockPickup",
-    )
-
-    register(
-        id="BabyAI-UnlockPickupDist-v0",
-        entry_point="minigrid.envs.babyai:UnlockPickup",
-        kwargs={"distractors": True},
-    )
-
-    register(
-        id="BabyAI-BlockedUnlockPickup-v0",
-        entry_point="minigrid.envs.babyai:BlockedUnlockPickup",
-    )
-
-    register(
-        id="BabyAI-UnlockToUnlock-v0",
-        entry_point="minigrid.envs.babyai:UnlockToUnlock",
-    )
-
-    # BabyAI - Language based levels - Other
-    # ----------------------------------------
-
-    register(
-        id="BabyAI-ActionObjDoor-v0",
-        entry_point="minigrid.envs.babyai:ActionObjDoor",
-    )
-
-    register(
-        id="BabyAI-FindObjS5-v0",
-        entry_point="minigrid.envs.babyai:FindObjS5",
-    )
-
-    register(
-        id="BabyAI-FindObjS6-v0",
-        entry_point="minigrid.envs.babyai:FindObjS5",
-        kwargs={"room_size": 6},
-    )
-
-    register(
-        id="BabyAI-FindObjS7-v0",
-        entry_point="minigrid.envs.babyai:FindObjS5",
-        kwargs={"room_size": 7},
-    )
-
-    register(
-        id="BabyAI-KeyCorridor-v0",
-        entry_point="minigrid.envs.babyai:KeyCorridor",
-    )
-
-    register(
-        id="BabyAI-KeyCorridorS3R1-v0",
-        entry_point="minigrid.envs.babyai:KeyCorridor",
-        kwargs={"room_size": 3, "num_rows": 1},
-    )
-
-    register(
-        id="BabyAI-KeyCorridorS3R2-v0",
-        entry_point="minigrid.envs.babyai:KeyCorridor",
-        kwargs={"room_size": 3, "num_rows": 2},
-    )
-
-    register(
-        id="BabyAI-KeyCorridorS3R3-v0",
-        entry_point="minigrid.envs.babyai:KeyCorridor",
-        kwargs={"room_size": 3, "num_rows": 3},
-    )
-
-    register(
-        id="BabyAI-KeyCorridorS4R3-v0",
-        entry_point="minigrid.envs.babyai:KeyCorridor",
-        kwargs={"room_size": 4, "num_rows": 3},
-    )
-
-    register(
-        id="BabyAI-KeyCorridorS5R3-v0",
-        entry_point="minigrid.envs.babyai:KeyCorridor",
-        kwargs={"room_size": 5, "num_rows": 3},
-    )
-
-    register(
-        id="BabyAI-KeyCorridorS6R3-v0",
-        entry_point="minigrid.envs.babyai:KeyCorridor",
-        kwargs={"room_size": 6, "num_rows": 3},
-    )
-
-    register(
-        id="BabyAI-OneRoomS8-v0",
-        entry_point="minigrid.envs.babyai:OneRoomS8",
-    )
-
-    register(
-        id="BabyAI-OneRoomS12-v0",
-        entry_point="minigrid.envs.babyai:OneRoomS8",
-        kwargs={"room_size": 12},
-    )
-
-    register(
-        id="BabyAI-OneRoomS16-v0",
-        entry_point="minigrid.envs.babyai:OneRoomS8",
-        kwargs={"room_size": 16},
-    )
-
-    register(
-        id="BabyAI-OneRoomS20-v0",
-        entry_point="minigrid.envs.babyai:OneRoomS8",
-        kwargs={"room_size": 20},
-    )
-
-    register(
-        id="BabyAI-MoveTwoAcrossS5N2-v0",
-        entry_point="minigrid.envs.babyai:MoveTwoAcross",
-        kwargs={"room_size": 5, "objs_per_room": 2},
-    )
-
-    register(
-        id="BabyAI-MoveTwoAcrossS8N9-v0",
-        entry_point="minigrid.envs.babyai:MoveTwoAcross",
-        kwargs={"room_size": 8, "objs_per_room": 9},
-    )
-
-    # BabyAI - Language based levels - Synth
-    # ----------------------------------------
-
-    register(
-        id="BabyAI-Synth-v0",
-        entry_point="minigrid.envs.babyai:Synth",
-    )
-
-    register(
-        id="BabyAI-SynthS5R2-v0",
-        entry_point="minigrid.envs.babyai:Synth",
-        kwargs={"room_size": 5, "num_rows": 2},
-    )
-
-    register(
-        id="BabyAI-SynthLoc-v0",
-        entry_point="minigrid.envs.babyai:SynthLoc",
-    )
-
-    register(
-        id="BabyAI-SynthSeq-v0",
-        entry_point="minigrid.envs.babyai:SynthSeq",
-    )
-
-    register(
-        id="BabyAI-MiniBossLevel-v0",
-        entry_point="minigrid.envs.babyai:MiniBossLevel",
-    )
-
-    register(
-        id="BabyAI-BossLevel-v0",
-        entry_point="minigrid.envs.babyai:BossLevel",
-    )
-
-    register(
-        id="BabyAI-BossLevelNoUnlock-v0",
-        entry_point="minigrid.envs.babyai:BossLevelNoUnlock",
-    )
diff --git a/rl-starter-files/Minigrid/minigrid/benchmark.py b/rl-starter-files/Minigrid/minigrid/benchmark.py
deleted file mode 100755
index 5a66774..0000000
--- a/rl-starter-files/Minigrid/minigrid/benchmark.py
+++ /dev/null
@@ -1,132 +0,0 @@
-#!/usr/bin/env python3
-
-from __future__ import annotations
-
-import time
-
-import gymnasium as gym
-
-from minigrid.manual_control import ManualControl
-from minigrid.wrappers import ImgObsWrapper, RGBImgPartialObsWrapper
-
-
-def benchmark(env_id, num_resets, num_frames):
-    env = gym.make(env_id, render_mode="rgb_array")
-    # Benchmark env.reset
-    t0 = time.time()
-    for i in range(num_resets):
-        env.reset()
-    t1 = time.time()
-    dt = t1 - t0
-    reset_time = (1000 * dt) / num_resets
-
-    # Benchmark rendering
-    t0 = time.time()
-    for i in range(num_frames):
-        env.render()
-    t1 = time.time()
-    dt = t1 - t0
-    frames_per_sec = num_frames / dt
-
-    # Create an environment with an RGB agent observation
-    env = gym.make(env_id, render_mode="rgb_array")
-    env = RGBImgPartialObsWrapper(env)
-    env = ImgObsWrapper(env)
-
-    env.reset()
-    # Benchmark rendering in agent view
-    t0 = time.time()
-    for i in range(num_frames):
-        obs, reward, terminated, truncated, info = env.step(0)
-    t1 = time.time()
-    dt = t1 - t0
-    agent_view_fps = num_frames / dt
-
-    print(f"Env reset time: {reset_time:.1f} ms")
-    print(f"Rendering FPS : {frames_per_sec:.0f}")
-    print(f"Agent view FPS: {agent_view_fps:.0f}")
-
-    env.close()
-
-
-def benchmark_manual_control(env_id, num_resets, num_frames, tile_size):
-    env = gym.make(env_id, tile_size=tile_size)
-    env = ManualControl(env, seed=args.seed)
-
-    # Benchmark env.reset
-    t0 = time.time()
-    for i in range(num_resets):
-        env.reset()
-    t1 = time.time()
-    dt = t1 - t0
-    reset_time = (1000 * dt) / num_resets
-
-    # Benchmark rendering
-    t0 = time.time()
-    for i in range(num_frames):
-        env.redraw()
-    t1 = time.time()
-    dt = t1 - t0
-    frames_per_sec = num_frames / dt
-
-    # Create an environment with an RGB agent observation
-    env = gym.make(env_id, tile_size=tile_size)
-    env = RGBImgPartialObsWrapper(env, env.tile_size)
-    env = ImgObsWrapper(env)
-
-    env = ManualControl(env, seed=args.seed)
-    env.reset()
-
-    # Benchmark rendering in agent view
-    t0 = time.time()
-    for i in range(num_frames):
-        env.step(0)
-    t1 = time.time()
-    dt = t1 - t0
-    agent_view_fps = num_frames / dt
-
-    print(f"Env reset time: {reset_time:.1f} ms")
-    print(f"Rendering FPS : {frames_per_sec:.0f}")
-    print(f"Agent view FPS: {agent_view_fps:.0f}")
-
-    env.close()
-
-
-if __name__ == "__main__":
-    import argparse
-
-    parser = argparse.ArgumentParser()
-    parser.add_argument(
-        "--env-id",
-        dest="env_id",
-        help="gym environment to load",
-        default="MiniGrid-LavaGapS7-v0",
-    )
-    parser.add_argument(
-        "--seed",
-        type=int,
-        help="random seed to generate the environment with",
-        default=None,
-    )
-    parser.add_argument(
-        "--num-resets",
-        type=int,
-        help="number of times to reset the environment for benchmarking",
-        default=200,
-    )
-    parser.add_argument(
-        "--num-frames",
-        type=int,
-        help="number of frames to test rendering for",
-        default=5000,
-    )
-    parser.add_argument(
-        "--tile-size", type=int, help="size at which to render tiles", default=32
-    )
-
-    args = parser.parse_args()
-    benchmark(args.env_id, args.num_resets, args.num_frames)
-
-    benchmark_manual_control(
-        args.env_id, args.num_resets, args.num_frames, args.tile_size
-    )
diff --git a/rl-starter-files/Minigrid/minigrid/core/__init__.py b/rl-starter-files/Minigrid/minigrid/core/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/rl-starter-files/Minigrid/minigrid/core/actions.py b/rl-starter-files/Minigrid/minigrid/core/actions.py
deleted file mode 100644
index b440438..0000000
--- a/rl-starter-files/Minigrid/minigrid/core/actions.py
+++ /dev/null
@@ -1,20 +0,0 @@
-# Enumeration of possible actions
-from __future__ import annotations
-
-from enum import IntEnum
-
-
-class Actions(IntEnum):
-    # Turn left, turn right, move forward
-    left = 0
-    right = 1
-    forward = 2
-    # Pick up an object
-    pickup = 3
-    # Drop an object
-    drop = 4
-    # Toggle/activate an object
-    toggle = 5
-
-    # Done completing task
-    done = 6
diff --git a/rl-starter-files/Minigrid/minigrid/core/constants.py b/rl-starter-files/Minigrid/minigrid/core/constants.py
deleted file mode 100644
index 9763c63..0000000
--- a/rl-starter-files/Minigrid/minigrid/core/constants.py
+++ /dev/null
@@ -1,58 +0,0 @@
-from __future__ import annotations
-
-import numpy as np
-
-TILE_PIXELS = 32
-
-# Map of color names to RGB values
-COLORS = {
-    "red": np.array([255, 0, 0]),
-    "green": np.array([0, 255, 0]),
-    "blue": np.array([0, 0, 255]),
-    "purple": np.array([112, 39, 195]),
-    "yellow": np.array([255, 255, 0]),
-    "grey": np.array([100, 100, 100]),
-}
-
-COLOR_NAMES = sorted(list(COLORS.keys()))
-
-# Used to map colors to integers
-COLOR_TO_IDX = {"red": 0, "green": 1, "blue": 2, "purple": 3, "yellow": 4, "grey": 5}
-
-IDX_TO_COLOR = dict(zip(COLOR_TO_IDX.values(), COLOR_TO_IDX.keys()))
-
-# Map of object type to integers
-OBJECT_TO_IDX = {
-    "unseen": 0,
-    "empty": 1,
-    "wall": 2,
-    "floor": 3,
-    "door": 4,
-    "key": 5,
-    "ball": 6,
-    "box": 7,
-    "goal": 8,
-    "lava": 9,
-    "agent": 10,
-}
-
-IDX_TO_OBJECT = dict(zip(OBJECT_TO_IDX.values(), OBJECT_TO_IDX.keys()))
-
-# Map of state names to integers
-STATE_TO_IDX = {
-    "open": 0,
-    "closed": 1,
-    "locked": 2,
-}
-
-# Map of agent direction indices to vectors
-DIR_TO_VEC = [
-    # Pointing right (positive X)
-    np.array((1, 0)),
-    # Down (positive Y)
-    np.array((0, 1)),
-    # Pointing left (negative X)
-    np.array((-1, 0)),
-    # Up (negative Y)
-    np.array((0, -1)),
-]
diff --git a/rl-starter-files/Minigrid/minigrid/core/grid.py b/rl-starter-files/Minigrid/minigrid/core/grid.py
deleted file mode 100644
index 3a46268..0000000
--- a/rl-starter-files/Minigrid/minigrid/core/grid.py
+++ /dev/null
@@ -1,328 +0,0 @@
-from __future__ import annotations
-
-import math
-from typing import Any, Callable
-
-import numpy as np
-
-from minigrid.core.constants import OBJECT_TO_IDX, TILE_PIXELS
-from minigrid.core.world_object import Wall, WorldObj
-from minigrid.utils.rendering import (
-    downsample,
-    fill_coords,
-    highlight_img,
-    point_in_rect,
-    point_in_triangle,
-    rotate_fn,
-)
-
-
-class Grid:
-    """
-    Represent a grid and operations on it
-    """
-
-    # Static cache of pre-renderer tiles
-    tile_cache: dict[tuple[Any, ...], Any] = {}
-
-    def __init__(self, width: int, height: int):
-        assert width >= 3
-        assert height >= 3
-
-        self.width: int = width
-        self.height: int = height
-
-        self.grid: list[WorldObj | None] = [None] * (width * height)
-
-    def __contains__(self, key: Any) -> bool:
-        if isinstance(key, WorldObj):
-            for e in self.grid:
-                if e is key:
-                    return True
-        elif isinstance(key, tuple):
-            for e in self.grid:
-                if e is None:
-                    continue
-                if (e.color, e.type) == key:
-                    return True
-                if key[0] is None and key[1] == e.type:
-                    return True
-        return False
-
-    def __eq__(self, other: Grid) -> bool:
-        grid1 = self.encode()
-        grid2 = other.encode()
-        return np.array_equal(grid2, grid1)
-
-    def __ne__(self, other: Grid) -> bool:
-        return not self == other
-
-    def copy(self) -> Grid:
-        from copy import deepcopy
-
-        return deepcopy(self)
-
-    def set(self, i: int, j: int, v: WorldObj | None):
-        assert (
-            0 <= i < self.width
-        ), f"column index {i} outside of grid of width {self.width}"
-        assert (
-            0 <= j < self.height
-        ), f"row index {j} outside of grid of height {self.height}"
-        self.grid[j * self.width + i] = v
-
-    def get(self, i: int, j: int) -> WorldObj | None:
-        assert 0 <= i < self.width
-        assert 0 <= j < self.height
-        assert self.grid is not None
-        return self.grid[j * self.width + i]
-
-    def horz_wall(
-        self,
-        x: int,
-        y: int,
-        length: int | None = None,
-        obj_type: Callable[[], WorldObj] = Wall,
-    ):
-        if length is None:
-            length = self.width - x
-        for i in range(0, length):
-            self.set(x + i, y, obj_type())
-
-    def vert_wall(
-        self,
-        x: int,
-        y: int,
-        length: int | None = None,
-        obj_type: Callable[[], WorldObj] = Wall,
-    ):
-        if length is None:
-            length = self.height - y
-        for j in range(0, length):
-            self.set(x, y + j, obj_type())
-
-    def wall_rect(self, x: int, y: int, w: int, h: int):
-        self.horz_wall(x, y, w)
-        self.horz_wall(x, y + h - 1, w)
-        self.vert_wall(x, y, h)
-        self.vert_wall(x + w - 1, y, h)
-
-    def rotate_left(self) -> Grid:
-        """
-        Rotate the grid to the left (counter-clockwise)
-        """
-
-        grid = Grid(self.height, self.width)
-
-        for i in range(self.width):
-            for j in range(self.height):
-                v = self.get(i, j)
-                grid.set(j, grid.height - 1 - i, v)
-
-        return grid
-
-    def slice(self, topX: int, topY: int, width: int, height: int) -> Grid:
-        """
-        Get a subset of the grid
-        """
-
-        grid = Grid(width, height)
-
-        for j in range(0, height):
-            for i in range(0, width):
-                x = topX + i
-                y = topY + j
-
-                if 0 <= x < self.width and 0 <= y < self.height:
-                    v = self.get(x, y)
-                else:
-                    v = Wall()
-
-                grid.set(i, j, v)
-
-        return grid
-
-    @classmethod
-    def render_tile(
-        cls,
-        obj: WorldObj | None,
-        agent_dir: int | None = None,
-        highlight: bool = False,
-        tile_size: int = TILE_PIXELS,
-        subdivs: int = 3,
-    ) -> np.ndarray:
-        """
-        Render a tile and cache the result
-        """
-
-        # Hash map lookup key for the cache
-        key: tuple[Any, ...] = (agent_dir, highlight, tile_size)
-        key = obj.encode() + key if obj else key
-
-        if key in cls.tile_cache:
-            return cls.tile_cache[key]
-
-        img = np.zeros(
-            shape=(tile_size * subdivs, tile_size * subdivs, 3), dtype=np.uint8
-        )
-
-        # Draw the grid lines (top and left edges)
-        fill_coords(img, point_in_rect(0, 0.031, 0, 1), (100, 100, 100))
-        fill_coords(img, point_in_rect(0, 1, 0, 0.031), (100, 100, 100))
-
-        if obj is not None:
-            obj.render(img)
-
-        # Overlay the agent on top
-        if agent_dir is not None:
-            tri_fn = point_in_triangle(
-                (0.12, 0.19),
-                (0.87, 0.50),
-                (0.12, 0.81),
-            )
-
-            # Rotate the agent based on its direction
-            tri_fn = rotate_fn(tri_fn, cx=0.5, cy=0.5, theta=0.5 * math.pi * agent_dir)
-            fill_coords(img, tri_fn, (255, 0, 0))
-
-        # Highlight the cell if needed
-        if highlight:
-            highlight_img(img)
-
-        # Downsample the image to perform supersampling/anti-aliasing
-        img = downsample(img, subdivs)
-
-        # Cache the rendered tile
-        cls.tile_cache[key] = img
-
-        return img
-
-    def render(
-        self,
-        tile_size: int,
-        agent_pos: tuple[int, int],
-        agent_dir: int | None = None,
-        highlight_mask: np.ndarray | None = None,
-    ) -> np.ndarray:
-        """
-        Render this grid at a given scale
-        :param r: target renderer object
-        :param tile_size: tile size in pixels
-        """
-
-        if highlight_mask is None:
-            highlight_mask = np.zeros(shape=(self.width, self.height), dtype=bool)
-
-        # Compute the total grid size
-        width_px = self.width * tile_size
-        height_px = self.height * tile_size
-
-        img = np.zeros(shape=(height_px, width_px, 3), dtype=np.uint8)
-
-        # Render the grid
-        for j in range(0, self.height):
-            for i in range(0, self.width):
-                cell = self.get(i, j)
-
-                agent_here = np.array_equal(agent_pos, (i, j))
-                assert highlight_mask is not None
-                tile_img = Grid.render_tile(
-                    cell,
-                    agent_dir=agent_dir if agent_here else None,
-                    highlight=highlight_mask[i, j],
-                    tile_size=tile_size,
-                )
-
-                ymin = j * tile_size
-                ymax = (j + 1) * tile_size
-                xmin = i * tile_size
-                xmax = (i + 1) * tile_size
-                img[ymin:ymax, xmin:xmax, :] = tile_img
-
-        return img
-
-    def encode(self, vis_mask: np.ndarray | None = None) -> np.ndarray:
-        """
-        Produce a compact numpy encoding of the grid
-        """
-
-        if vis_mask is None:
-            vis_mask = np.ones((self.width, self.height), dtype=bool)
-
-        array = np.zeros((self.width, self.height, 3), dtype="uint8")
-
-        for i in range(self.width):
-            for j in range(self.height):
-                assert vis_mask is not None
-                if vis_mask[i, j]:
-                    v = self.get(i, j)
-
-                    if v is None:
-                        array[i, j, 0] = OBJECT_TO_IDX["empty"]
-                        array[i, j, 1] = 0
-                        array[i, j, 2] = 0
-
-                    else:
-                        array[i, j, :] = v.encode()
-
-        return array
-
-    @staticmethod
-    def decode(array: np.ndarray) -> tuple[Grid, np.ndarray]:
-        """
-        Decode an array grid encoding back into a grid
-        """
-
-        width, height, channels = array.shape
-        assert channels == 3
-
-        vis_mask = np.ones(shape=(width, height), dtype=bool)
-
-        grid = Grid(width, height)
-        for i in range(width):
-            for j in range(height):
-                type_idx, color_idx, state = array[i, j]
-                v = WorldObj.decode(type_idx, color_idx, state)
-                grid.set(i, j, v)
-                vis_mask[i, j] = type_idx != OBJECT_TO_IDX["unseen"]
-
-        return grid, vis_mask
-
-    def process_vis(self, agent_pos: tuple[int, int]) -> np.ndarray:
-        mask = np.zeros(shape=(self.width, self.height), dtype=bool)
-
-        mask[agent_pos[0], agent_pos[1]] = True
-
-        for j in reversed(range(0, self.height)):
-            for i in range(0, self.width - 1):
-                if not mask[i, j]:
-                    continue
-
-                cell = self.get(i, j)
-                if cell and not cell.see_behind():
-                    continue
-
-                mask[i + 1, j] = True
-                if j > 0:
-                    mask[i + 1, j - 1] = True
-                    mask[i, j - 1] = True
-
-            for i in reversed(range(1, self.width)):
-                if not mask[i, j]:
-                    continue
-
-                cell = self.get(i, j)
-                if cell and not cell.see_behind():
-                    continue
-
-                mask[i - 1, j] = True
-                if j > 0:
-                    mask[i - 1, j - 1] = True
-                    mask[i, j - 1] = True
-
-        for j in range(0, self.height):
-            for i in range(0, self.width):
-                if not mask[i, j]:
-                    self.set(i, j, None)
-
-        return mask
diff --git a/rl-starter-files/Minigrid/minigrid/core/mission.py b/rl-starter-files/Minigrid/minigrid/core/mission.py
deleted file mode 100644
index 8e62410..0000000
--- a/rl-starter-files/Minigrid/minigrid/core/mission.py
+++ /dev/null
@@ -1,202 +0,0 @@
-from __future__ import annotations
-
-from typing import Any, Callable
-
-from gymnasium import spaces
-from gymnasium.utils import seeding
-
-
-def check_if_no_duplicate(duplicate_list: list) -> bool:
-    """Check if given list contains any duplicates"""
-    return len(set(duplicate_list)) == len(duplicate_list)
-
-
-class MissionSpace(spaces.Space[str]):
-    r"""A space representing a mission for the Gym-Minigrid environments.
-    The space allows generating random mission strings constructed with an input placeholder list.
-    Example Usage::
-        >>> observation_space = MissionSpace(mission_func=lambda color: f"Get the {color} ball.",
-        ...                                  ordered_placeholders=[["green", "blue"]])
-        >>> _ = observation_space.seed(123)
-        >>> observation_space.sample()
-        'Get the green ball.'
-        >>> observation_space = MissionSpace(mission_func=lambda : "Get the ball.",
-        ...                                  ordered_placeholders=None)
-        >>> observation_space.sample()
-        'Get the ball.'
-    """
-
-    def __init__(
-        self,
-        mission_func: Callable[..., str],
-        ordered_placeholders: list[list[str]] | None = None,
-        seed: int | seeding.RandomNumberGenerator | None = None,
-    ):
-        r"""Constructor of :class:`MissionSpace` space.
-
-        Args:
-            mission_func (lambda _placeholders(str): _mission(str)): Function that generates a mission string from random placeholders.
-            ordered_placeholders (Optional["list[list[str]]"]): List of lists of placeholders ordered in placing order in the mission function mission_func.
-            seed: seed: The seed for sampling from the space.
-        """
-        # Check that the ordered placeholders and mission function are well defined.
-        if ordered_placeholders is not None:
-            assert (
-                len(ordered_placeholders) == mission_func.__code__.co_argcount
-            ), f"The number of placeholders {len(ordered_placeholders)} is different from the number of parameters in the mission function {mission_func.__code__.co_argcount}."
-            for placeholder_list in ordered_placeholders:
-                assert check_if_no_duplicate(
-                    placeholder_list
-                ), "Make sure that the placeholders don't have any duplicate values."
-        else:
-            assert (
-                mission_func.__code__.co_argcount == 0
-            ), f"If the ordered placeholders are {ordered_placeholders}, the mission function shouldn't have any parameters."
-
-        self.ordered_placeholders = ordered_placeholders
-        self.mission_func = mission_func
-
-        super().__init__(dtype=str, seed=seed)
-
-        # Check that mission_func returns a string
-        sampled_mission = self.sample()
-        assert isinstance(
-            sampled_mission, str
-        ), f"mission_func must return type str not {type(sampled_mission)}"
-
-    def sample(self) -> str:
-        """Sample a random mission string."""
-        if self.ordered_placeholders is not None:
-            placeholders = []
-            for rand_var_list in self.ordered_placeholders:
-                idx = self.np_random.integers(0, len(rand_var_list))
-
-                placeholders.append(rand_var_list[idx])
-
-            return self.mission_func(*placeholders)
-        else:
-            return self.mission_func()
-
-    def contains(self, x: Any) -> bool:
-        """Return boolean specifying if x is a valid member of this space."""
-        # Store a list of all the placeholders from self.ordered_placeholders that appear in x
-        if self.ordered_placeholders is not None:
-            check_placeholder_list = []
-            for placeholder_list in self.ordered_placeholders:
-                for placeholder in placeholder_list:
-                    if placeholder in x:
-                        check_placeholder_list.append(placeholder)
-
-            # Remove duplicates from the list
-            check_placeholder_list = list(set(check_placeholder_list))
-
-            start_id_placeholder = []
-            end_id_placeholder = []
-            # Get the starting and ending id of the identified placeholders with possible duplicates
-            new_check_placeholder_list = []
-            for placeholder in check_placeholder_list:
-                new_start_id_placeholder = [
-                    i for i in range(len(x)) if x.startswith(placeholder, i)
-                ]
-                new_check_placeholder_list += [placeholder] * len(
-                    new_start_id_placeholder
-                )
-                end_id_placeholder += [
-                    start_id + len(placeholder) - 1
-                    for start_id in new_start_id_placeholder
-                ]
-                start_id_placeholder += new_start_id_placeholder
-
-            # Order by starting id the placeholders
-            ordered_placeholder_list = sorted(
-                zip(
-                    start_id_placeholder, end_id_placeholder, new_check_placeholder_list
-                )
-            )
-
-            # Check for repeated placeholders contained in each other
-            remove_placeholder_id = []
-            for i, placeholder_1 in enumerate(ordered_placeholder_list):
-                starting_id = i + 1
-                for j, placeholder_2 in enumerate(
-                    ordered_placeholder_list[starting_id:]
-                ):
-                    # Check if place holder ids overlap and keep the longest
-                    if max(placeholder_1[0], placeholder_2[0]) < min(
-                        placeholder_1[1], placeholder_2[1]
-                    ):
-                        remove_placeholder = min(
-                            placeholder_1[2], placeholder_2[2], key=len
-                        )
-                        if remove_placeholder == placeholder_1[2]:
-                            remove_placeholder_id.append(i)
-                        else:
-                            remove_placeholder_id.append(i + j + 1)
-            for id in remove_placeholder_id:
-                del ordered_placeholder_list[id]
-
-            final_placeholders = [
-                placeholder[2] for placeholder in ordered_placeholder_list
-            ]
-
-            # Check that the identified final placeholders are in the same order as the original placeholders.
-            for orered_placeholder, final_placeholder in zip(
-                self.ordered_placeholders, final_placeholders
-            ):
-                if final_placeholder in orered_placeholder:
-                    continue
-                else:
-                    return False
-            try:
-                mission_string_with_placeholders = self.mission_func(
-                    *final_placeholders
-                )
-            except Exception as e:
-                print(
-                    f"{x} is not contained in MissionSpace due to the following exception: {e}"
-                )
-                return False
-
-            return bool(mission_string_with_placeholders == x)
-
-        else:
-            return bool(self.mission_func() == x)
-
-    def __repr__(self) -> str:
-        """Gives a string representation of this space."""
-        return f"MissionSpace({self.mission_func}, {self.ordered_placeholders})"
-
-    def __eq__(self, other) -> bool:
-        """Check whether ``other`` is equivalent to this instance."""
-        if isinstance(other, MissionSpace):
-
-            # Check that place holder lists are the same
-            if self.ordered_placeholders is not None:
-                # Check length
-                if (
-                    len(self.ordered_placeholders) == len(other.ordered_placeholders)
-                ) and (
-                    all(
-                        set(i) == set(j)
-                        for i, j in zip(
-                            self.ordered_placeholders, other.ordered_placeholders
-                        )
-                    )
-                ):
-                    # Check mission string is the same with dummy space placeholders
-                    test_placeholders = [""] * len(self.ordered_placeholders)
-                    mission = self.mission_func(*test_placeholders)
-                    other_mission = other.mission_func(*test_placeholders)
-                    return mission == other_mission
-            else:
-
-                # Check that other is also None
-                if other.ordered_placeholders is None:
-
-                    # Check mission string is the same
-                    mission = self.mission_func()
-                    other_mission = other.mission_func()
-                    return mission == other_mission
-
-        # If none of the statements above return then False
-        return False
diff --git a/rl-starter-files/Minigrid/minigrid/core/roomgrid.py b/rl-starter-files/Minigrid/minigrid/core/roomgrid.py
deleted file mode 100644
index c0ba6fb..0000000
--- a/rl-starter-files/Minigrid/minigrid/core/roomgrid.py
+++ /dev/null
@@ -1,438 +0,0 @@
-from __future__ import annotations
-
-import numpy as np
-
-from minigrid.core.constants import COLOR_NAMES
-from minigrid.core.grid import Grid
-from minigrid.core.world_object import Ball, Box, Door, Key, WorldObj
-from minigrid.minigrid_env import MiniGridEnv
-
-
-def reject_next_to(env: MiniGridEnv, pos: tuple[int, int]):
-    """
-    Function to filter out object positions that are right next to
-    the agent's starting point
-    """
-
-    sx, sy = env.agent_pos
-    x, y = pos
-    d = abs(sx - x) + abs(sy - y)
-    return d < 2
-
-
-class Room:
-    def __init__(self, top: tuple[int, int], size: tuple[int, int]):
-        # Top-left corner and size (tuples)
-        self.top = top
-        self.size = size
-
-        # List of door objects and door positions
-        # Order of the doors is right, down, left, up
-        self.doors: list[bool | Door | None] = [None] * 4
-        self.door_pos: list[tuple[int, int] | None] = [None] * 4
-
-        # List of rooms adjacent to this one
-        # Order of the neighbors is right, down, left, up
-        self.neighbors: list[Room | None] = [None] * 4
-
-        # Indicates if this room is behind a locked door
-        self.locked: bool = False
-
-        # List of objects contained
-        self.objs: list[WorldObj] = []
-
-    def rand_pos(self, env: MiniGridEnv) -> tuple[int, int]:
-        topX, topY = self.top
-        sizeX, sizeY = self.size
-        return env._randPos(topX + 1, topX + sizeX - 1, topY + 1, topY + sizeY - 1)
-
-    def pos_inside(self, x: int, y: int) -> bool:
-        """
-        Check if a position is within the bounds of this room
-        """
-
-        topX, topY = self.top
-        sizeX, sizeY = self.size
-
-        if x < topX or y < topY:
-            return False
-
-        if x >= topX + sizeX or y >= topY + sizeY:
-            return False
-
-        return True
-
-
-class RoomGrid(MiniGridEnv):
-    """
-    Environment with multiple rooms and random objects.
-    This is meant to serve as a base class for other environments.
-    """
-
-    def __init__(
-        self,
-        room_size: int = 7,
-        num_rows: int = 3,
-        num_cols: int = 3,
-        max_steps: int = 100,
-        agent_view_size: int = 7,
-        **kwargs,
-    ):
-        assert room_size > 0
-        assert room_size >= 3
-        assert num_rows > 0
-        assert num_cols > 0
-        self.room_size = room_size
-        self.num_rows = num_rows
-        self.num_cols = num_cols
-
-        height = (room_size - 1) * num_rows + 1
-        width = (room_size - 1) * num_cols + 1
-
-        # By default, this environment has no mission
-        self.mission = ""
-
-        super().__init__(
-            width=width,
-            height=height,
-            max_steps=max_steps,
-            see_through_walls=False,
-            agent_view_size=agent_view_size,
-            **kwargs,
-        )
-
-    def room_from_pos(self, x: int, y: int) -> Room:
-        """Get the room a given position maps to"""
-
-        assert x >= 0
-        assert y >= 0
-
-        i = x // (self.room_size - 1)
-        j = y // (self.room_size - 1)
-
-        assert i < self.num_cols
-        assert j < self.num_rows
-
-        return self.room_grid[j][i]
-
-    def get_room(self, i: int, j: int) -> Room:
-        assert i < self.num_cols
-        assert j < self.num_rows
-        return self.room_grid[j][i]
-
-    def _gen_grid(self, width, height):
-        # Create the grid
-        self.grid = Grid(width, height)
-
-        self.room_grid = []
-
-        # For each row of rooms
-        for j in range(0, self.num_rows):
-            row = []
-
-            # For each column of rooms
-            for i in range(0, self.num_cols):
-                room = Room(
-                    (i * (self.room_size - 1), j * (self.room_size - 1)),
-                    (self.room_size, self.room_size),
-                )
-                row.append(room)
-
-                # Generate the walls for this room
-                self.grid.wall_rect(*room.top, *room.size)
-
-            self.room_grid.append(row)
-
-        # For each row of rooms
-        for j in range(0, self.num_rows):
-            # For each column of rooms
-            for i in range(0, self.num_cols):
-                room = self.room_grid[j][i]
-
-                x_l, y_l = (room.top[0] + 1, room.top[1] + 1)
-                x_m, y_m = (
-                    room.top[0] + room.size[0] - 1,
-                    room.top[1] + room.size[1] - 1,
-                )
-
-                # Door positions, order is right, down, left, up
-                if i < self.num_cols - 1:
-                    room.neighbors[0] = self.room_grid[j][i + 1]
-                    room.door_pos[0] = (x_m, self._rand_int(y_l, y_m))
-                if j < self.num_rows - 1:
-                    room.neighbors[1] = self.room_grid[j + 1][i]
-                    room.door_pos[1] = (self._rand_int(x_l, x_m), y_m)
-                if i > 0:
-                    room.neighbors[2] = self.room_grid[j][i - 1]
-                    room.door_pos[2] = room.neighbors[2].door_pos[0]
-                if j > 0:
-                    room.neighbors[3] = self.room_grid[j - 1][i]
-                    room.door_pos[3] = room.neighbors[3].door_pos[1]
-
-        # The agent starts in the middle, facing right
-        self.agent_pos = np.array(
-            (
-                (self.num_cols // 2) * (self.room_size - 1) + (self.room_size // 2),
-                (self.num_rows // 2) * (self.room_size - 1) + (self.room_size // 2),
-            )
-        )
-        self.agent_dir = 0
-
-    def place_in_room(
-        self, i: int, j: int, obj: WorldObj
-    ) -> tuple[WorldObj, tuple[int, int]]:
-        """
-        Add an existing object to room (i, j)
-        """
-
-        room = self.get_room(i, j)
-
-        pos = self.place_obj(
-            obj, room.top, room.size, reject_fn=reject_next_to, max_tries=1000
-        )
-
-        room.objs.append(obj)
-
-        return obj, pos
-
-    def add_object(
-        self,
-        i: int,
-        j: int,
-        kind: str | None = None,
-        color: str | None = None,
-    ) -> tuple[WorldObj, tuple[int, int]]:
-        """
-        Add a new object to room (i, j)
-        """
-
-        if kind is None:
-            kind = self._rand_elem(["key", "ball", "box"])
-
-        if color is None:
-            color = self._rand_color()
-
-        # TODO: we probably want to add an Object.make helper function
-        assert kind in ["key", "ball", "box"]
-        if kind == "key":
-            obj = Key(color)
-        elif kind == "ball":
-            obj = Ball(color)
-        elif kind == "box":
-            obj = Box(color)
-        else:
-            raise ValueError(
-                f"{kind} object kind is not available in this environment."
-            )
-
-        return self.place_in_room(i, j, obj)
-
-    def add_door(
-        self,
-        i: int,
-        j: int,
-        door_idx: int | None = None,
-        color: str | None = None,
-        locked: bool | None = None,
-    ) -> tuple[Door, tuple[int, int]]:
-        """
-        Add a door to a room, connecting it to a neighbor
-        """
-
-        room = self.get_room(i, j)
-
-        if door_idx is None:
-            # Need to make sure that there is a neighbor along this wall
-            # and that there is not already a door
-            while True:
-                door_idx = self._rand_int(0, 4)
-                if room.neighbors[door_idx] and room.doors[door_idx] is None:
-                    break
-
-        if color is None:
-            color = self._rand_color()
-
-        if locked is None:
-            locked = self._rand_bool()
-
-        assert room.doors[door_idx] is None, "door already exists"
-
-        room.locked = locked
-        door = Door(color, is_locked=locked)
-
-        pos = room.door_pos[door_idx]
-        assert pos is not None
-        self.grid.set(pos[0], pos[1], door)
-        door.cur_pos = pos
-
-        assert door_idx is not None
-        neighbor = room.neighbors[door_idx]
-        assert neighbor is not None
-        room.doors[door_idx] = door
-        neighbor.doors[(door_idx + 2) % 4] = door
-
-        return door, pos
-
-    def remove_wall(self, i: int, j: int, wall_idx: int):
-        """
-        Remove a wall between two rooms
-        """
-
-        room = self.get_room(i, j)
-
-        assert 0 <= wall_idx < 4
-        assert room.doors[wall_idx] is None, "door exists on this wall"
-        assert room.neighbors[wall_idx], "invalid wall"
-
-        neighbor = room.neighbors[wall_idx]
-
-        tx, ty = room.top
-        w, h = room.size
-
-        # Ordering of walls is right, down, left, up
-        if wall_idx == 0:
-            for i in range(1, h - 1):
-                self.grid.set(tx + w - 1, ty + i, None)
-        elif wall_idx == 1:
-            for i in range(1, w - 1):
-                self.grid.set(tx + i, ty + h - 1, None)
-        elif wall_idx == 2:
-            for i in range(1, h - 1):
-                self.grid.set(tx, ty + i, None)
-        elif wall_idx == 3:
-            for i in range(1, w - 1):
-                self.grid.set(tx + i, ty, None)
-        else:
-            assert False, "invalid wall index"
-
-        # Mark the rooms as connected
-        room.doors[wall_idx] = True
-        assert neighbor is not None
-        neighbor.doors[(wall_idx + 2) % 4] = True
-
-    def place_agent(
-        self, i: int | None = None, j: int | None = None, rand_dir: bool = True
-    ) -> np.ndarray:
-        """
-        Place the agent in a room
-        """
-
-        if i is None:
-            i = self._rand_int(0, self.num_cols)
-        if j is None:
-            j = self._rand_int(0, self.num_rows)
-
-        room = self.room_grid[j][i]
-
-        # Find a position that is not right in front of an object
-        while True:
-            super().place_agent(room.top, room.size, rand_dir, max_tries=1000)
-            front_cell = self.grid.get(*self.front_pos)
-            if front_cell is None or front_cell.type == "wall":
-                break
-
-        return self.agent_pos
-
-    def connect_all(
-        self, door_colors: list[str] = COLOR_NAMES, max_itrs: int = 5000
-    ) -> list[Door]:
-        """
-        Make sure that all rooms are reachable by the agent from its
-        starting position
-        """
-
-        start_room = self.room_from_pos(*self.agent_pos)
-
-        added_doors = []
-
-        def find_reach():
-            reach = set()
-            stack = [start_room]
-            while len(stack) > 0:
-                room = stack.pop()
-                if room in reach:
-                    continue
-                reach.add(room)
-                for i in range(0, 4):
-                    if room.doors[i]:
-                        stack.append(room.neighbors[i])
-            return reach
-
-        num_itrs = 0
-
-        while True:
-            # This is to handle rare situations where random sampling produces
-            # a level that cannot be connected, producing in an infinite loop
-            if num_itrs > max_itrs:
-                raise RecursionError("connect_all failed")
-            num_itrs += 1
-
-            # If all rooms are reachable, stop
-            reach = find_reach()
-            if len(reach) == self.num_rows * self.num_cols:
-                break
-
-            # Pick a random room and door position
-            i = self._rand_int(0, self.num_cols)
-            j = self._rand_int(0, self.num_rows)
-            k = self._rand_int(0, 4)
-            room = self.get_room(i, j)
-
-            # If there is already a door there, skip
-            if not room.door_pos[k] or room.doors[k]:
-                continue
-
-            neighbor_room = room.neighbors[k]
-            assert neighbor_room is not None
-            if room.locked or neighbor_room.locked:
-                continue
-
-            color = self._rand_elem(door_colors)
-            door, _ = self.add_door(i, j, k, color, False)
-            added_doors.append(door)
-
-        return added_doors
-
-    def add_distractors(
-        self,
-        i: int | None = None,
-        j: int | None = None,
-        num_distractors: int = 10,
-        all_unique: bool = True,
-    ) -> list[WorldObj]:
-        """
-        Add random objects that can potentially distract/confuse the agent.
-        """
-
-        # Collect a list of existing objects
-        objs = []
-        for row in self.room_grid:
-            for room in row:
-                for obj in room.objs:
-                    objs.append((obj.type, obj.color))
-
-        # List of distractors added
-        dists = []
-
-        while len(dists) < num_distractors:
-            color = self._rand_elem(COLOR_NAMES)
-            type = self._rand_elem(["key", "ball", "box"])
-            obj = (type, color)
-
-            if all_unique and obj in objs:
-                continue
-
-            # Add the object to a random room if no room specified
-            room_i = i
-            room_j = j
-            if room_i is None:
-                room_i = self._rand_int(0, self.num_cols)
-            if room_j is None:
-                room_j = self._rand_int(0, self.num_rows)
-
-            dist, pos = self.add_object(room_i, room_j, *obj)
-
-            objs.append(obj)
-            dists.append(dist)
-
-        return dists
diff --git a/rl-starter-files/Minigrid/minigrid/core/world_object.py b/rl-starter-files/Minigrid/minigrid/core/world_object.py
deleted file mode 100644
index 592be95..0000000
--- a/rl-starter-files/Minigrid/minigrid/core/world_object.py
+++ /dev/null
@@ -1,294 +0,0 @@
-from __future__ import annotations
-
-from typing import TYPE_CHECKING, Tuple
-
-import numpy as np
-
-from minigrid.core.constants import (
-    COLOR_TO_IDX,
-    COLORS,
-    IDX_TO_COLOR,
-    IDX_TO_OBJECT,
-    OBJECT_TO_IDX,
-)
-from minigrid.utils.rendering import (
-    fill_coords,
-    point_in_circle,
-    point_in_line,
-    point_in_rect,
-)
-
-if TYPE_CHECKING:
-    from minigrid.minigrid_env import MiniGridEnv
-
-Point = Tuple[int, int]
-
-
-class WorldObj:
-
-    """
-    Base class for grid world objects
-    """
-
-    def __init__(self, type: str, color: str):
-        assert type in OBJECT_TO_IDX, type
-        assert color in COLOR_TO_IDX, color
-        self.type = type
-        self.color = color
-        self.contains = None
-
-        # Initial position of the object
-        self.init_pos: Point | None = None
-
-        # Current position of the object
-        self.cur_pos: Point | None = None
-
-    def can_overlap(self) -> bool:
-        """Can the agent overlap with this?"""
-        return False
-
-    def can_pickup(self) -> bool:
-        """Can the agent pick this up?"""
-        return False
-
-    def can_contain(self) -> bool:
-        """Can this contain another object?"""
-        return False
-
-    def see_behind(self) -> bool:
-        """Can the agent see behind this object?"""
-        return True
-
-    def toggle(self, env: MiniGridEnv, pos: tuple[int, int]) -> bool:
-        """Method to trigger/toggle an action this object performs"""
-        return False
-
-    def encode(self) -> tuple[int, int, int]:
-        """Encode the a description of this object as a 3-tuple of integers"""
-        return (OBJECT_TO_IDX[self.type], COLOR_TO_IDX[self.color], 0)
-
-    @staticmethod
-    def decode(type_idx: int, color_idx: int, state: int) -> WorldObj | None:
-        """Create an object from a 3-tuple state description"""
-
-        obj_type = IDX_TO_OBJECT[type_idx]
-        color = IDX_TO_COLOR[color_idx]
-
-        if obj_type == "empty" or obj_type == "unseen":
-            return None
-
-        # State, 0: open, 1: closed, 2: locked
-        is_open = state == 0
-        is_locked = state == 2
-
-        if obj_type == "wall":
-            v = Wall(color)
-        elif obj_type == "floor":
-            v = Floor(color)
-        elif obj_type == "ball":
-            v = Ball(color)
-        elif obj_type == "key":
-            v = Key(color)
-        elif obj_type == "box":
-            v = Box(color)
-        elif obj_type == "door":
-            v = Door(color, is_open, is_locked)
-        elif obj_type == "goal":
-            v = Goal()
-        elif obj_type == "lava":
-            v = Lava()
-        else:
-            assert False, "unknown object type in decode '%s'" % obj_type
-
-        return v
-
-    def render(self, r: np.ndarray) -> np.ndarray:
-        """Draw this object with the given renderer"""
-        raise NotImplementedError
-
-
-class Goal(WorldObj):
-    def __init__(self):
-        super().__init__("goal", "green")
-
-    def can_overlap(self):
-        return True
-
-    def render(self, img):
-        fill_coords(img, point_in_rect(0, 1, 0, 1), COLORS[self.color])
-
-
-class Floor(WorldObj):
-    """
-    Colored floor tile the agent can walk over
-    """
-
-    def __init__(self, color: str = "blue"):
-        super().__init__("floor", color)
-
-    def can_overlap(self):
-        return True
-
-    def render(self, img):
-        # Give the floor a pale color
-        color = COLORS[self.color] / 2
-        fill_coords(img, point_in_rect(0.031, 1, 0.031, 1), color)
-
-
-class Lava(WorldObj):
-    def __init__(self):
-        super().__init__("lava", "red")
-
-    def can_overlap(self):
-        return True
-
-    def render(self, img):
-        c = (255, 128, 0)
-
-        # Background color
-        fill_coords(img, point_in_rect(0, 1, 0, 1), c)
-
-        # Little waves
-        for i in range(3):
-            ylo = 0.3 + 0.2 * i
-            yhi = 0.4 + 0.2 * i
-            fill_coords(img, point_in_line(0.1, ylo, 0.3, yhi, r=0.03), (0, 0, 0))
-            fill_coords(img, point_in_line(0.3, yhi, 0.5, ylo, r=0.03), (0, 0, 0))
-            fill_coords(img, point_in_line(0.5, ylo, 0.7, yhi, r=0.03), (0, 0, 0))
-            fill_coords(img, point_in_line(0.7, yhi, 0.9, ylo, r=0.03), (0, 0, 0))
-
-
-class Wall(WorldObj):
-    def __init__(self, color: str = "grey"):
-        super().__init__("wall", color)
-
-    def see_behind(self):
-        return False
-
-    def render(self, img):
-        fill_coords(img, point_in_rect(0, 1, 0, 1), COLORS[self.color])
-
-
-class Door(WorldObj):
-    def __init__(self, color: str, is_open: bool = False, is_locked: bool = False):
-        super().__init__("door", color)
-        self.is_open = is_open
-        self.is_locked = is_locked
-
-    def can_overlap(self):
-        """The agent can only walk over this cell when the door is open"""
-        return self.is_open
-
-    def see_behind(self):
-        return self.is_open
-
-    def toggle(self, env, pos):
-        # If the player has the right key to open the door
-        if self.is_locked:
-            if isinstance(env.carrying, Key) and env.carrying.color == self.color:
-                self.is_locked = False
-                self.is_open = True
-                return True
-            return False
-
-        self.is_open = not self.is_open
-        return True
-
-    def encode(self):
-        """Encode the a description of this object as a 3-tuple of integers"""
-
-        # State, 0: open, 1: closed, 2: locked
-        if self.is_open:
-            state = 0
-        elif self.is_locked:
-            state = 2
-        # if door is closed and unlocked
-        elif not self.is_open:
-            state = 1
-        else:
-            raise ValueError(
-                f"There is no possible state encoding for the state:\n -Door Open: {self.is_open}\n -Door Closed: {not self.is_open}\n -Door Locked: {self.is_locked}"
-            )
-
-        return (OBJECT_TO_IDX[self.type], COLOR_TO_IDX[self.color], state)
-
-    def render(self, img):
-        c = COLORS[self.color]
-
-        if self.is_open:
-            fill_coords(img, point_in_rect(0.88, 1.00, 0.00, 1.00), c)
-            fill_coords(img, point_in_rect(0.92, 0.96, 0.04, 0.96), (0, 0, 0))
-            return
-
-        # Door frame and door
-        if self.is_locked:
-            fill_coords(img, point_in_rect(0.00, 1.00, 0.00, 1.00), c)
-            fill_coords(img, point_in_rect(0.06, 0.94, 0.06, 0.94), 0.45 * np.array(c))
-
-            # Draw key slot
-            fill_coords(img, point_in_rect(0.52, 0.75, 0.50, 0.56), c)
-        else:
-            fill_coords(img, point_in_rect(0.00, 1.00, 0.00, 1.00), c)
-            fill_coords(img, point_in_rect(0.04, 0.96, 0.04, 0.96), (0, 0, 0))
-            fill_coords(img, point_in_rect(0.08, 0.92, 0.08, 0.92), c)
-            fill_coords(img, point_in_rect(0.12, 0.88, 0.12, 0.88), (0, 0, 0))
-
-            # Draw door handle
-            fill_coords(img, point_in_circle(cx=0.75, cy=0.50, r=0.08), c)
-
-
-class Key(WorldObj):
-    def __init__(self, color: str = "blue"):
-        super().__init__("key", color)
-
-    def can_pickup(self):
-        return True
-
-    def render(self, img):
-        c = COLORS[self.color]
-
-        # Vertical quad
-        fill_coords(img, point_in_rect(0.50, 0.63, 0.31, 0.88), c)
-
-        # Teeth
-        fill_coords(img, point_in_rect(0.38, 0.50, 0.59, 0.66), c)
-        fill_coords(img, point_in_rect(0.38, 0.50, 0.81, 0.88), c)
-
-        # Ring
-        fill_coords(img, point_in_circle(cx=0.56, cy=0.28, r=0.190), c)
-        fill_coords(img, point_in_circle(cx=0.56, cy=0.28, r=0.064), (0, 0, 0))
-
-
-class Ball(WorldObj):
-    def __init__(self, color="blue"):
-        super().__init__("ball", color)
-
-    def can_pickup(self):
-        return True
-
-    def render(self, img):
-        fill_coords(img, point_in_circle(0.5, 0.5, 0.31), COLORS[self.color])
-
-
-class Box(WorldObj):
-    def __init__(self, color, contains: WorldObj | None = None):
-        super().__init__("box", color)
-        self.contains = contains
-
-    def can_pickup(self):
-        return True
-
-    def render(self, img):
-        c = COLORS[self.color]
-
-        # Outline
-        fill_coords(img, point_in_rect(0.12, 0.88, 0.12, 0.88), c)
-        fill_coords(img, point_in_rect(0.18, 0.82, 0.18, 0.82), (0, 0, 0))
-
-        # Horizontal slit
-        fill_coords(img, point_in_rect(0.16, 0.84, 0.47, 0.53), c)
-
-    def toggle(self, env, pos):
-        # Replace the box by its contents
-        env.grid.set(pos[0], pos[1], self.contains)
-        return True
diff --git a/rl-starter-files/Minigrid/minigrid/envs/__init__.py b/rl-starter-files/Minigrid/minigrid/envs/__init__.py
deleted file mode 100644
index 5401e71..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/__init__.py
+++ /dev/null
@@ -1,27 +0,0 @@
-from __future__ import annotations
-
-from minigrid.envs.blockedunlockpickup import BlockedUnlockPickupEnv
-from minigrid.envs.crossing import CrossingEnv
-from minigrid.envs.distshift import DistShiftEnv
-from minigrid.envs.doorkey import DoorKeyEnv
-from minigrid.envs.dynamicobstacles import DynamicObstaclesEnv
-from minigrid.envs.empty import EmptyEnv
-from minigrid.envs.fetch import FetchEnv
-from minigrid.envs.fourrooms import FourRoomsEnv
-from minigrid.envs.gotodoor import GoToDoorEnv
-from minigrid.envs.gotoobject import GoToObjectEnv
-from minigrid.envs.keycorridor import KeyCorridorEnv
-from minigrid.envs.lavagap import LavaGapEnv
-from minigrid.envs.lockedroom import LockedRoom, LockedRoomEnv
-from minigrid.envs.memory import MemoryEnv
-from minigrid.envs.multiroom import MultiRoom, MultiRoomEnv
-from minigrid.envs.obstructedmaze import (
-    ObstructedMaze_1Dlhb,
-    ObstructedMaze_Full,
-    ObstructedMazeEnv,
-)
-from minigrid.envs.playground import PlaygroundEnv
-from minigrid.envs.putnear import PutNearEnv
-from minigrid.envs.redbluedoors import RedBlueDoorEnv
-from minigrid.envs.unlock import UnlockEnv
-from minigrid.envs.unlockpickup import UnlockPickupEnv
diff --git a/rl-starter-files/Minigrid/minigrid/envs/babyai/__init__.py b/rl-starter-files/Minigrid/minigrid/envs/babyai/__init__.py
deleted file mode 100644
index fb39fbf..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/babyai/__init__.py
+++ /dev/null
@@ -1,53 +0,0 @@
-from __future__ import annotations
-
-from minigrid.envs.babyai.goto import (
-    GoTo,
-    GoToDoor,
-    GoToImpUnlock,
-    GoToLocal,
-    GoToObj,
-    GoToObjDoor,
-    GoToRedBall,
-    GoToRedBallGrey,
-    GoToRedBallNoDists,
-    GoToRedBlueBall,
-    GoToSeq,
-)
-from minigrid.envs.babyai.open import (
-    Open,
-    OpenDoor,
-    OpenDoorsOrder,
-    OpenRedDoor,
-    OpenTwoDoors,
-)
-from minigrid.envs.babyai.other import (
-    ActionObjDoor,
-    FindObjS5,
-    KeyCorridor,
-    MoveTwoAcross,
-    OneRoomS8,
-)
-from minigrid.envs.babyai.pickup import (
-    Pickup,
-    PickupAbove,
-    PickupDist,
-    PickupLoc,
-    UnblockPickup,
-)
-from minigrid.envs.babyai.putnext import PutNext, PutNextLocal
-from minigrid.envs.babyai.synth import (
-    BossLevel,
-    BossLevelNoUnlock,
-    MiniBossLevel,
-    Synth,
-    SynthLoc,
-    SynthSeq,
-)
-from minigrid.envs.babyai.unlock import (
-    BlockedUnlockPickup,
-    KeyInBox,
-    Unlock,
-    UnlockLocal,
-    UnlockPickup,
-    UnlockToUnlock,
-)
diff --git a/rl-starter-files/Minigrid/minigrid/envs/babyai/core/__init__.py b/rl-starter-files/Minigrid/minigrid/envs/babyai/core/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/rl-starter-files/Minigrid/minigrid/envs/babyai/core/levelgen.py b/rl-starter-files/Minigrid/minigrid/envs/babyai/core/levelgen.py
deleted file mode 100644
index f99c2e3..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/babyai/core/levelgen.py
+++ /dev/null
@@ -1,210 +0,0 @@
-"""
-Copied and adapted from https://github.com/mila-iqia/babyai
-"""
-from __future__ import annotations
-
-from minigrid.core.constants import COLOR_NAMES
-from minigrid.core.roomgrid import Room
-from minigrid.envs.babyai.core.roomgrid_level import RoomGridLevel
-from minigrid.envs.babyai.core.verifier import (
-    LOC_NAMES,
-    OBJ_TYPES,
-    OBJ_TYPES_NOT_DOOR,
-    AfterInstr,
-    AndInstr,
-    BeforeInstr,
-    GoToInstr,
-    ObjDesc,
-    OpenInstr,
-    PickupInstr,
-    PutNextInstr,
-)
-
-
-class LevelGen(RoomGridLevel):
-    """
-    Level generator which attempts to produce every possible sentence in
-    the baby language as an instruction.
-    """
-
-    def __init__(
-        self,
-        room_size=8,
-        num_rows=3,
-        num_cols=3,
-        num_dists=18,
-        locked_room_prob=0.5,
-        locations=True,
-        unblocking=True,
-        implicit_unlock=True,
-        action_kinds=["goto", "pickup", "open", "putnext"],
-        instr_kinds=["action", "and", "seq"],
-        **kwargs,
-    ):
-        self.num_dists = num_dists
-        self.locked_room_prob = locked_room_prob
-        self.locations = locations
-        self.unblocking = unblocking
-        self.implicit_unlock = implicit_unlock
-        self.action_kinds = action_kinds
-        self.instr_kinds = instr_kinds
-
-        self.locked_room = None
-
-        super().__init__(
-            room_size=room_size, num_rows=num_rows, num_cols=num_cols, **kwargs
-        )
-
-    def gen_mission(self):
-        if self._rand_float(0, 1) < self.locked_room_prob:
-            self.add_locked_room()
-
-        self.connect_all()
-
-        self.add_distractors(num_distractors=self.num_dists, all_unique=False)
-
-        # The agent must be placed after all the object to respect constraints
-        while True:
-            self.place_agent()
-            start_room = self.room_from_pos(*self.agent_pos)
-            # Ensure that we are not placing the agent in the locked room
-            if start_room is self.locked_room:
-                continue
-            break
-
-        # If no unblocking required, make sure all objects are
-        # reachable without unblocking
-        if not self.unblocking:
-            self.check_objs_reachable()
-
-        # Generate random instructions
-        self.instrs = self.rand_instr(
-            action_kinds=self.action_kinds, instr_kinds=self.instr_kinds
-        )
-
-    def add_locked_room(self):
-        # Until we've successfully added a locked room
-        while True:
-            i = self._rand_int(0, self.num_cols)
-            j = self._rand_int(0, self.num_rows)
-            door_idx = self._rand_int(0, 4)
-            self.locked_room = self.get_room(i, j)
-
-            # Don't add a locked door in an external wall
-            if self.locked_room.neighbors[door_idx] is None:
-                continue
-
-            door, _ = self.add_door(i, j, door_idx, locked=True)
-
-            # Done adding locked room
-            break
-
-        # Until we find a room to put the key
-        while True:
-            i = self._rand_int(0, self.num_cols)
-            j = self._rand_int(0, self.num_rows)
-            key_room = self.get_room(i, j)
-
-            if key_room is self.locked_room:
-                continue
-
-            self.add_object(i, j, "key", door.color)
-            break
-
-    def rand_obj(self, types=OBJ_TYPES, colors=COLOR_NAMES, max_tries=100):
-        """
-        Generate a random object descriptor
-        """
-
-        num_tries = 0
-
-        # Keep trying until we find a matching object
-        while True:
-            if num_tries > max_tries:
-                raise RecursionError("failed to find suitable object")
-            num_tries += 1
-
-            color = self._rand_elem([None, *colors])
-            type = self._rand_elem(types)
-
-            loc = None
-            if self.locations and self._rand_bool():
-                loc = self._rand_elem(LOC_NAMES)
-
-            desc = ObjDesc(type, color, loc)
-
-            # Find all objects matching the descriptor
-            objs, poss = desc.find_matching_objs(self)
-
-            # The description must match at least one object
-            if len(objs) == 0:
-                continue
-
-            # If no implicit unlocking is required
-            if not self.implicit_unlock and isinstance(self.locked_room, Room):
-                locked_room = self.locked_room
-                # Check that at least one object is not in the locked room
-                pos_not_locked = list(
-                    filter(lambda p: not locked_room.pos_inside(*p), poss)
-                )
-
-                if len(pos_not_locked) == 0:
-                    continue
-
-            # Found a valid object description
-            return desc
-
-    def rand_instr(self, action_kinds, instr_kinds, depth=0):
-        """
-        Generate random instructions
-        """
-
-        kind = self._rand_elem(instr_kinds)
-
-        if kind == "action":
-            action = self._rand_elem(action_kinds)
-
-            if action == "goto":
-                return GoToInstr(self.rand_obj())
-            elif action == "pickup":
-                return PickupInstr(self.rand_obj(types=OBJ_TYPES_NOT_DOOR))
-            elif action == "open":
-                return OpenInstr(self.rand_obj(types=["door"]))
-            elif action == "putnext":
-                return PutNextInstr(
-                    self.rand_obj(types=OBJ_TYPES_NOT_DOOR), self.rand_obj()
-                )
-
-            assert False
-
-        elif kind == "and":
-            instr_a = self.rand_instr(
-                action_kinds=action_kinds, instr_kinds=["action"], depth=depth + 1
-            )
-            instr_b = self.rand_instr(
-                action_kinds=action_kinds, instr_kinds=["action"], depth=depth + 1
-            )
-            return AndInstr(instr_a, instr_b)
-
-        elif kind == "seq":
-            instr_a = self.rand_instr(
-                action_kinds=action_kinds,
-                instr_kinds=["action", "and"],
-                depth=depth + 1,
-            )
-            instr_b = self.rand_instr(
-                action_kinds=action_kinds,
-                instr_kinds=["action", "and"],
-                depth=depth + 1,
-            )
-
-            kind = self._rand_elem(["before", "after"])
-
-            if kind == "before":
-                return BeforeInstr(instr_a, instr_b)
-            elif kind == "after":
-                return AfterInstr(instr_a, instr_b)
-
-            assert False
-
-        assert False
diff --git a/rl-starter-files/Minigrid/minigrid/envs/babyai/core/roomgrid_level.py b/rl-starter-files/Minigrid/minigrid/envs/babyai/core/roomgrid_level.py
deleted file mode 100644
index 7de73c6..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/babyai/core/roomgrid_level.py
+++ /dev/null
@@ -1,301 +0,0 @@
-"""
-Copied and adapted from https://github.com/mila-iqia/babyai
-"""
-from __future__ import annotations
-
-from minigrid.core.roomgrid import RoomGrid
-from minigrid.envs.babyai.core.verifier import (
-    ActionInstr,
-    AfterInstr,
-    AndInstr,
-    BeforeInstr,
-    PutNextInstr,
-    SeqInstr,
-)
-from minigrid.minigrid_env import MissionSpace
-
-
-class RejectSampling(Exception):
-    """
-    Exception used for rejection sampling
-    """
-
-    pass
-
-
-class BabyAIMissionSpace(MissionSpace):
-    """
-    Class that mimics the behavior required by minigrid.minigrid_env.MissionSpace,
-    but does not change how missions are generated for BabyAI. It silences
-    the gymnasium.utils.passive_env_checker given that it considers all strings to be
-    plausible samples.
-    """
-
-    def __init__(self):
-        super().__init__(mission_func=self._gen_mission)
-
-    @staticmethod
-    def _gen_mission():
-        return "go"
-
-    def contains(self, x: str):
-        return True
-
-
-class RoomGridLevel(RoomGrid):
-    """
-    Base for levels based on RoomGrid.
-    A level, generates missions generated from
-    one or more patterns. Levels should produce a family of missions
-    of approximately similar difficulty.
-    """
-
-    def __init__(self, room_size=8, max_steps: int | None = None, **kwargs):
-        mission_space = BabyAIMissionSpace()
-
-        # If `max_steps` arg is passed it will be fixed for every episode,
-        # if not it will vary after reset depending on the maze size.
-        self.fixed_max_steps = False
-        if max_steps is not None:
-            self.fixed_max_steps = True
-        else:
-            max_steps = 0  # only for initialization
-        super().__init__(
-            room_size=room_size,
-            mission_space=mission_space,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    def reset(self, **kwargs):
-        obs = super().reset(**kwargs)
-
-        # Recreate the verifier
-        self.instrs.reset_verifier(self)
-
-        # Compute the time step limit based on the maze size and instructions
-        nav_time_room = self.room_size**2
-        nav_time_maze = nav_time_room * self.num_rows * self.num_cols
-        num_navs = self.num_navs_needed(self.instrs)
-
-        if not self.fixed_max_steps:
-            self.max_steps = num_navs * nav_time_maze
-
-        return obs
-
-    def step(self, action):
-        obs, reward, terminated, truncated, info = super().step(action)
-
-        # If we drop an object, we need to update its position in the environment
-        if action == self.actions.drop:
-            self.update_objs_poss()
-
-        # If we've successfully completed the mission
-        status = self.instrs.verify(action)
-
-        if status == "success":
-            terminated = True
-            reward = self._reward()
-        elif status == "failure":
-            terminated = True
-            reward = 0
-
-        return obs, reward, terminated, truncated, info
-
-    def update_objs_poss(self, instr=None):
-        if instr is None:
-            instr = self.instrs
-        if (
-            isinstance(instr, BeforeInstr)
-            or isinstance(instr, AndInstr)
-            or isinstance(instr, AfterInstr)
-        ):
-            self.update_objs_poss(instr.instr_a)
-            self.update_objs_poss(instr.instr_b)
-        else:
-            instr.update_objs_poss()
-
-    def _gen_grid(self, width, height):
-        # We catch RecursionError to deal with rare cases where
-        # rejection sampling gets stuck in an infinite loop
-        while True:
-            try:
-                super()._gen_grid(width, height)
-
-                # Generate the mission
-                self.gen_mission()
-
-                # Validate the instructions
-                self.validate_instrs(self.instrs)
-
-            except RecursionError as error:
-                print("Timeout during mission generation:", error)
-                continue
-
-            except RejectSampling as error:
-                print("Sampling rejected:", error)
-                continue
-
-            break
-
-        # Generate the surface form for the instructions
-        self.surface = self.instrs.surface(self)
-        self.mission = self.surface
-
-    def validate_instrs(self, instr):
-        """
-        Perform some validation on the generated instructions
-        """
-        # Gather the colors of locked doors
-        colors_of_locked_doors = []
-        if hasattr(self, "unblocking") and self.unblocking:
-            for i in range(self.num_cols):
-                for j in range(self.num_rows):
-                    room = self.get_room(i, j)
-                    for door in room.doors:
-                        if door and door.is_locked:
-                            colors_of_locked_doors.append(door.color)
-
-        if isinstance(instr, PutNextInstr):
-            # Resolve the objects referenced by the instruction
-            instr.reset_verifier(self)
-
-            # Check that the objects are not already next to each other
-            if set(instr.desc_move.obj_set).intersection(set(instr.desc_fixed.obj_set)):
-                raise RejectSampling(
-                    "there are objects that match both lhs and rhs of PutNext"
-                )
-            if instr.objs_next():
-                raise RejectSampling("objs already next to each other")
-
-            # Check that we are not asking to move an object next to itself
-            move = instr.desc_move
-            fixed = instr.desc_fixed
-            if len(move.obj_set) == 1 and len(fixed.obj_set) == 1:
-                if move.obj_set[0] is fixed.obj_set[0]:
-                    raise RejectSampling("cannot move an object next to itself")
-
-        if isinstance(instr, ActionInstr):
-            if not hasattr(self, "unblocking") or not self.unblocking:
-                return
-            # TODO: either relax this a bit or make the bot handle this super corner-y scenarios
-            # Check that the instruction doesn't involve a key that matches the color of a locked door
-            potential_objects = ("desc", "desc_move", "desc_fixed")
-            for attr in potential_objects:
-                if hasattr(instr, attr):
-                    obj = getattr(instr, attr)
-                    if obj.type == "key" and obj.color in colors_of_locked_doors:
-                        raise RejectSampling(
-                            "cannot do anything with/to a key that can be used to open a door"
-                        )
-            return
-
-        if isinstance(instr, SeqInstr):
-            self.validate_instrs(instr.instr_a)
-            self.validate_instrs(instr.instr_b)
-            return
-
-        assert False, "unhandled instruction type"
-
-    def gen_mission(self):
-        """
-        Generate a mission (instructions and matching environment)
-        Derived level classes should implement this method
-        """
-        raise NotImplementedError
-
-    @property
-    def level_name(self):
-        return self.__class__.level_name
-
-    @property
-    def gym_id(self):
-        return self.__class__.gym_id
-
-    def num_navs_needed(self, instr) -> int:
-        """
-        Compute the maximum number of navigations needed to perform
-        a simple or complex instruction
-        """
-
-        if isinstance(instr, PutNextInstr):
-            return 2
-
-        elif isinstance(instr, ActionInstr):
-            return 1
-
-        elif isinstance(instr, SeqInstr):
-            na = self.num_navs_needed(instr.instr_a)
-            nb = self.num_navs_needed(instr.instr_b)
-            return na + nb
-
-        else:
-            raise NotImplementedError(
-                "instr needs to be an instance of PutNextInstr, ActionInstr, or SeqInstr"
-            )
-
-    def open_all_doors(self):
-        """
-        Open all the doors in the maze
-        """
-
-        for i in range(self.num_cols):
-            for j in range(self.num_rows):
-                room = self.get_room(i, j)
-                for door in room.doors:
-                    if door:
-                        door.is_open = True
-
-    def check_objs_reachable(self, raise_exc=True):
-        """
-        Check that all objects are reachable from the agent's starting
-        position without requiring any other object to be moved
-        (without unblocking)
-        """
-
-        # Reachable positions
-        reachable = set()
-
-        # Work list
-        stack = [self.agent_pos]
-
-        while len(stack) > 0:
-            i, j = stack.pop()
-
-            if i < 0 or i >= self.grid.width or j < 0 or j >= self.grid.height:
-                continue
-
-            if (i, j) in reachable:
-                continue
-
-            # This position is reachable
-            reachable.add((i, j))
-
-            cell = self.grid.get(i, j)
-
-            # If there is something other than a door in this cell, it
-            # blocks reachability
-            if cell and cell.type != "door":
-                continue
-
-            # Visit the horizontal and vertical neighbors
-            stack.append((i + 1, j))
-            stack.append((i - 1, j))
-            stack.append((i, j + 1))
-            stack.append((i, j - 1))
-
-        # Check that all objects are reachable
-        for i in range(self.grid.width):
-            for j in range(self.grid.height):
-                cell = self.grid.get(i, j)
-
-                if not cell or cell.type == "wall":
-                    continue
-
-                if (i, j) not in reachable:
-                    if not raise_exc:
-                        return False
-                    raise RejectSampling("unreachable object at " + str((i, j)))
-
-        # All objects reachable
-        return True
diff --git a/rl-starter-files/Minigrid/minigrid/envs/babyai/core/verifier.py b/rl-starter-files/Minigrid/minigrid/envs/babyai/core/verifier.py
deleted file mode 100644
index 260ff94..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/babyai/core/verifier.py
+++ /dev/null
@@ -1,566 +0,0 @@
-"""
-Copied and adapted from https://github.com/mila-iqia/babyai
-"""
-from __future__ import annotations
-
-import os
-from abc import ABC, abstractmethod
-
-import numpy as np
-
-from minigrid.core.constants import COLOR_NAMES, DIR_TO_VEC
-from minigrid.minigrid_env import MiniGridEnv
-
-# Object types we are allowed to describe in language
-OBJ_TYPES = ["box", "ball", "key", "door"]
-
-# Object types we are allowed to describe in language
-OBJ_TYPES_NOT_DOOR = list(filter(lambda t: t != "door", OBJ_TYPES))
-
-# Locations are all relative to the agent's starting position
-LOC_NAMES = ["left", "right", "front", "behind"]
-
-# Environment flag to indicate that done actions should be
-# used by the verifier
-use_done_actions = os.environ.get("BABYAI_DONE_ACTIONS", False)
-
-
-def dot_product(v1, v2):
-    """
-    Compute the dot product of the vectors v1 and v2.
-    """
-
-    return sum(i * j for i, j in zip(v1, v2))
-
-
-def pos_next_to(pos_a, pos_b):
-    """
-    Test if two positions are next to each other.
-    The positions have to line up either horizontally or vertically,
-    but positions that are diagonally adjacent are not counted.
-    """
-
-    xa, ya = pos_a
-    xb, yb = pos_b
-    d = abs(xa - xb) + abs(ya - yb)
-    return d == 1
-
-
-class ObjDesc:
-    """
-    Description of a set of objects in an environment
-    """
-
-    def __init__(self, type, color=None, loc=None):
-        assert type in [None, *OBJ_TYPES], type
-        assert color in [None, *COLOR_NAMES], color
-        assert loc in [None, *LOC_NAMES], loc
-
-        self.color = color
-        self.type = type
-        self.loc = loc
-
-        # Set of objects possibly matching the description
-        self.obj_set = []
-
-        # Set of initial object positions
-        self.obj_poss = []
-
-    def __repr__(self):
-        return f"{self.color} {self.type} {self.loc}"
-
-    def surface(self, env):
-        """
-        Generate a natural language representation of the object description
-        """
-
-        self.find_matching_objs(env)
-        assert len(self.obj_set) > 0, "no object matching description"
-
-        if self.type:
-            s = str(self.type)
-        else:
-            s = "object"
-
-        if self.color:
-            s = self.color + " " + s
-
-        if self.loc:
-            if self.loc == "front":
-                s = s + " in front of you"
-            elif self.loc == "behind":
-                s = s + " behind you"
-            else:
-                s = s + " on your " + self.loc
-
-        # Singular vs plural
-        if len(self.obj_set) > 1:
-            s = "a " + s
-        else:
-            s = "the " + s
-
-        return s
-
-    def find_matching_objs(self, env, use_location=True):
-        """
-        Find the set of objects matching the description and their positions.
-        When use_location is False, we only update the positions of already tracked objects, without taking into account
-        the location of the object. e.g. A ball that was on "your right" initially will still be tracked as being "on
-        your right" when you move.
-        """
-
-        if use_location:
-            self.obj_set = []
-            # otherwise we keep the same obj_set
-
-        self.obj_poss = []
-
-        agent_room = env.room_from_pos(*env.agent_pos)
-
-        for i in range(env.grid.width):
-            for j in range(env.grid.height):
-                cell = env.grid.get(i, j)
-                if cell is None:
-                    continue
-
-                if not use_location:
-                    # we should keep tracking the same objects initially tracked only
-                    already_tracked = any([cell is obj for obj in self.obj_set])
-                    if not already_tracked:
-                        continue
-
-                # Check if object's type matches description
-                if self.type is not None and cell.type != self.type:
-                    continue
-
-                # Check if object's color matches description
-                if self.color is not None and cell.color != self.color:
-                    continue
-
-                # Check if object's position matches description
-                if use_location and self.loc in ["left", "right", "front", "behind"]:
-                    # Locations apply only to objects in the same room
-                    # the agent starts in
-                    if not agent_room.pos_inside(i, j):
-                        continue
-
-                    # Direction from the agent to the object
-                    v = (i - env.agent_pos[0], j - env.agent_pos[1])
-
-                    # (d1, d2) is an oriented orthonormal basis
-                    d1 = DIR_TO_VEC[env.agent_dir]
-                    d2 = (-d1[1], d1[0])
-
-                    # Check if object's position matches with location
-                    pos_matches = {
-                        "left": dot_product(v, d2) < 0,
-                        "right": dot_product(v, d2) > 0,
-                        "front": dot_product(v, d1) > 0,
-                        "behind": dot_product(v, d1) < 0,
-                    }
-
-                    if not (pos_matches[self.loc]):
-                        continue
-
-                if use_location:
-                    self.obj_set.append(cell)
-                self.obj_poss.append((i, j))
-
-        return self.obj_set, self.obj_poss
-
-
-class Instr(ABC):
-    """
-    Base class for all instructions in the baby language
-    """
-
-    def __init__(self):
-        self.env: MiniGridEnv
-
-    @abstractmethod
-    def surface(self, env):
-        """
-        Produce a natural language representation of the instruction
-        """
-
-        raise NotImplementedError
-
-    def reset_verifier(self, env):
-        """
-        Must be called at the beginning of the episode
-        """
-
-        self.env = env
-
-    @abstractmethod
-    def verify(self, action):
-        """
-        Verify if the task described by the instruction is incomplete,
-        complete with success or failed. The return value is a string,
-        one of: 'success', 'failure' or 'continue'.
-        """
-
-        raise NotImplementedError
-
-    def update_objs_poss(self):
-        """
-        Update the position of objects present in the instruction if needed
-        """
-        potential_objects = ("desc", "desc_move", "desc_fixed")
-        for attr in potential_objects:
-            if hasattr(self, attr):
-                getattr(self, attr).find_matching_objs(self.env, use_location=False)
-
-
-class ActionInstr(Instr, ABC):
-    """
-    Base class for all action instructions (clauses)
-    """
-
-    def __init__(self):
-        super().__init__()
-
-        # Indicates that the action was completed on the last step
-        self.lastStepMatch = False
-
-    def verify(self, action):
-        """
-        Verifies actions, with and without the done action.
-        """
-
-        if not use_done_actions:
-            return self.verify_action(action)
-
-        if action == self.env.actions.done:
-            if self.lastStepMatch:
-                return "success"
-            return "failure"
-
-        res = self.verify_action(action)
-        self.lastStepMatch = res == "success"
-
-    @abstractmethod
-    def verify_action(self):
-        """
-        Each action instruction class should implement this method
-        to verify the action.
-        """
-
-        raise NotImplementedError
-
-
-class OpenInstr(ActionInstr):
-    def __init__(self, obj_desc, strict=False):
-        super().__init__()
-        assert obj_desc.type == "door"
-        self.desc = obj_desc
-        self.strict = strict
-
-    def surface(self, env):
-        return "open " + self.desc.surface(env)
-
-    def reset_verifier(self, env):
-        super().reset_verifier(env)
-
-        # Identify set of possible matching objects in the environment
-        self.desc.find_matching_objs(env)
-
-    def verify_action(self, action):
-        # Only verify when the toggle action is performed
-        if action != self.env.actions.toggle:
-            return "continue"
-
-        # Get the contents of the cell in front of the agent
-        front_cell = self.env.grid.get(*self.env.front_pos)
-
-        for door in self.desc.obj_set:
-            if front_cell and front_cell is door and door.is_open:
-                return "success"
-
-        # If in strict mode and the wrong door is opened, failure
-        if self.strict:
-            if front_cell and front_cell.type == "door":
-                return "failure"
-
-        return "continue"
-
-
-class GoToInstr(ActionInstr):
-    """
-    Go next to (and look towards) an object matching a given description
-    eg: go to the door
-    """
-
-    def __init__(self, obj_desc):
-        super().__init__()
-        self.desc = obj_desc
-
-    def surface(self, env):
-        return "go to " + self.desc.surface(env)
-
-    def reset_verifier(self, env):
-        super().reset_verifier(env)
-
-        # Identify set of possible matching objects in the environment
-        self.desc.find_matching_objs(env)
-
-    def verify_action(self, action):
-        # For each object position
-        for pos in self.desc.obj_poss:
-            # If the agent is next to (and facing) the object
-            if np.array_equal(pos, self.env.front_pos):
-                return "success"
-
-        return "continue"
-
-
-class PickupInstr(ActionInstr):
-    """
-    Pick up an object matching a given description
-    eg: pick up the grey ball
-    """
-
-    def __init__(self, obj_desc, strict=False):
-        super().__init__()
-        assert obj_desc.type != "door"
-        self.desc = obj_desc
-        self.strict = strict
-
-    def surface(self, env):
-        return "pick up " + self.desc.surface(env)
-
-    def reset_verifier(self, env):
-        super().reset_verifier(env)
-
-        # Object previously being carried
-        self.preCarrying = None
-
-        # Identify set of possible matching objects in the environment
-        self.desc.find_matching_objs(env)
-
-    def verify_action(self, action):
-        # To keep track of what was carried at the last time step
-        preCarrying = self.preCarrying
-        self.preCarrying = self.env.carrying
-
-        # Only verify when the pickup action is performed
-        if action != self.env.actions.pickup:
-            return "continue"
-
-        for obj in self.desc.obj_set:
-            if preCarrying is None and self.env.carrying is obj:
-                return "success"
-
-        # If in strict mode and the wrong door object is picked up, failure
-        if self.strict:
-            if self.env.carrying:
-                return "failure"
-
-        self.preCarrying = self.env.carrying
-
-        return "continue"
-
-
-class PutNextInstr(ActionInstr):
-    """
-    Put an object next to another object
-    eg: put the red ball next to the blue key
-    """
-
-    def __init__(self, obj_move, obj_fixed, strict=False):
-        super().__init__()
-        assert obj_move.type != "door"
-        self.desc_move = obj_move
-        self.desc_fixed = obj_fixed
-        self.strict = strict
-
-    def surface(self, env):
-        return (
-            "put "
-            + self.desc_move.surface(env)
-            + " next to "
-            + self.desc_fixed.surface(env)
-        )
-
-    def reset_verifier(self, env):
-        super().reset_verifier(env)
-
-        # Object previously being carried
-        self.preCarrying = None
-
-        # Identify set of possible matching objects in the environment
-        self.desc_move.find_matching_objs(env)
-        self.desc_fixed.find_matching_objs(env)
-
-    def objs_next(self):
-        """
-        Check if the objects are next to each other
-        This is used for rejection sampling
-        """
-
-        for obj_a in self.desc_move.obj_set:
-            pos_a = obj_a.cur_pos
-
-            for pos_b in self.desc_fixed.obj_poss:
-                if pos_next_to(pos_a, pos_b):
-                    return True
-        return False
-
-    def verify_action(self, action):
-        # To keep track of what was carried at the last time step
-        preCarrying = self.preCarrying
-        self.preCarrying = self.env.carrying
-
-        # In strict mode, picking up the wrong object fails
-        if self.strict:
-            if action == self.env.actions.pickup and self.env.carrying:
-                return "failure"
-
-        # Only verify when the drop action is performed
-        if action != self.env.actions.drop:
-            return "continue"
-
-        for obj_a in self.desc_move.obj_set:
-            if preCarrying is not obj_a:
-                continue
-
-            pos_a = obj_a.cur_pos
-
-            for pos_b in self.desc_fixed.obj_poss:
-                if pos_next_to(pos_a, pos_b):
-                    return "success"
-
-        return "continue"
-
-
-class SeqInstr(Instr, ABC):
-    """
-    Base class for sequencing instructions (before, after, and)
-    """
-
-    def __init__(self, instr_a, instr_b, strict=False):
-        assert isinstance(instr_a, ActionInstr) or isinstance(instr_a, AndInstr)
-        assert isinstance(instr_b, ActionInstr) or isinstance(instr_b, AndInstr)
-        self.instr_a = instr_a
-        self.instr_b = instr_b
-        self.strict = strict
-
-
-class BeforeInstr(SeqInstr):
-    """
-    Sequence two instructions in order:
-    eg: go to the red door then pick up the blue ball
-    """
-
-    def surface(self, env):
-        return self.instr_a.surface(env) + ", then " + self.instr_b.surface(env)
-
-    def reset_verifier(self, env):
-        super().reset_verifier(env)
-        self.instr_a.reset_verifier(env)
-        self.instr_b.reset_verifier(env)
-        self.a_done = False
-        self.b_done = False
-
-    def verify(self, action):
-        if self.a_done == "success":
-            self.b_done = self.instr_b.verify(action)
-
-            if self.b_done == "failure":
-                return "failure"
-
-            if self.b_done == "success":
-                return "success"
-        else:
-            self.a_done = self.instr_a.verify(action)
-            if self.a_done == "failure":
-                return "failure"
-
-            if self.a_done == "success":
-                return self.verify(action)
-
-            # In strict mode, completing b first means failure
-            if self.strict:
-                if self.instr_b.verify(action) == "success":
-                    return "failure"
-
-        return "continue"
-
-
-class AfterInstr(SeqInstr):
-    """
-    Sequence two instructions in reverse order:
-    eg: go to the red door after you pick up the blue ball
-    """
-
-    def surface(self, env):
-        return self.instr_a.surface(env) + " after you " + self.instr_b.surface(env)
-
-    def reset_verifier(self, env):
-        super().reset_verifier(env)
-        self.instr_a.reset_verifier(env)
-        self.instr_b.reset_verifier(env)
-        self.a_done = False
-        self.b_done = False
-
-    def verify(self, action):
-        if self.b_done == "success":
-            self.a_done = self.instr_a.verify(action)
-
-            if self.a_done == "success":
-                return "success"
-
-            if self.a_done == "failure":
-                return "failure"
-        else:
-            self.b_done = self.instr_b.verify(action)
-            if self.b_done == "failure":
-                return "failure"
-
-            if self.b_done == "success":
-                return self.verify(action)
-
-            # In strict mode, completing a first means failure
-            if self.strict:
-                if self.instr_a.verify(action) == "success":
-                    return "failure"
-
-        return "continue"
-
-
-class AndInstr(SeqInstr):
-    """
-    Conjunction of two actions, both can be completed in any other
-    eg: go to the red door and pick up the blue ball
-    """
-
-    def __init__(self, instr_a, instr_b, strict=False):
-        assert isinstance(instr_a, ActionInstr)
-        assert isinstance(instr_b, ActionInstr)
-        super().__init__(instr_a, instr_b, strict)
-
-    def surface(self, env):
-        return self.instr_a.surface(env) + " and " + self.instr_b.surface(env)
-
-    def reset_verifier(self, env):
-        super().reset_verifier(env)
-        self.instr_a.reset_verifier(env)
-        self.instr_b.reset_verifier(env)
-        self.a_done = False
-        self.b_done = False
-
-    def verify(self, action):
-        if self.a_done != "success":
-            self.a_done = self.instr_a.verify(action)
-
-        if self.b_done != "success":
-            self.b_done = self.instr_b.verify(action)
-
-        if use_done_actions and action is self.env.actions.done:
-            if self.a_done == "failure" and self.b_done == "failure":
-                return "failure"
-
-        if self.a_done == "success" and self.b_done == "success":
-            return "success"
-
-        return "continue"
diff --git a/rl-starter-files/Minigrid/minigrid/envs/babyai/goto.py b/rl-starter-files/Minigrid/minigrid/envs/babyai/goto.py
deleted file mode 100644
index 59f987c..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/babyai/goto.py
+++ /dev/null
@@ -1,812 +0,0 @@
-"""
-Copied and adapted from https://github.com/mila-iqia/babyai.
-Levels described in the Baby AI ICLR 2019 submission, with the `Go to` instruction.
-"""
-from __future__ import annotations
-
-from minigrid.envs.babyai.core.levelgen import LevelGen
-from minigrid.envs.babyai.core.roomgrid_level import RejectSampling, RoomGridLevel
-from minigrid.envs.babyai.core.verifier import GoToInstr, ObjDesc
-
-
-class GoToRedBallGrey(RoomGridLevel):
-    """
-
-    ## Description
-
-    Go to the red ball, single room, with distractors.
-    The distractors are all grey to reduce perceptual complexity.
-    This level has distractors but doesn't make use of language.
-
-    ## Mission Space
-
-    "go to the red ball"
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent goes to the red ball.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-GoToRedBallGrey-v0`
-
-    """
-
-    def __init__(self, room_size=8, num_dists=7, **kwargs):
-        self.num_dists = num_dists
-        super().__init__(num_rows=1, num_cols=1, room_size=room_size, **kwargs)
-
-    def gen_mission(self):
-        self.place_agent()
-        obj, _ = self.add_object(0, 0, "ball", "red")
-        dists = self.add_distractors(num_distractors=self.num_dists, all_unique=False)
-
-        for dist in dists:
-            dist.color = "grey"
-
-        # Make sure no unblocking is required
-        self.check_objs_reachable()
-
-        self.instrs = GoToInstr(ObjDesc(obj.type, obj.color))
-
-
-class GoToRedBall(RoomGridLevel):
-    """
-    ## Description
-
-    Go to the red ball, single room, with distractors.
-    This level has distractors but doesn't make use of language.
-
-    ## Mission Space
-
-    "go to the red ball"
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent goes to the red ball.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-GoToRedBall-v0`
-
-    """
-
-    def __init__(self, room_size=8, num_dists=7, **kwargs):
-        self.num_dists = num_dists
-        super().__init__(num_rows=1, num_cols=1, room_size=room_size, **kwargs)
-
-    def gen_mission(self):
-        self.place_agent()
-        obj, _ = self.add_object(0, 0, "ball", "red")
-        self.add_distractors(num_distractors=self.num_dists, all_unique=False)
-
-        # Make sure no unblocking is required
-        self.check_objs_reachable()
-
-        self.instrs = GoToInstr(ObjDesc(obj.type, obj.color))
-
-
-class GoToRedBallNoDists(GoToRedBall):
-    """
-
-    ## Description
-
-    Go to the red ball. No distractors present.
-
-    ## Mission Space
-
-    "go to the red ball"
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent goes to the red ball.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-GoToRedBallNoDists-v0`
-
-    """
-
-    def __init__(self, **kwargs):
-        super().__init__(room_size=8, num_dists=0, **kwargs)
-
-
-class GoToObj(RoomGridLevel):
-    """
-    ## Description
-
-    Go to an object, inside a single room with no doors, no distractors. The
-    naming convention `GoToObjS{X}` represents a room of size `X`.
-
-    ## Mission Space
-
-    "go to the {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent goes to the object.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-GoToObj-v0`
-    - `BabyAI-GoToObjS4-v0`
-    - `BabyAI-GoToObjS6-v0`
-
-    """
-
-    def __init__(self, room_size=8, **kwargs):
-        super().__init__(num_rows=1, num_cols=1, room_size=room_size, **kwargs)
-
-    def gen_mission(self):
-        self.place_agent()
-        objs = self.add_distractors(num_distractors=1)
-        obj = objs[0]
-        self.instrs = GoToInstr(ObjDesc(obj.type, obj.color))
-
-
-class GoToLocal(RoomGridLevel):
-    """
-
-    ## Description
-
-    Go to an object, inside a single room with no doors, no distractors. The
-    naming convention `GoToLocalS{X}N{Y}` represents a room of size `X` with
-    distractor number `Y`.
-
-    ## Mission Space
-
-    "go to the {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent goes to the object.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-GoToLocal-v0`
-    - `BabyAI-GoToLocalS5N2-v0`
-    - `BabyAI-GoToLocalS6N2-v0`
-    - `BabyAI-GoToLocalS6N3-v0`
-    - `BabyAI-GoToLocalS6N4-v0`
-    - `BabyAI-GoToLocalS7N4-v0`
-    - `BabyAI-GoToLocalS7N5-v0`
-    - `BabyAI-GoToLocalS8N2-v0`
-    - `BabyAI-GoToLocalS8N3-v0`
-    - `BabyAI-GoToLocalS8N4-v0`
-    - `BabyAI-GoToLocalS8N5-v0`
-    - `BabyAI-GoToLocalS8N6-v0`
-    - `BabyAI-GoToLocalS8N7-v0`
-    """
-
-    def __init__(self, room_size=8, num_dists=8, **kwargs):
-        self.num_dists = num_dists
-        super().__init__(num_rows=1, num_cols=1, room_size=room_size, **kwargs)
-
-    def gen_mission(self):
-        self.place_agent()
-        objs = self.add_distractors(num_distractors=self.num_dists, all_unique=False)
-        self.check_objs_reachable()
-        obj = self._rand_elem(objs)
-        self.instrs = GoToInstr(ObjDesc(obj.type, obj.color))
-
-
-class GoTo(RoomGridLevel):
-    """
-
-    ## Description
-
-    Go to an object, the object may be in another room. Many distractors.
-
-    ## Mission Space
-
-    "go to a/the {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent goes to the object.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-GoTo-v0`
-    - `BabyAI-GoToOpen-v0`
-    - `BabyAI-GoToObjMaze-v0`
-    - `BabyAI-GoToObjMazeOpen-v0`
-    - `BabyAI-GoToObjMazeS4R2-v0`
-    - `BabyAI-GoToObjMazeS4-v0`
-    - `BabyAI-GoToObjMazeS5-v0`
-    - `BabyAI-GoToObjMazeS6-v0`
-    - `BabyAI-GoToObjMazeS7-v0`
-    """
-
-    def __init__(
-        self,
-        room_size=8,
-        num_rows=3,
-        num_cols=3,
-        num_dists=18,
-        doors_open=False,
-        **kwargs,
-    ):
-        self.num_dists = num_dists
-        self.doors_open = doors_open
-        super().__init__(
-            num_rows=num_rows, num_cols=num_cols, room_size=room_size, **kwargs
-        )
-
-    def gen_mission(self):
-        self.place_agent()
-        self.connect_all()
-        objs = self.add_distractors(num_distractors=self.num_dists, all_unique=False)
-        self.check_objs_reachable()
-        obj = self._rand_elem(objs)
-        self.instrs = GoToInstr(ObjDesc(obj.type, obj.color))
-
-        # If requested, open all the doors
-        if self.doors_open:
-            self.open_all_doors()
-
-
-class GoToImpUnlock(RoomGridLevel):
-    """
-
-    ## Description
-
-    Go to an object, which may be in a locked room.
-    Competencies: Maze, GoTo, ImpUnlock
-    No unblocking.
-
-    ## Mission Space
-
-    "go to a/the {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent goes to the object.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-GoToImpUnlock-v0`
-
-    """
-
-    def gen_mission(self):
-        # Add a locked door to a random room
-        id = self._rand_int(0, self.num_cols)
-        jd = self._rand_int(0, self.num_rows)
-        door, pos = self.add_door(id, jd, locked=True)
-        locked_room = self.get_room(id, jd)
-
-        # Add the key to a different room
-        while True:
-            ik = self._rand_int(0, self.num_cols)
-            jk = self._rand_int(0, self.num_rows)
-            if ik is id and jk is jd:
-                continue
-            self.add_object(ik, jk, "key", door.color)
-            break
-
-        self.connect_all()
-
-        # Add distractors to all but the locked room.
-        # We do this to speed up the reachability test,
-        # which otherwise will reject all levels with
-        # objects in the locked room.
-        for i in range(self.num_cols):
-            for j in range(self.num_rows):
-                if i is not id or j is not jd:
-                    self.add_distractors(i, j, num_distractors=2, all_unique=False)
-
-        # The agent must be placed after all the object to respect constraints
-        while True:
-            self.place_agent()
-            start_room = self.room_from_pos(*self.agent_pos)
-            # Ensure that we are not placing the agent in the locked room
-            if start_room is locked_room:
-                continue
-            break
-
-        self.check_objs_reachable()
-
-        # Add a single object to the locked room
-        # The instruction requires going to an object matching that description
-        (obj,) = self.add_distractors(id, jd, num_distractors=1, all_unique=False)
-        self.instrs = GoToInstr(ObjDesc(obj.type, obj.color))
-
-
-class GoToSeq(LevelGen):
-    """
-
-    ## Description
-
-    Sequencing of go-to-object commands.
-
-    Competencies: Maze, GoTo, Seq
-    No locked room.
-    No locations.
-    No unblocking.
-
-    ## Mission Space
-
-    "go to a/the {color} {type}" +
-    "and go to a/the {color} {type}" +
-    ", then go to a/the {color} {type}" +
-    "and go to a/the {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent goes to the object.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-GoToSeq-v0`
-    - `BabyAI-GoToSeqS5R2-v0`
-
-    """
-
-    def __init__(self, room_size=8, num_rows=3, num_cols=3, num_dists=18, **kwargs):
-        super().__init__(
-            room_size=room_size,
-            num_rows=num_rows,
-            num_cols=num_cols,
-            num_dists=num_dists,
-            action_kinds=["goto"],
-            locked_room_prob=0,
-            locations=False,
-            unblocking=False,
-            **kwargs,
-        )
-
-
-class GoToRedBlueBall(RoomGridLevel):
-    """
-
-    ## Description
-
-    Go to the red ball or to the blue ball.
-    There is exactly one red or blue ball, and some distractors.
-    The distractors are guaranteed not to be red or blue balls.
-    Language is not required to solve this level.
-
-    ## Mission Space
-
-    "go to the {color} ball"
-
-    {color} is the color of the box. Can be "red" or "blue".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent goes to the ball.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-GoToRedBlueBall-v0`
-
-    """
-
-    def __init__(self, room_size=8, num_dists=7, **kwargs):
-        self.num_dists = num_dists
-        super().__init__(num_rows=1, num_cols=1, room_size=room_size, **kwargs)
-
-    def gen_mission(self):
-        self.place_agent()
-
-        dists = self.add_distractors(num_distractors=self.num_dists, all_unique=False)
-
-        # Ensure there is only one red or blue ball
-        for dist in dists:
-            if dist.type == "ball" and (dist.color == "blue" or dist.color == "red"):
-                raise RejectSampling("can only have one blue or red ball")
-
-        color = self._rand_elem(["red", "blue"])
-        obj, _ = self.add_object(0, 0, "ball", color)
-
-        # Make sure no unblocking is required
-        self.check_objs_reachable()
-
-        self.instrs = GoToInstr(ObjDesc(obj.type, obj.color))
-
-
-class GoToDoor(RoomGridLevel):
-    """
-
-    ## Description
-
-    Go to a door
-    (of a given color, in the current room)
-    No distractors, no language variation
-
-    ## Mission Space
-
-    "go to the {color} door"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent goes to the door.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-GoToDoor-v0`
-
-    """
-
-    def __init__(self, **kwargs):
-        super().__init__(room_size=7, **kwargs)
-
-    def gen_mission(self):
-        objs = []
-        for _ in range(4):
-            door, _ = self.add_door(1, 1)
-            objs.append(door)
-        self.place_agent(1, 1)
-
-        obj = self._rand_elem(objs)
-        self.instrs = GoToInstr(ObjDesc("door", obj.color))
-
-
-class GoToObjDoor(RoomGridLevel):
-    """
-
-    ## Description
-
-    Go to an object or door
-    (of a given type and color, in the current room)
-
-    ## Mission Space
-
-    "go to the {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box", "key" or "door".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent goes to the object or door.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-GoToObjDoor-v0`
-
-    """
-
-    def __init__(self, **kwargs):
-        super().__init__(room_size=8, **kwargs)
-
-    def gen_mission(self):
-        self.place_agent(1, 1)
-        objs = self.add_distractors(1, 1, num_distractors=8, all_unique=False)
-
-        for _ in range(4):
-            door, _ = self.add_door(1, 1)
-            objs.append(door)
-
-        self.check_objs_reachable()
-
-        obj = self._rand_elem(objs)
-        self.instrs = GoToInstr(ObjDesc(obj.type, obj.color))
diff --git a/rl-starter-files/Minigrid/minigrid/envs/babyai/open.py b/rl-starter-files/Minigrid/minigrid/envs/babyai/open.py
deleted file mode 100644
index 0e27fd2..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/babyai/open.py
+++ /dev/null
@@ -1,422 +0,0 @@
-"""
-Copied and adapted from https://github.com/mila-iqia/babyai.
-Levels described in the Baby AI ICLR 2019 submission, with the `Open` instruction.
-"""
-from __future__ import annotations
-
-from minigrid.core.constants import COLOR_NAMES
-from minigrid.envs.babyai.core.roomgrid_level import RoomGridLevel
-from minigrid.envs.babyai.core.verifier import (
-    LOC_NAMES,
-    AfterInstr,
-    BeforeInstr,
-    ObjDesc,
-    OpenInstr,
-)
-
-
-class Open(RoomGridLevel):
-    """
-
-    ## Description
-
-    Open a door, which may be in another room
-
-    ## Mission Space
-
-    "open a {color} door"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent opens the door.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-Open-v0`
-
-    """
-
-    def gen_mission(self):
-        self.place_agent()
-        self.connect_all()
-        self.add_distractors(num_distractors=18, all_unique=False)
-        self.check_objs_reachable()
-
-        # Collect a list of all the doors in the environment
-        doors = []
-        for i in range(self.num_cols):
-            for j in range(self.num_rows):
-                room = self.get_room(i, j)
-                for door in room.doors:
-                    if door:
-                        doors.append(door)
-
-        door = self._rand_elem(doors)
-        self.instrs = OpenInstr(ObjDesc(door.type, door.color))
-
-
-class OpenRedDoor(RoomGridLevel):
-    """
-
-    ## Description
-
-    Go to the red door
-    (always unlocked, in the current room)
-    Note: this level is intentionally meant for debugging and is
-    intentionally kept very simple.
-
-    ## Mission Space
-
-    "open the red door"
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent opens the door.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-OpenRedDoor-v0`
-
-    """
-
-    def __init__(self, **kwargs):
-        super().__init__(num_rows=1, num_cols=2, room_size=5, **kwargs)
-
-    def gen_mission(self):
-        obj, _ = self.add_door(0, 0, 0, "red", locked=False)
-        self.place_agent(0, 0)
-        self.instrs = OpenInstr(ObjDesc("door", "red"))
-
-
-class OpenDoor(RoomGridLevel):
-    """
-
-    ## Description
-
-    Go to the door
-    The door to open is given by its color or by its location.
-    (always unlocked, in the current room)
-
-    ## Mission Space
-
-    "open the {color} door"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent opens the door.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-OpenDoor-v0`
-    - `BabyAI-OpenDoorDebug-v0`
-    - `BabyAI-OpenDoorColor-v0`
-    - `BabyAI-OpenDoorLoc-v0`
-
-    """
-
-    def __init__(self, debug=False, select_by=None, **kwargs):
-        self.select_by = select_by
-        self.debug = debug
-        super().__init__(**kwargs)
-
-    def gen_mission(self):
-        door_colors = self._rand_subset(COLOR_NAMES, 4)
-        objs = []
-
-        for i, color in enumerate(door_colors):
-            obj, _ = self.add_door(1, 1, door_idx=i, color=color, locked=False)
-            objs.append(obj)
-
-        select_by = self.select_by
-        if select_by is None:
-            select_by = self._rand_elem(["color", "loc"])
-        if select_by == "color":
-            object = ObjDesc(objs[0].type, color=objs[0].color)
-        elif select_by == "loc":
-            object = ObjDesc(objs[0].type, loc=self._rand_elem(LOC_NAMES))
-        else:
-            raise NotImplementedError("Not implemented.")
-
-        self.place_agent(1, 1)
-        self.instrs = OpenInstr(object, strict=self.debug)
-
-
-class OpenTwoDoors(RoomGridLevel):
-    """
-
-    ## Description
-
-    Open door X, then open door Y
-    The two doors are facing opposite directions, so that the agent
-    Can't see whether the door behind him is open.
-    This task requires memory (recurrent policy) to be solved effectively.
-
-    ## Mission Space
-
-    "open the {color} door, the open the {color} door"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent opens the door.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-OpenTwoDoors-v0`
-    - `BabyAI-OpenRedBlueDoors-v0`
-    - `BabyAI-OpenRedBlueDoorsDebug-v0`
-
-    """
-
-    def __init__(
-        self,
-        first_color=None,
-        second_color=None,
-        strict=False,
-        max_steps: int | None = None,
-        **kwargs,
-    ):
-        self.first_color = first_color
-        self.second_color = second_color
-        self.strict = strict
-
-        room_size = 6
-        if max_steps is None:
-            max_steps = 20 * room_size**2
-
-        super().__init__(room_size=room_size, max_steps=max_steps, **kwargs)
-
-    def gen_mission(self):
-        colors = self._rand_subset(COLOR_NAMES, 2)
-
-        first_color = self.first_color
-        if first_color is None:
-            first_color = colors[0]
-        second_color = self.second_color
-        if second_color is None:
-            second_color = colors[1]
-
-        door1, _ = self.add_door(1, 1, 2, color=first_color, locked=False)
-        door2, _ = self.add_door(1, 1, 0, color=second_color, locked=False)
-
-        self.place_agent(1, 1)
-
-        self.instrs = BeforeInstr(
-            OpenInstr(ObjDesc(door1.type, door1.color), strict=self.strict),
-            OpenInstr(ObjDesc(door2.type, door2.color)),
-        )
-
-
-class OpenDoorsOrder(RoomGridLevel):
-    """
-
-    ## Description
-
-    Open one or two doors in the order specified.
-
-    ## Mission Space
-
-    "open the {color} door, the open the {color} door"
-
-    or
-
-    "open the {color} door after you open the {color} door"
-
-    or
-
-    "open the {color} door"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent opens the door.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-OpenDoorsOrderN2-v0`
-    - `BabyAI-OpenDoorsOrderN4-v0`
-    - `BabyAI-OpenDoorsOrderN2Debug-v0`
-    - `BabyAI-OpenDoorsOrderN4Debug-v0`
-    """
-
-    def __init__(self, num_doors, debug=False, max_steps: int | None = None, **kwargs):
-        assert num_doors >= 2
-        self.num_doors = num_doors
-        self.debug = debug
-
-        room_size = 6
-        if max_steps is None:
-            max_steps = 20 * room_size**2
-
-        super().__init__(room_size=room_size, max_steps=max_steps, **kwargs)
-
-    def gen_mission(self):
-        colors = self._rand_subset(COLOR_NAMES, self.num_doors)
-        doors = []
-        for i in range(self.num_doors):
-            door, _ = self.add_door(1, 1, color=colors[i], locked=False)
-            doors.append(door)
-        self.place_agent(1, 1)
-
-        door1, door2 = self._rand_subset(doors, 2)
-        desc1 = ObjDesc(door1.type, door1.color)
-        desc2 = ObjDesc(door2.type, door2.color)
-
-        mode = self._rand_int(0, 3)
-        if mode == 0:
-            self.instrs = OpenInstr(desc1, strict=self.debug)
-        elif mode == 1:
-            self.instrs = BeforeInstr(
-                OpenInstr(desc1, strict=self.debug), OpenInstr(desc2, strict=self.debug)
-            )
-        elif mode == 2:
-            self.instrs = AfterInstr(
-                OpenInstr(desc1, strict=self.debug), OpenInstr(desc2, strict=self.debug)
-            )
-        else:
-            assert False
diff --git a/rl-starter-files/Minigrid/minigrid/envs/babyai/other.py b/rl-starter-files/Minigrid/minigrid/envs/babyai/other.py
deleted file mode 100644
index 0e29315..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/babyai/other.py
+++ /dev/null
@@ -1,426 +0,0 @@
-"""
-Copied and adapted from https://github.com/mila-iqia/babyai.
-Levels described in the Baby AI ICLR 2019 submission, with different instructions than those in other files.
-"""
-from __future__ import annotations
-
-from minigrid.envs.babyai.core.roomgrid_level import RoomGridLevel
-from minigrid.envs.babyai.core.verifier import (
-    BeforeInstr,
-    GoToInstr,
-    ObjDesc,
-    OpenInstr,
-    PickupInstr,
-    PutNextInstr,
-)
-
-
-class ActionObjDoor(RoomGridLevel):
-    """
-
-    ## Description
-
-    [pick up an object] or
-    [go to an object or door] or
-    [open a door]
-    (in the current room)
-
-    ## Mission Space
-
-    "pick up the {color} {type}"
-
-    or
-
-    "go to the {color} {type}"
-
-    or
-
-    "open a {color} door"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box", "door" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent finishes the instruction.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-ActionObjDoor-v0`
-
-    """
-
-    def __init__(self, **kwargs):
-        super().__init__(room_size=7, **kwargs)
-
-    def gen_mission(self):
-        objs = self.add_distractors(1, 1, num_distractors=5)
-        for _ in range(4):
-            door, _ = self.add_door(1, 1, locked=False)
-            objs.append(door)
-
-        self.place_agent(1, 1)
-
-        obj = self._rand_elem(objs)
-        desc = ObjDesc(obj.type, obj.color)
-
-        if obj.type == "door":
-            if self._rand_bool():
-                self.instrs = GoToInstr(desc)
-            else:
-                self.instrs = OpenInstr(desc)
-        else:
-            if self._rand_bool():
-                self.instrs = GoToInstr(desc)
-            else:
-                self.instrs = PickupInstr(desc)
-
-
-class FindObjS5(RoomGridLevel):
-    """
-
-    ## Description
-
-    Pick up an object (in a random room)
-    Rooms have a size of 5
-    This level requires potentially exhaustive exploration
-
-    ## Mission Space
-
-    "pick up the {type}"
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the object.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-FindObjS5-v0`
-    - `BabyAI-FindObjS6-v0`
-    - `BabyAI-FindObjS7-v0`
-
-    """
-
-    def __init__(self, room_size=5, max_steps: int | None = None, **kwargs):
-
-        if max_steps is None:
-            max_steps = 20 * room_size**2
-
-        super().__init__(room_size=room_size, max_steps=max_steps, **kwargs)
-
-    def gen_mission(self):
-        # Add a random object to a random room
-        i = self._rand_int(0, self.num_rows)
-        j = self._rand_int(0, self.num_cols)
-        obj, _ = self.add_object(i, j)
-        self.place_agent(1, 1)
-        self.connect_all()
-
-        self.instrs = PickupInstr(ObjDesc(obj.type))
-
-
-class KeyCorridor(RoomGridLevel):
-    """
-
-    ## Description
-
-    A ball is behind a locked door, the key is placed in a
-    random room.
-
-    ## Mission Space
-
-    "pick up the ball"
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the ball.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-KeyCorridor-v0`
-    - `BabyAI-KeyCorridorS3R1-v0`
-    - `BabyAI-KeyCorridorS3R2-v0`
-    - `BabyAI-KeyCorridorS3R3-v0`
-    - `BabyAI-KeyCorridorS4R3-v0`
-    - `BabyAI-KeyCorridorS5R3-v0`
-    - `BabyAI-KeyCorridorS6R3-v0`
-
-    """
-
-    def __init__(
-        self,
-        num_rows=3,
-        obj_type="ball",
-        room_size=6,
-        max_steps: int | None = None,
-        **kwargs,
-    ):
-        self.obj_type = obj_type
-
-        if max_steps is None:
-            max_steps = 30 * room_size**2
-
-        super().__init__(
-            room_size=room_size, num_rows=num_rows, max_steps=max_steps, **kwargs
-        )
-
-    def gen_mission(self):
-        # Connect the middle column rooms into a hallway
-        for j in range(1, self.num_rows):
-            self.remove_wall(1, j, 3)
-
-        # Add a locked door on the bottom right
-        # Add an object behind the locked door
-        room_idx = self._rand_int(0, self.num_rows)
-        door, _ = self.add_door(2, room_idx, 2, locked=True)
-        obj, _ = self.add_object(2, room_idx, kind=self.obj_type)
-
-        # Add a key in a random room on the left side
-        self.add_object(0, self._rand_int(0, self.num_rows), "key", door.color)
-
-        # Place the agent in the middle
-        self.place_agent(1, self.num_rows // 2)
-
-        # Make sure all rooms are accessible
-        self.connect_all()
-
-        self.instrs = PickupInstr(ObjDesc(obj.type))
-
-
-class OneRoomS8(RoomGridLevel):
-    """
-
-    ## Description
-
-    Pick up the ball. Rooms have a size of 8.
-
-    ## Mission Space
-
-    "pick up the ball"
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the ball.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-OneRoomS8-v0`
-    - `BabyAI-OneRoomS12-v0`
-    - `BabyAI-OneRoomS16-v0`
-    - `BabyAI-OneRoomS20-v0`
-
-    """
-
-    def __init__(self, room_size=8, **kwargs):
-        super().__init__(room_size=room_size, num_rows=1, num_cols=1, **kwargs)
-
-    def gen_mission(self):
-        obj, _ = self.add_object(0, 0, kind="ball")
-        self.place_agent()
-        self.instrs = PickupInstr(ObjDesc(obj.type))
-
-
-class MoveTwoAcross(RoomGridLevel):
-    """
-
-    ## Description
-
-    Task of the form: move the A next to the B and the C next to the D.
-    This task is structured to have a very large number of possible
-    instructions.
-
-    ## Mission Space
-
-    "put the {color} {type} next to the {color} {type}, then put the {color} {type} next to the {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent finishes the instruction.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-MoveTwoAcrossS5N2-v0`
-    - `BabyAI-MoveTwoAcrossS8N9-v0`
-
-    """
-
-    def __init__(
-        self, room_size, objs_per_room, max_steps: int | None = None, **kwargs
-    ):
-        assert objs_per_room <= 9
-        self.objs_per_room = objs_per_room
-
-        if max_steps is None:
-            max_steps = 16 * room_size**2
-
-        super().__init__(
-            num_rows=1, num_cols=2, room_size=room_size, max_steps=max_steps, **kwargs
-        )
-
-    def gen_mission(self):
-        self.place_agent(0, 0)
-
-        # Add objects to both the left and right rooms
-        # so that we know that we have two non-adjacent set of objects
-        objs_l = self.add_distractors(0, 0, self.objs_per_room)
-        objs_r = self.add_distractors(1, 0, self.objs_per_room)
-
-        # Remove the wall between the two rooms
-        self.remove_wall(0, 0, 0)
-
-        # Select objects from both subsets
-        objs_l = self._rand_subset(objs_l, 2)
-        objs_r = self._rand_subset(objs_r, 2)
-        a = objs_l[0]
-        b = objs_r[0]
-        c = objs_r[1]
-        d = objs_l[1]
-
-        self.instrs = BeforeInstr(
-            PutNextInstr(ObjDesc(a.type, a.color), ObjDesc(b.type, b.color)),
-            PutNextInstr(ObjDesc(c.type, c.color), ObjDesc(d.type, d.color)),
-        )
diff --git a/rl-starter-files/Minigrid/minigrid/envs/babyai/pickup.py b/rl-starter-files/Minigrid/minigrid/envs/babyai/pickup.py
deleted file mode 100644
index 81ca88d..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/babyai/pickup.py
+++ /dev/null
@@ -1,361 +0,0 @@
-"""
-Copied and adapted from https://github.com/mila-iqia/babyai.
-Levels described in the Baby AI ICLR 2019 submission, with the `Pick up` instruction.
-"""
-from __future__ import annotations
-
-from minigrid.envs.babyai.core.levelgen import LevelGen
-from minigrid.envs.babyai.core.roomgrid_level import RejectSampling, RoomGridLevel
-from minigrid.envs.babyai.core.verifier import ObjDesc, PickupInstr
-
-
-class Pickup(RoomGridLevel):
-    """
-
-    ## Description
-
-    Pick up an object, the object may be in another room.
-
-    ## Mission Space
-
-    "pick up a {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the object.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-Pickup-v0`
-
-    """
-
-    def gen_mission(self):
-        self.place_agent()
-        self.connect_all()
-        objs = self.add_distractors(num_distractors=18, all_unique=False)
-        self.check_objs_reachable()
-        obj = self._rand_elem(objs)
-        self.instrs = PickupInstr(ObjDesc(obj.type, obj.color))
-
-
-class UnblockPickup(RoomGridLevel):
-    """
-
-    ## Description
-
-    Pick up an object, the object may be in another room. The path may
-    be blocked by one or more obstructors.
-
-    ## Mission Space
-
-    "pick up a/the {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the object.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-UnblockPickup-v0`
-
-    """
-
-    def gen_mission(self):
-        self.place_agent()
-        self.connect_all()
-        objs = self.add_distractors(num_distractors=20, all_unique=False)
-
-        # Ensure that at least one object is not reachable without unblocking
-        # Note: the selected object will still be reachable most of the time
-        if self.check_objs_reachable(raise_exc=False):
-            raise RejectSampling("all objects reachable")
-
-        obj = self._rand_elem(objs)
-        self.instrs = PickupInstr(ObjDesc(obj.type, obj.color))
-
-
-class PickupLoc(LevelGen):
-    """
-
-    ## Description
-
-    Pick up an object which may be described using its location. This is a
-    single room environment.
-
-    Competencies: PickUp, Loc. No unblocking.
-
-    ## Mission Space
-
-    "pick up the {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the object.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-PickupLoc-v0`
-
-    """
-
-    def __init__(self, **kwargs):
-        # We add many distractors to increase the probability
-        # of ambiguous locations within the same room
-        super().__init__(
-            action_kinds=["pickup"],
-            instr_kinds=["action"],
-            num_rows=1,
-            num_cols=1,
-            num_dists=8,
-            locked_room_prob=0,
-            locations=True,
-            unblocking=False,
-            **kwargs,
-        )
-
-
-class PickupDist(RoomGridLevel):
-    """
-
-    ## Description
-
-    Pick up an object
-    The object to pick up is given by its type only, or
-    by its color, or by its type and color.
-    (in the current room, with distractors)
-
-    ## Mission Space
-
-    "pick up a/the {color}/{type}/{color}{type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the object.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-PickupDist-v0`
-    - `BabyAI-PickupDistDebug-v0`
-
-    """
-
-    def __init__(self, debug=False, **kwargs):
-        self.debug = debug
-        super().__init__(num_rows=1, num_cols=1, room_size=7, **kwargs)
-
-    def gen_mission(self):
-        # Add 5 random objects in the room
-        objs = self.add_distractors(num_distractors=5)
-        self.place_agent(0, 0)
-        obj = self._rand_elem(objs)
-        type = obj.type
-        color = obj.color
-
-        select_by = self._rand_elem(["type", "color", "both"])
-        if select_by == "color":
-            type = None
-        elif select_by == "type":
-            color = None
-
-        self.instrs = PickupInstr(ObjDesc(type, color), strict=self.debug)
-
-
-class PickupAbove(RoomGridLevel):
-    """
-
-    ## Description
-
-    Pick up an object (in the room above)
-    This task requires to use the compass to be solved effectively.
-
-    ## Mission Space
-
-    "go to the {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the object.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-PickupAbove-v0`
-
-    """
-
-    def __init__(self, max_steps: int | None = None, **kwargs):
-        room_size = 6
-        if max_steps is None:
-            max_steps = 8 * room_size**2
-
-        super().__init__(room_size=room_size, max_steps=max_steps, **kwargs)
-
-    def gen_mission(self):
-        # Add a random object to the top-middle room
-        obj, pos = self.add_object(1, 0)
-        # Make sure the two rooms are directly connected
-        self.add_door(1, 1, 3, locked=False)
-        self.place_agent(1, 1)
-        self.connect_all()
-
-        self.instrs = PickupInstr(ObjDesc(obj.type, obj.color))
diff --git a/rl-starter-files/Minigrid/minigrid/envs/babyai/putnext.py b/rl-starter-files/Minigrid/minigrid/envs/babyai/putnext.py
deleted file mode 100644
index 3e3ed0a..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/babyai/putnext.py
+++ /dev/null
@@ -1,198 +0,0 @@
-"""
-Copied and adapted from https://github.com/mila-iqia/babyai.
-Levels described in the Baby AI ICLR 2019 submission, with the `Put Next` instruction.
-"""
-from __future__ import annotations
-
-from minigrid.envs.babyai.core.roomgrid_level import RoomGridLevel
-from minigrid.envs.babyai.core.verifier import ObjDesc, PutNextInstr
-
-
-class PutNextLocal(RoomGridLevel):
-    """
-
-    ## Description
-
-    Put an object next to another object, inside a single room
-    with no doors, no distractors
-
-    ## Mission Space
-
-    "put the {color} {type} next to the {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent finishes the instructed task.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-PutNextLocal-v0`
-    - `BabyAI-PutNextLocalS5N3-v0`
-    - `BabyAI-PutNextLocalS6N4-v0``
-
-    """
-
-    def __init__(self, room_size=8, num_objs=8, **kwargs):
-        self.num_objs = num_objs
-        super().__init__(num_rows=1, num_cols=1, room_size=room_size, **kwargs)
-
-    def gen_mission(self):
-        self.place_agent()
-        objs = self.add_distractors(num_distractors=self.num_objs, all_unique=True)
-        self.check_objs_reachable()
-        o1, o2 = self._rand_subset(objs, 2)
-
-        self.instrs = PutNextInstr(
-            ObjDesc(o1.type, o1.color), ObjDesc(o2.type, o2.color)
-        )
-
-
-class PutNext(RoomGridLevel):
-    """
-
-    ## Description
-
-    Task of the form: move the A next to the B and the C next to the D.
-    This task is structured to have a very large number of possible
-    instructions.
-
-    ## Mission Space
-
-    "put the {color} {type} next to the {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent finishes the instructed task.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-PutNextS4N1-v0`
-    - `BabyAI-PutNextS5N2-v0`
-    - `BabyAI-PutNextS5N1-v0`
-    - `BabyAI-PutNextS6N3-v0`
-    - `BabyAI-PutNextS7N4-v0`
-    - `BabyAI-PutNextS5N2Carrying-v0`
-    - `BabyAI-PutNextS6N3Carrying-v0`
-    - `BabyAI-PutNextS7N4Carrying-v0`
-
-    """
-
-    def __init__(
-        self,
-        room_size,
-        objs_per_room,
-        start_carrying=False,
-        max_steps: int | None = None,
-        **kwargs,
-    ):
-        assert room_size >= 4
-        assert objs_per_room <= 9
-        self.objs_per_room = objs_per_room
-        self.start_carrying = start_carrying
-
-        if max_steps is None:
-            max_steps = 8 * room_size**2
-
-        super().__init__(
-            num_rows=1, num_cols=2, room_size=room_size, max_steps=max_steps, **kwargs
-        )
-
-    def gen_mission(self):
-        self.place_agent(0, 0)
-
-        # Add objects to both the left and right rooms
-        # so that we know that we have two non-adjacent set of objects
-        objs_l = self.add_distractors(0, 0, self.objs_per_room)
-        objs_r = self.add_distractors(1, 0, self.objs_per_room)
-
-        # Remove the wall between the two rooms
-        self.remove_wall(0, 0, 0)
-
-        # Select objects from both subsets
-        a = self._rand_elem(objs_l)
-        b = self._rand_elem(objs_r)
-
-        # Randomly flip the object to be moved
-        if self._rand_bool():
-            t = a
-            a = b
-            b = t
-
-        self.obj_a = a
-
-        self.instrs = PutNextInstr(ObjDesc(a.type, a.color), ObjDesc(b.type, b.color))
-
-    def reset(self, **kwargs):
-        obs = super().reset(**kwargs)
-
-        # If the agent starts off carrying the object
-        if self.start_carrying:
-            assert self.obj_a.init_pos is not None
-            self.grid.set(*self.obj_a.init_pos, None)
-            self.carrying = self.obj_a
-
-        return obs
diff --git a/rl-starter-files/Minigrid/minigrid/envs/babyai/synth.py b/rl-starter-files/Minigrid/minigrid/envs/babyai/synth.py
deleted file mode 100644
index 7f60c03..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/babyai/synth.py
+++ /dev/null
@@ -1,576 +0,0 @@
-"""
-Copied and adapted from https://github.com/mila-iqia/babyai.
-Levels described in the Baby AI ICLR 2019 submission.
-The instructions are a synthesis of those from `PutNext`, `Open`, `GoTo`, and `Pickup`.
-"""
-
-from __future__ import annotations
-
-from minigrid.envs.babyai.core.levelgen import LevelGen
-
-
-class Synth(LevelGen):
-    """
-
-    ## Description
-
-    Union of all instructions from PutNext, Open, Goto and PickUp.
-    The agent may need to move objects around. The agent may have
-    to unlock the door, but only if it is explicitly referred by
-    the instruction.
-
-    Competencies: Maze, Unblock, Unlock, GoTo, PickUp, PutNext, Open
-
-    ## Mission Space
-
-    "go to the {color} {type}"
-
-    or
-
-    "pick up a/the {color} {type}"
-
-    or
-
-    "open the {color} door"
-
-    or
-
-    "put the {color} {type} next to the {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent achieves the task.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-Synth-v0`
-    - `BabyAI-SynthS5R2-v0`
-
-    """
-
-    def __init__(self, room_size=8, num_rows=3, num_cols=3, num_dists=18, **kwargs):
-        # We add many distractors to increase the probability
-        # of ambiguous locations within the same room
-        super().__init__(
-            room_size=room_size,
-            num_rows=num_rows,
-            num_cols=num_cols,
-            num_dists=num_dists,
-            instr_kinds=["action"],
-            locations=False,
-            unblocking=True,
-            implicit_unlock=False,
-            **kwargs,
-        )
-
-
-class SynthLoc(LevelGen):
-    """
-
-    ## Description
-
-    Like Synth, but a significant share of object descriptions involves
-    location language like in PickUpLoc. No implicit unlocking.
-
-    Competencies: Maze, Unblock, Unlock, GoTo, PickUp, PutNext, Open, Loc
-
-    ## Mission Space
-
-    "go to the {color} {type} {location}"
-
-    or
-
-    "pick up a/the {color} {type} {location}"
-
-    or
-
-    "open the {color} door {location}"
-
-    or
-
-    "put the {color} {type} {location} next to the {color} {type} {location}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    {location} can be " ", "in front of you", "behind you", "on your left"
-    or "on your right"
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent achieves the task.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-SynthLoc-v0`
-    """
-
-    def __init__(self, **kwargs):
-        # We add many distractors to increase the probability
-        # of ambiguous locations within the same room
-        super().__init__(
-            instr_kinds=["action"],
-            locations=True,
-            unblocking=True,
-            implicit_unlock=False,
-            **kwargs,
-        )
-
-
-class SynthSeq(LevelGen):
-    """
-
-    ## Description
-
-    Like SynthLoc, but now with multiple commands, combined just like in GoToSeq.
-    No implicit unlocking.
-
-    Competencies: Maze, Unblock, Unlock, GoTo, PickUp, PutNext, Open, Loc, Seq
-
-    ## Mission Space
-
-    Action mission space:
-
-    "go to the {color} {type} {location}"
-
-    or
-
-    "pick up a/the {color} {type} {location}"
-
-    or
-
-    "open the {color} door {location}"
-
-    or
-
-    "put the {color} {type} {location} next to the {color} {type} {location}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    {location} can be " ", "in front of you", "behind you", "on your left"
-    or "on your right"
-
-    And mission space:
-
-    Two action missions concatenated with "and"
-
-    Example:
-
-    go to the green key
-    and
-    put the box next to the yellow ball
-
-    Sequence mission space:
-
-    Two missions, they can be action or and missions, concatenated with
-    ", then" or "after you".
-
-    Example:
-
-    open a red door and go to the ball on your left
-    after you
-    put the grey ball next to a door
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent achieves the task.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-SynthSeq-v0`
-
-    """
-
-    def __init__(self, **kwargs):
-        # We add many distractors to increase the probability
-        # of ambiguous locations within the same room
-        super().__init__(
-            locations=True, unblocking=True, implicit_unlock=False, **kwargs
-        )
-
-
-class MiniBossLevel(LevelGen):
-    """
-
-    ## Description
-
-    Command can be any sentence drawn from the Baby Language grammar.
-    Union of all competencies. This level is a superset of all other levels.
-    Compared to BossLevel this has a smaller room and a lower probability of
-    locked rooms.
-
-    ## Mission Space
-
-    Action mission space:
-
-    "go to the {color} {type} {location}"
-
-    or
-
-    "pick up a/the {color} {type} {location}"
-
-    or
-
-    "open the {color} door {location}"
-
-    or
-
-    "put the {color} {type} {location} next to the {color} {type} {location}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    {location} can be " ", "in front of you", "behind you", "on your left"
-    or "on your right"
-
-    And mission space:
-
-    Two action missions concatenated with "and"
-
-    Example:
-
-    go to the green key
-    and
-    put the box next to the yellow ball
-
-    Sequence mission space:
-
-    Two missions, they can be action or and missions, concatenated with
-    ", then" or "after you".
-
-    Example:
-
-    open a red door and go to the ball on your left
-    after you
-    put the grey ball next to a door
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent achieves the task.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-MiniBossLevel-v0`
-
-    """
-
-    def __init__(self, **kwargs):
-        super().__init__(
-            num_cols=2,
-            num_rows=2,
-            room_size=5,
-            num_dists=7,
-            locked_room_prob=0.25,
-            **kwargs,
-        )
-
-
-class BossLevel(LevelGen):
-    """
-
-    ## Description
-
-    Command can be any sentence drawn from the Baby Language grammar.
-    Union of all competencies. This level is a superset of all other levels.
-
-    ## Mission Space
-
-    Action mission space:
-
-    "go to the {color} {type} {location}"
-
-    or
-
-    "pick up a/the {color} {type} {location}"
-
-    or
-
-    "open the {color} door {location}"
-
-    or
-
-    "put the {color} {type} {location} next to the {color} {type} {location}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    {location} can be " ", "in front of you", "behind you", "on your left"
-    or "on your right"
-
-    And mission space:
-
-    Two action missions concatenated with "and"
-
-    Example:
-
-    go to the green key
-    and
-    put the box next to the yellow ball
-
-    Sequence mission space:
-
-    Two missions, they can be action or and missions, concatenated with
-    ", then" or "after you".
-
-    Example:
-
-    open a red door and go to the ball on your left
-    after you
-    put the grey ball next to a door
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent achieves the task.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-BossLevel-v0`
-    """
-
-    def __init__(self, **kwargs):
-        super().__init__(**kwargs)
-
-
-class BossLevelNoUnlock(LevelGen):
-    """
-
-    ## Description
-
-    Command can be any sentence drawn from the Baby Language grammar.
-    Union of all competencies. This level is a superset of all other levels.
-    No implicit unlocking.
-
-    ## Mission Space
-
-    Action mission space:
-
-    "go to the {color} {type} {location}"
-
-    or
-
-    "pick up a/the {color} {type} {location}"
-
-    or
-
-    "open the {color} door {location}"
-
-    or
-
-    "put the {color} {type} {location} next to the {color} {type} {location}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball", "box" or "key".
-
-    {location} can be " ", "in front of you", "behind you", "on your left"
-    or "on your right"
-
-    And mission space:
-
-    Two action missions concatenated with "and"
-
-    Example:
-
-    go to the green key
-    and
-    put the box next to the yellow ball
-
-    Sequence mission space:
-
-    Two missions, they can be action or and missions, concatenated with
-    ", then" or "after you".
-
-    Example:
-
-    open a red door and go to the ball on your left
-    after you
-    put the grey ball next to a door
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent achieves the task.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-BossLevelNoUnlock-v0`
-    """
-
-    def __init__(self, **kwargs):
-        super().__init__(locked_room_prob=0, implicit_unlock=False, **kwargs)
diff --git a/rl-starter-files/Minigrid/minigrid/envs/babyai/unlock.py b/rl-starter-files/Minigrid/minigrid/envs/babyai/unlock.py
deleted file mode 100644
index 0bc9d6d..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/babyai/unlock.py
+++ /dev/null
@@ -1,468 +0,0 @@
-"""
-Copied and adapted from https://github.com/mila-iqia/babyai.
-Levels described in the Baby AI ICLR 2019 submission, with the `Unlock` instruction.
-"""
-from __future__ import annotations
-
-from minigrid.core.constants import COLOR_NAMES
-from minigrid.core.world_object import Ball, Box, Key
-from minigrid.envs.babyai.core.roomgrid_level import RoomGridLevel
-from minigrid.envs.babyai.core.verifier import ObjDesc, OpenInstr, PickupInstr
-
-
-class Unlock(RoomGridLevel):
-    """
-
-    ## Description
-
-    Unlock a door.
-
-    Competencies: Maze, Open, Unlock. No unblocking.
-
-    ## Mission Space
-
-    "open the {color} door"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent opens the correct door.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-Unlock-v0`
-
-    """
-
-    def gen_mission(self):
-        # Add a locked door to a random room
-        id = self._rand_int(0, self.num_cols)
-        jd = self._rand_int(0, self.num_rows)
-        door, pos = self.add_door(id, jd, locked=True)
-        locked_room = self.get_room(id, jd)
-
-        # Add the key to a different room
-        while True:
-            ik = self._rand_int(0, self.num_cols)
-            jk = self._rand_int(0, self.num_rows)
-            if ik is id and jk is jd:
-                continue
-            self.add_object(ik, jk, "key", door.color)
-            break
-
-        # With 50% probability, ensure that the locked door is the only
-        # door of that color
-        if self._rand_bool():
-            colors = list(filter(lambda c: c is not door.color, COLOR_NAMES))
-            self.connect_all(door_colors=colors)
-        else:
-            self.connect_all()
-
-        # Add distractors to all but the locked room.
-        # We do this to speed up the reachability test,
-        # which otherwise will reject all levels with
-        # objects in the locked room.
-        for i in range(self.num_cols):
-            for j in range(self.num_rows):
-                if i is not id or j is not jd:
-                    self.add_distractors(i, j, num_distractors=3, all_unique=False)
-
-        # The agent must be placed after all the object to respect constraints
-        while True:
-            self.place_agent()
-            start_room = self.room_from_pos(*self.agent_pos)
-            # Ensure that we are not placing the agent in the locked room
-            if start_room is locked_room:
-                continue
-            break
-
-        self.check_objs_reachable()
-
-        self.instrs = OpenInstr(ObjDesc(door.type, door.color))
-
-
-class UnlockLocal(RoomGridLevel):
-    """
-
-    ## Description
-
-    Fetch a key and unlock a door
-    (in the current room)
-
-    ## Mission Space
-
-    "open the door"
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent opens the door.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-UnlockLocal-v0`
-    - `BabyAI-UnlockLocalDist-v0`
-
-    """
-
-    def __init__(self, distractors=False, **kwargs):
-        self.distractors = distractors
-        super().__init__(**kwargs)
-
-    def gen_mission(self):
-        door, _ = self.add_door(1, 1, locked=True)
-        self.add_object(1, 1, "key", door.color)
-        if self.distractors:
-            self.add_distractors(1, 1, num_distractors=3)
-        self.place_agent(1, 1)
-
-        self.instrs = OpenInstr(ObjDesc(door.type))
-
-
-class KeyInBox(RoomGridLevel):
-    """
-
-    ## Description
-
-    Unlock a door. Key is in a box (in the current room).
-
-    ## Mission Space
-
-    "open the door"
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent opens the door.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-KeyInBox-v0`
-
-    """
-
-    def __init__(self, **kwargs):
-        super().__init__(**kwargs)
-
-    def gen_mission(self):
-        door, _ = self.add_door(1, 1, locked=True)
-
-        # Put the key in the box, then place the box in the room
-        key = Key(door.color)
-        box = Box(self._rand_color(), key)
-        self.place_in_room(1, 1, box)
-
-        self.place_agent(1, 1)
-
-        self.instrs = OpenInstr(ObjDesc(door.type))
-
-
-class UnlockPickup(RoomGridLevel):
-    """
-
-    ## Description
-
-    Unlock a door, then pick up a box in another room
-
-    ## Mission Space
-
-    "pick up the {color} box"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the correct box.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-UnlockPickup-v0`
-    - `BabyAI-UnlockPickupDist-v0`
-
-    """
-
-    def __init__(self, distractors=False, max_steps: int | None = None, **kwargs):
-        self.distractors = distractors
-        room_size = 6
-        if max is None:
-            max_steps = 8 * room_size**2
-
-        super().__init__(
-            num_rows=1, num_cols=2, room_size=6, max_steps=max_steps, **kwargs
-        )
-
-    def gen_mission(self):
-        # Add a random object to the room on the right
-        obj, _ = self.add_object(1, 0, kind="box")
-        # Make sure the two rooms are directly connected by a locked door
-        door, _ = self.add_door(0, 0, 0, locked=True)
-        # Add a key to unlock the door
-        self.add_object(0, 0, "key", door.color)
-        if self.distractors:
-            self.add_distractors(num_distractors=4)
-
-        self.place_agent(0, 0)
-
-        self.instrs = PickupInstr(ObjDesc(obj.type, obj.color))
-
-
-class BlockedUnlockPickup(RoomGridLevel):
-    """
-
-    ## Description
-
-    Unlock a door blocked by a ball, then pick up a box
-    in another room
-
-    ## Mission Space
-
-    "pick up the box"
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the box.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-BlockedUnlockPickup-v0`
-
-    """
-
-    def __init__(self, max_steps: int | None = None, **kwargs):
-        room_size = 6
-        if max_steps is None:
-            max_steps = 16 * room_size**2
-
-        super().__init__(
-            num_rows=1, num_cols=2, room_size=room_size, max_steps=max_steps, **kwargs
-        )
-
-    def gen_mission(self):
-        # Add a box to the room on the right
-        obj, _ = self.add_object(1, 0, kind="box")
-        # Make sure the two rooms are directly connected by a locked door
-        door, pos = self.add_door(0, 0, 0, locked=True)
-        # Block the door with a ball
-        color = self._rand_color()
-        self.grid.set(pos[0] - 1, pos[1], Ball(color))
-        # Add a key to unlock the door
-        self.add_object(0, 0, "key", door.color)
-
-        self.place_agent(0, 0)
-
-        self.instrs = PickupInstr(ObjDesc(obj.type))
-
-
-class UnlockToUnlock(RoomGridLevel):
-    """
-
-    ## Description
-
-    Unlock a door A that requires to unlock a door B before
-
-    ## Mission Space
-
-    "pick up the ball"
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the ball.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `BabyAI-UnlockToUnlock-v0`
-
-    """
-
-    def __init__(self, max_steps: int | None = None, **kwargs):
-        room_size = 6
-        if max_steps is None:
-            max_steps = 30 * room_size**2
-
-        super().__init__(
-            num_rows=1, num_cols=3, room_size=room_size, max_steps=max_steps, **kwargs
-        )
-
-    def gen_mission(self):
-        colors = self._rand_subset(COLOR_NAMES, 2)
-
-        # Add a door of color A connecting left and middle room
-        self.add_door(0, 0, door_idx=0, color=colors[0], locked=True)
-
-        # Add a key of color A in the room on the right
-        self.add_object(2, 0, kind="key", color=colors[0])
-
-        # Add a door of color B connecting middle and right room
-        self.add_door(1, 0, door_idx=0, color=colors[1], locked=True)
-
-        # Add a key of color B in the middle room
-        self.add_object(1, 0, kind="key", color=colors[1])
-
-        obj, _ = self.add_object(0, 0, kind="ball")
-
-        self.place_agent(1, 0)
-
-        self.instrs = PickupInstr(ObjDesc(obj.type))
diff --git a/rl-starter-files/Minigrid/minigrid/envs/blockedunlockpickup.py b/rl-starter-files/Minigrid/minigrid/envs/blockedunlockpickup.py
deleted file mode 100644
index 30490d1..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/blockedunlockpickup.py
+++ /dev/null
@@ -1,116 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.constants import COLOR_NAMES
-from minigrid.core.mission import MissionSpace
-from minigrid.core.roomgrid import RoomGrid
-from minigrid.core.world_object import Ball
-
-
-class BlockedUnlockPickupEnv(RoomGrid):
-
-    """
-
-    ## Description
-
-    The agent has to pick up a box which is placed in another room, behind a
-    locked door. The door is also blocked by a ball which the agent has to move
-    before it can unlock the door. Hence, the agent has to learn to move the
-    ball, pick up the key, open the door and pick up the object in the other
-    room. This environment can be solved without relying on language.
-
-    ## Mission Space
-
-    "pick up the {color} {type}"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "box" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the correct box.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `MiniGrid-BlockedUnlockPickup-v0`
-
-    """
-
-    def __init__(self, max_steps: int | None = None, **kwargs):
-        mission_space = MissionSpace(
-            mission_func=self._gen_mission,
-            ordered_placeholders=[COLOR_NAMES, ["box", "key"]],
-        )
-
-        room_size = 6
-        if max_steps is None:
-            max_steps = 16 * room_size**2
-
-        super().__init__(
-            mission_space=mission_space,
-            num_rows=1,
-            num_cols=2,
-            room_size=room_size,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission(color: str, obj_type: str):
-        return f"pick up the {color} {obj_type}"
-
-    def _gen_grid(self, width, height):
-        super()._gen_grid(width, height)
-
-        # Add a box to the room on the right
-        obj, _ = self.add_object(1, 0, kind="box")
-        # Make sure the two rooms are directly connected by a locked door
-        door, pos = self.add_door(0, 0, 0, locked=True)
-        # Block the door with a ball
-        color = self._rand_color()
-        self.grid.set(pos[0] - 1, pos[1], Ball(color))
-        # Add a key to unlock the door
-        self.add_object(0, 0, "key", door.color)
-
-        self.place_agent(0, 0)
-
-        self.obj = obj
-        self.mission = f"pick up the {obj.color} {obj.type}"
-
-    def step(self, action):
-        obs, reward, terminated, truncated, info = super().step(action)
-
-        if action == self.actions.pickup:
-            if self.carrying and self.carrying == self.obj:
-                reward = self._reward()
-                terminated = True
-
-        return obs, reward, terminated, truncated, info
diff --git a/rl-starter-files/Minigrid/minigrid/envs/crossing.py b/rl-starter-files/Minigrid/minigrid/envs/crossing.py
deleted file mode 100644
index 4531403..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/crossing.py
+++ /dev/null
@@ -1,184 +0,0 @@
-from __future__ import annotations
-
-import itertools as itt
-
-import numpy as np
-
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Goal, Lava
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class CrossingEnv(MiniGridEnv):
-
-    """
-    ## Description
-
-    Depending on the `obstacle_type` parameter:
-    - `Lava` - The agent has to reach the green goal square on the other corner
-        of the room while avoiding rivers of deadly lava which terminate the
-        episode in failure. Each lava stream runs across the room either
-        horizontally or vertically, and has a single crossing point which can be
-        safely used; Luckily, a path to the goal is guaranteed to exist. This
-        environment is useful for studying safety and safe exploration.
-    - otherwise - Similar to the `LavaCrossing` environment, the agent has to
-        reach the green goal square on the other corner of the room, however
-        lava is replaced by walls. This MDP is therefore much easier and maybe
-        useful for quickly testing your algorithms.
-
-    ## Mission Space
-    Depending on the `obstacle_type` parameter:
-    - `Lava` - "avoid the lava and get to the green goal square"
-    - otherwise - "find the opening and get to the green goal square"
-
-    ## Action Space
-
-    | Num | Name         | Action       |
-    |-----|--------------|--------------|
-    | 0   | left         | Turn left    |
-    | 1   | right        | Turn right   |
-    | 2   | forward      | Move forward |
-    | 3   | pickup       | Unused       |
-    | 4   | drop         | Unused       |
-    | 5   | toggle       | Unused       |
-    | 6   | done         | Unused       |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent reaches the goal.
-    2. The agent falls into lava.
-    3. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    S: size of the map SxS.
-    N: number of valid crossings across lava or walls from the starting position
-    to the goal
-
-    - `Lava` :
-        - `MiniGrid-LavaCrossingS9N1-v0`
-        - `MiniGrid-LavaCrossingS9N2-v0`
-        - `MiniGrid-LavaCrossingS9N3-v0`
-        - `MiniGrid-LavaCrossingS11N5-v0`
-
-    - otherwise :
-        - `MiniGrid-SimpleCrossingS9N1-v0`
-        - `MiniGrid-SimpleCrossingS9N2-v0`
-        - `MiniGrid-SimpleCrossingS9N3-v0`
-        - `MiniGrid-SimpleCrossingS11N5-v0`
-
-    """
-
-    def __init__(
-        self,
-        size=9,
-        num_crossings=1,
-        obstacle_type=Lava,
-        max_steps: int | None = None,
-        **kwargs,
-    ):
-        self.num_crossings = num_crossings
-        self.obstacle_type = obstacle_type
-
-        if obstacle_type == Lava:
-            mission_space = MissionSpace(mission_func=self._gen_mission_lava)
-        else:
-            mission_space = MissionSpace(mission_func=self._gen_mission)
-
-        if max_steps is None:
-            max_steps = 4 * size**2
-
-        super().__init__(
-            mission_space=mission_space,
-            grid_size=size,
-            see_through_walls=False,  # Set this to True for maximum speed
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission_lava():
-        return "avoid the lava and get to the green goal square"
-
-    @staticmethod
-    def _gen_mission():
-        return "find the opening and get to the green goal square"
-
-    def _gen_grid(self, width, height):
-        assert width % 2 == 1 and height % 2 == 1  # odd size
-
-        # Create an empty grid
-        self.grid = Grid(width, height)
-
-        # Generate the surrounding walls
-        self.grid.wall_rect(0, 0, width, height)
-
-        # Place the agent in the top-left corner
-        self.agent_pos = np.array((1, 1))
-        self.agent_dir = 0
-
-        # Place a goal square in the bottom-right corner
-        self.put_obj(Goal(), width - 2, height - 2)
-
-        # Place obstacles (lava or walls)
-        v, h = object(), object()  # singleton `vertical` and `horizontal` objects
-
-        # Lava rivers or walls specified by direction and position in grid
-        rivers = [(v, i) for i in range(2, height - 2, 2)]
-        rivers += [(h, j) for j in range(2, width - 2, 2)]
-        self.np_random.shuffle(rivers)
-        rivers = rivers[: self.num_crossings]  # sample random rivers
-        rivers_v = sorted(pos for direction, pos in rivers if direction is v)
-        rivers_h = sorted(pos for direction, pos in rivers if direction is h)
-        obstacle_pos = itt.chain(
-            itt.product(range(1, width - 1), rivers_h),
-            itt.product(rivers_v, range(1, height - 1)),
-        )
-        for i, j in obstacle_pos:
-            self.put_obj(self.obstacle_type(), i, j)
-
-        # Sample path to goal
-        path = [h] * len(rivers_v) + [v] * len(rivers_h)
-        self.np_random.shuffle(path)
-
-        # Create openings
-        limits_v = [0] + rivers_v + [height - 1]
-        limits_h = [0] + rivers_h + [width - 1]
-        room_i, room_j = 0, 0
-        for direction in path:
-            if direction is h:
-                i = limits_v[room_i + 1]
-                j = self.np_random.choice(
-                    range(limits_h[room_j] + 1, limits_h[room_j + 1])
-                )
-                room_i += 1
-            elif direction is v:
-                i = self.np_random.choice(
-                    range(limits_v[room_i] + 1, limits_v[room_i + 1])
-                )
-                j = limits_h[room_j + 1]
-                room_j += 1
-            else:
-                assert False
-            self.grid.set(i, j, None)
-
-        self.mission = (
-            "avoid the lava and get to the green goal square"
-            if self.obstacle_type == Lava
-            else "find the opening and get to the green goal square"
-        )
diff --git a/rl-starter-files/Minigrid/minigrid/envs/distshift.py b/rl-starter-files/Minigrid/minigrid/envs/distshift.py
deleted file mode 100644
index cc9289e..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/distshift.py
+++ /dev/null
@@ -1,121 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Goal, Lava
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class DistShiftEnv(MiniGridEnv):
-
-    """
-    ## Description
-
-    This environment is based on one of the DeepMind [AI safety gridworlds](https://github.com/deepmind/ai-safety-gridworlds).
-    The agent starts in the
-    top-left corner and must reach the goal which is in the top-right corner,
-    but has to avoid stepping into lava on its way. The aim of this environment
-    is to test an agent's ability to generalize. There are two slightly
-    different variants of the environment, so that the agent can be trained on
-    one variant and tested on the other.
-
-    ## Mission Space
-
-    "get to the green goal square"
-
-    ## Action Space
-
-    | Num | Name         | Action       |
-    |-----|--------------|--------------|
-    | 0   | left         | Turn left    |
-    | 1   | right        | Turn right   |
-    | 2   | forward      | Move forward |
-    | 3   | pickup       | Unused       |
-    | 4   | drop         | Unused       |
-    | 5   | toggle       | Unused       |
-    | 6   | done         | Unused       |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent reaches the goal.
-    2. The agent falls into lava.
-    3. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `MiniGrid-DistShift1-v0`
-    - `MiniGrid-DistShift2-v0`
-
-    """
-
-    def __init__(
-        self,
-        width=9,
-        height=7,
-        agent_start_pos=(1, 1),
-        agent_start_dir=0,
-        strip2_row=2,
-        max_steps: int | None = None,
-        **kwargs,
-    ):
-        self.agent_start_pos = agent_start_pos
-        self.agent_start_dir = agent_start_dir
-        self.goal_pos = (width - 2, 1)
-        self.strip2_row = strip2_row
-
-        mission_space = MissionSpace(mission_func=self._gen_mission)
-
-        if max_steps is None:
-            max_steps = 4 * width * height
-
-        super().__init__(
-            mission_space=mission_space,
-            width=width,
-            height=height,
-            # Set this to True for maximum speed
-            see_through_walls=True,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission():
-        return "get to the green goal square"
-
-    def _gen_grid(self, width, height):
-        # Create an empty grid
-        self.grid = Grid(width, height)
-
-        # Generate the surrounding walls
-        self.grid.wall_rect(0, 0, width, height)
-
-        # Place a goal square in the bottom-right corner
-        self.put_obj(Goal(), *self.goal_pos)
-
-        # Place the lava rows
-        for i in range(self.width - 6):
-            self.grid.set(3 + i, 1, Lava())
-            self.grid.set(3 + i, self.strip2_row, Lava())
-
-        # Place the agent
-        if self.agent_start_pos is not None:
-            self.agent_pos = self.agent_start_pos
-            self.agent_dir = self.agent_start_dir
-        else:
-            self.place_agent()
-
-        self.mission = "get to the green goal square"
diff --git a/rl-starter-files/Minigrid/minigrid/envs/doorkey.py b/rl-starter-files/Minigrid/minigrid/envs/doorkey.py
deleted file mode 100644
index 0f83fe8..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/doorkey.py
+++ /dev/null
@@ -1,100 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Door, Goal, Key
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class DoorKeyEnv(MiniGridEnv):
-
-    """
-    ## Description
-
-    This environment has a key that the agent must pick up in order to unlock a
-    goal and then get to the green goal square. This environment is difficult,
-    because of the sparse reward, to solve using classical RL algorithms. It is
-    useful to experiment with curiosity or curriculum learning.
-
-    ## Mission Space
-
-    "use the key to open the door and then get to the goal"
-
-    ## Action Space
-
-    | Num | Name         | Action                    |
-    |-----|--------------|---------------------------|
-    | 0   | left         | Turn left                 |
-    | 1   | right        | Turn right                |
-    | 2   | forward      | Move forward              |
-    | 3   | pickup       | Pick up an object         |
-    | 4   | drop         | Unused                    |
-    | 5   | toggle       | Toggle/activate an object |
-    | 6   | done         | Unused                    |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent reaches the goal.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `MiniGrid-DoorKey-5x5-v0`
-    - `MiniGrid-DoorKey-6x6-v0`
-    - `MiniGrid-DoorKey-8x8-v0`
-    - `MiniGrid-DoorKey-16x16-v0`
-
-    """
-
-    def __init__(self, size=8, max_steps: int | None = None, **kwargs):
-        if max_steps is None:
-            max_steps = 10 * size**2
-        mission_space = MissionSpace(mission_func=self._gen_mission)
-        super().__init__(
-            mission_space=mission_space, grid_size=size, max_steps=max_steps, **kwargs
-        )
-
-    @staticmethod
-    def _gen_mission():
-        return "use the key to open the door and then get to the goal"
-
-    def _gen_grid(self, width, height):
-        # Create an empty grid
-        self.grid = Grid(width, height)
-
-        # Generate the surrounding walls
-        self.grid.wall_rect(0, 0, width, height)
-
-        # Place a goal in the bottom-right corner
-        self.put_obj(Goal(), width - 2, height - 2)
-
-        # Create a vertical splitting wall
-        splitIdx = self._rand_int(2, width - 2)
-        self.grid.vert_wall(splitIdx, 0)
-
-        # Place the agent at a random position and orientation
-        # on the left side of the splitting wall
-        self.place_agent(size=(splitIdx, height))
-
-        # Place a door in the wall
-        doorIdx = self._rand_int(1, width - 2)
-        self.put_obj(Door("yellow", is_locked=True), splitIdx, doorIdx)
-
-        # Place a yellow key on the left side
-        self.place_obj(obj=Key("yellow"), top=(0, 0), size=(splitIdx, height))
-
-        self.mission = "use the key to open the door and then get to the goal"
diff --git a/rl-starter-files/Minigrid/minigrid/envs/dynamicobstacles.py b/rl-starter-files/Minigrid/minigrid/envs/dynamicobstacles.py
deleted file mode 100644
index 9000059..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/dynamicobstacles.py
+++ /dev/null
@@ -1,167 +0,0 @@
-from __future__ import annotations
-
-from operator import add
-
-from gymnasium.spaces import Discrete
-
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Ball, Goal
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class DynamicObstaclesEnv(MiniGridEnv):
-    """
-    ## Description
-
-    This environment is an empty room with moving obstacles.
-    The goal of the agent is to reach the green goal square without colliding
-    with any obstacle. A large penalty is subtracted if the agent collides with
-    an obstacle and the episode finishes. This environment is useful to test
-    Dynamic Obstacle Avoidance for mobile robots with Reinforcement Learning in
-    Partial Observability.
-
-    ## Mission Space
-
-    "get to the green goal square"
-
-    ## Action Space
-
-    | Num | Name         | Action       |
-    |-----|--------------|--------------|
-    | 0   | left         | Turn left    |
-    | 1   | right        | Turn right   |
-    | 2   | forward      | Move forward |
-    | 3   | pickup       | Unused       |
-    | 4   | drop         | Unused       |
-    | 5   | toggle       | Unused       |
-    | 6   | done         | Unused       |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure. A '-1' penalty is
-    subtracted if the agent collides with an obstacle.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent reaches the goal.
-    2. The agent collides with an obstacle.
-    3. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `MiniGrid-Dynamic-Obstacles-5x5-v0`
-    - `MiniGrid-Dynamic-Obstacles-Random-5x5-v0`
-    - `MiniGrid-Dynamic-Obstacles-6x6-v0`
-    - `MiniGrid-Dynamic-Obstacles-Random-6x6-v0`
-    - `MiniGrid-Dynamic-Obstacles-8x8-v0`
-    - `MiniGrid-Dynamic-Obstacles-16x16-v0`
-
-    """
-
-    def __init__(
-        self,
-        size=8,
-        agent_start_pos=(1, 1),
-        agent_start_dir=0,
-        n_obstacles=4,
-        max_steps: int | None = None,
-        **kwargs,
-    ):
-        self.agent_start_pos = agent_start_pos
-        self.agent_start_dir = agent_start_dir
-
-        # Reduce obstacles if there are too many
-        if n_obstacles <= size / 2 + 1:
-            self.n_obstacles = int(n_obstacles)
-        else:
-            self.n_obstacles = int(size / 2)
-
-        mission_space = MissionSpace(mission_func=self._gen_mission)
-
-        if max_steps is None:
-            max_steps = 4 * size**2
-
-        super().__init__(
-            mission_space=mission_space,
-            grid_size=size,
-            # Set this to True for maximum speed
-            see_through_walls=True,
-            max_steps=max_steps,
-            **kwargs,
-        )
-        # Allow only 3 actions permitted: left, right, forward
-        self.action_space = Discrete(self.actions.forward + 1)
-        self.reward_range = (-1, 1)
-
-    @staticmethod
-    def _gen_mission():
-        return "get to the green goal square"
-
-    def _gen_grid(self, width, height):
-        # Create an empty grid
-        self.grid = Grid(width, height)
-
-        # Generate the surrounding walls
-        self.grid.wall_rect(0, 0, width, height)
-
-        # Place a goal square in the bottom-right corner
-        self.grid.set(width - 2, height - 2, Goal())
-
-        # Place the agent
-        if self.agent_start_pos is not None:
-            self.agent_pos = self.agent_start_pos
-            self.agent_dir = self.agent_start_dir
-        else:
-            self.place_agent()
-
-        # Place obstacles
-        self.obstacles = []
-        for i_obst in range(self.n_obstacles):
-            self.obstacles.append(Ball())
-            self.place_obj(self.obstacles[i_obst], max_tries=100)
-
-        self.mission = "get to the green goal square"
-
-    def step(self, action):
-        # Invalid action
-        if action >= self.action_space.n:
-            action = 0
-
-        # Check if there is an obstacle in front of the agent
-        front_cell = self.grid.get(*self.front_pos)
-        not_clear = front_cell and front_cell.type != "goal"
-
-        # Update obstacle positions
-        for i_obst in range(len(self.obstacles)):
-            old_pos = self.obstacles[i_obst].cur_pos
-            top = tuple(map(add, old_pos, (-1, -1)))
-
-            try:
-                self.place_obj(
-                    self.obstacles[i_obst], top=top, size=(3, 3), max_tries=100
-                )
-                self.grid.set(old_pos[0], old_pos[1], None)
-            except Exception:
-                pass
-
-        # Update the agent's position/direction
-        obs, reward, terminated, truncated, info = super().step(action)
-
-        # If the agent tried to walk over an obstacle or wall
-        if action == self.actions.forward and not_clear:
-            reward = -1
-            terminated = True
-            return obs, reward, terminated, truncated, info
-
-        return obs, reward, terminated, truncated, info
diff --git a/rl-starter-files/Minigrid/minigrid/envs/empty.py b/rl-starter-files/Minigrid/minigrid/envs/empty.py
deleted file mode 100644
index f4cb7c8..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/empty.py
+++ /dev/null
@@ -1,114 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Goal
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class EmptyEnv(MiniGridEnv):
-    """
-    ## Description
-
-    This environment is an empty room, and the goal of the agent is to reach the
-    green goal square, which provides a sparse reward. A small penalty is
-    subtracted for the number of steps to reach the goal. This environment is
-    useful, with small rooms, to validate that your RL algorithm works
-    correctly, and with large rooms to experiment with sparse rewards and
-    exploration. The random variants of the environment have the agent starting
-    at a random position for each episode, while the regular variants have the
-    agent always starting in the corner opposite to the goal.
-
-    ## Mission Space
-
-    "get to the green goal square"
-
-    ## Action Space
-
-    | Num | Name         | Action       |
-    |-----|--------------|--------------|
-    | 0   | left         | Turn left    |
-    | 1   | right        | Turn right   |
-    | 2   | forward      | Move forward |
-    | 3   | pickup       | Unused       |
-    | 4   | drop         | Unused       |
-    | 5   | toggle       | Unused       |
-    | 6   | done         | Unused       |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent reaches the goal.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `MiniGrid-Empty-5x5-v0`
-    - `MiniGrid-Empty-Random-5x5-v0`
-    - `MiniGrid-Empty-6x6-v0`
-    - `MiniGrid-Empty-Random-6x6-v0`
-    - `MiniGrid-Empty-8x8-v0`
-    - `MiniGrid-Empty-16x16-v0`
-
-    """
-
-    def __init__(
-        self,
-        size=8,
-        agent_start_pos=(1, 1),
-        agent_start_dir=0,
-        max_steps: int | None = None,
-        **kwargs,
-    ):
-        self.agent_start_pos = agent_start_pos
-        self.agent_start_dir = agent_start_dir
-
-        mission_space = MissionSpace(mission_func=self._gen_mission)
-
-        if max_steps is None:
-            max_steps = 4 * size**2
-
-        super().__init__(
-            mission_space=mission_space,
-            grid_size=size,
-            # Set this to True for maximum speed
-            see_through_walls=True,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission():
-        return "get to the green goal square"
-
-    def _gen_grid(self, width, height):
-        # Create an empty grid
-        self.grid = Grid(width, height)
-
-        # Generate the surrounding walls
-        self.grid.wall_rect(0, 0, width, height)
-
-        # Place a goal square in the bottom-right corner
-        self.put_obj(Goal(), width - 2, height - 2)
-
-        # Place the agent
-        if self.agent_start_pos is not None:
-            self.agent_pos = self.agent_start_pos
-            self.agent_dir = self.agent_start_dir
-        else:
-            self.place_agent()
-
-        self.mission = "get to the green goal square"
diff --git a/rl-starter-files/Minigrid/minigrid/envs/fetch.py b/rl-starter-files/Minigrid/minigrid/envs/fetch.py
deleted file mode 100644
index 887562f..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/fetch.py
+++ /dev/null
@@ -1,176 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.constants import COLOR_NAMES
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Ball, Key
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class FetchEnv(MiniGridEnv):
-
-    """
-    ## Description
-
-    This environment has multiple objects of assorted types and colors. The
-    agent receives a textual string as part of its observation telling it which
-    object to pick up. Picking up the wrong object terminates the episode with
-    zero reward.
-
-    ## Mission Space
-
-    "{syntax} {color} {type}"
-
-    {syntax} is one of the following: "get a", "go get a", "fetch a",
-    "go fetch a", "you must fetch a".
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "key" or "ball".
-
-    ## Action Space
-
-    | Num | Name         | Action               |
-    |-----|--------------|----------------------|
-    | 0   | left         | Turn left            |
-    | 1   | right        | Turn right           |
-    | 2   | forward      | Move forward         |
-    | 3   | pickup       | Pick up an object    |
-    | 4   | drop         | Unused               |
-    | 5   | toggle       | Unused               |
-    | 6   | done         | Unused               |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the correct object.
-    2. The agent picks up the wrong object.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    N: number of objects to be generated.
-
-    - `MiniGrid-Fetch-5x5-N2-v0`
-    - `MiniGrid-Fetch-6x6-N2-v0`
-    - `MiniGrid-Fetch-8x8-N3-v0`
-
-    """
-
-    def __init__(self, size=8, numObjs=3, max_steps: int | None = None, **kwargs):
-        self.numObjs = numObjs
-        self.obj_types = ["key", "ball"]
-
-        MISSION_SYNTAX = [
-            "get a",
-            "go get a",
-            "fetch a",
-            "go fetch a",
-            "you must fetch a",
-        ]
-        self.size = size
-        mission_space = MissionSpace(
-            mission_func=self._gen_mission,
-            ordered_placeholders=[MISSION_SYNTAX, COLOR_NAMES, self.obj_types],
-        )
-
-        if max_steps is None:
-            max_steps = 5 * size**2
-
-        super().__init__(
-            mission_space=mission_space,
-            width=size,
-            height=size,
-            # Set this to True for maximum speed
-            see_through_walls=True,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission(syntax: str, color: str, obj_type: str):
-        return f"{syntax} {color} {obj_type}"
-
-    def _gen_grid(self, width, height):
-        self.grid = Grid(width, height)
-
-        # Generate the surrounding walls
-        self.grid.horz_wall(0, 0)
-        self.grid.horz_wall(0, height - 1)
-        self.grid.vert_wall(0, 0)
-        self.grid.vert_wall(width - 1, 0)
-
-        objs = []
-
-        # For each object to be generated
-        while len(objs) < self.numObjs:
-            objType = self._rand_elem(self.obj_types)
-            objColor = self._rand_elem(COLOR_NAMES)
-
-            if objType == "key":
-                obj = Key(objColor)
-            elif objType == "ball":
-                obj = Ball(objColor)
-            else:
-                raise ValueError(
-                    "{} object type given. Object type can only be of values key and ball.".format(
-                        objType
-                    )
-                )
-
-            self.place_obj(obj)
-            objs.append(obj)
-
-        # Randomize the player start position and orientation
-        self.place_agent()
-
-        # Choose a random object to be picked up
-        target = objs[self._rand_int(0, len(objs))]
-        self.targetType = target.type
-        self.targetColor = target.color
-
-        descStr = f"{self.targetColor} {self.targetType}"
-
-        # Generate the mission string
-        idx = self._rand_int(0, 5)
-        if idx == 0:
-            self.mission = "get a %s" % descStr
-        elif idx == 1:
-            self.mission = "go get a %s" % descStr
-        elif idx == 2:
-            self.mission = "fetch a %s" % descStr
-        elif idx == 3:
-            self.mission = "go fetch a %s" % descStr
-        elif idx == 4:
-            self.mission = "you must fetch a %s" % descStr
-        assert hasattr(self, "mission")
-
-    def step(self, action):
-        obs, reward, terminated, truncated, info = super().step(action)
-
-        if self.carrying:
-            if (
-                self.carrying.color == self.targetColor
-                and self.carrying.type == self.targetType
-            ):
-                reward = self._reward()
-                terminated = True
-            else:
-                reward = 0
-                terminated = True
-
-        return obs, reward, terminated, truncated, info
diff --git a/rl-starter-files/Minigrid/minigrid/envs/fourrooms.py b/rl-starter-files/Minigrid/minigrid/envs/fourrooms.py
deleted file mode 100644
index 046dc27..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/fourrooms.py
+++ /dev/null
@@ -1,128 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Goal
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class FourRoomsEnv(MiniGridEnv):
-
-    """
-    ## Description
-
-    Classic four room reinforcement learning environment. The agent must
-    navigate in a maze composed of four rooms interconnected by 4 gaps in the
-    walls. To obtain a reward, the agent must reach the green goal square. Both
-    the agent and the goal square are randomly placed in any of the four rooms.
-
-    ## Mission Space
-
-    "reach the goal"
-
-    ## Action Space
-
-    | Num | Name         | Action       |
-    |-----|--------------|--------------|
-    | 0   | left         | Turn left    |
-    | 1   | right        | Turn right   |
-    | 2   | forward      | Move forward |
-    | 3   | pickup       | Unused       |
-    | 4   | drop         | Unused       |
-    | 5   | toggle       | Unused       |
-    | 6   | done         | Unused       |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent reaches the goal.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `MiniGrid-FourRooms-v0`
-
-    """
-
-    def __init__(self, agent_pos=None, goal_pos=None, max_steps=100, **kwargs):
-        self._agent_default_pos = agent_pos
-        self._goal_default_pos = goal_pos
-
-        self.size = 19
-        mission_space = MissionSpace(mission_func=self._gen_mission)
-
-        super().__init__(
-            mission_space=mission_space,
-            width=self.size,
-            height=self.size,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission():
-        return "reach the goal"
-
-    def _gen_grid(self, width, height):
-        # Create the grid
-        self.grid = Grid(width, height)
-
-        # Generate the surrounding walls
-        self.grid.horz_wall(0, 0)
-        self.grid.horz_wall(0, height - 1)
-        self.grid.vert_wall(0, 0)
-        self.grid.vert_wall(width - 1, 0)
-
-        room_w = width // 2
-        room_h = height // 2
-
-        # For each row of rooms
-        for j in range(0, 2):
-
-            # For each column
-            for i in range(0, 2):
-                xL = i * room_w
-                yT = j * room_h
-                xR = xL + room_w
-                yB = yT + room_h
-
-                # Bottom wall and door
-                if i + 1 < 2:
-                    self.grid.vert_wall(xR, yT, room_h)
-                    pos = (xR, self._rand_int(yT + 1, yB))
-                    self.grid.set(*pos, None)
-
-                # Bottom wall and door
-                if j + 1 < 2:
-                    self.grid.horz_wall(xL, yB, room_w)
-                    pos = (self._rand_int(xL + 1, xR), yB)
-                    self.grid.set(*pos, None)
-
-        # Randomize the player start position and orientation
-        if self._agent_default_pos is not None:
-            self.agent_pos = self._agent_default_pos
-            self.grid.set(*self._agent_default_pos, None)
-            # assuming random start direction
-            self.agent_dir = self._rand_int(0, 4)
-        else:
-            self.place_agent()
-
-        if self._goal_default_pos is not None:
-            goal = Goal()
-            self.put_obj(goal, *self._goal_default_pos)
-            goal.init_pos, goal.cur_pos = self._goal_default_pos
-        else:
-            self.place_obj(Goal())
diff --git a/rl-starter-files/Minigrid/minigrid/envs/gotodoor.py b/rl-starter-files/Minigrid/minigrid/envs/gotodoor.py
deleted file mode 100644
index 5018d3a..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/gotodoor.py
+++ /dev/null
@@ -1,149 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.constants import COLOR_NAMES
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Door
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class GoToDoorEnv(MiniGridEnv):
-    """
-    ## Description
-
-    This environment is a room with four doors, one on each wall. The agent
-    receives a textual (mission) string as input, telling it which door to go
-    to, (eg: "go to the red door"). It receives a positive reward for performing
-    the `done` action next to the correct door, as indicated in the mission
-    string.
-
-    ## Mission Space
-
-    "go to the {color} door"
-
-    {color} is the color of the door. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    ## Action Space
-
-    | Num | Name         | Action               |
-    |-----|--------------|----------------------|
-    | 0   | left         | Turn left            |
-    | 1   | right        | Turn right           |
-    | 2   | forward      | Move forward         |
-    | 3   | pickup       | Unused               |
-    | 4   | drop         | Unused               |
-    | 5   | toggle       | Unused               |
-    | 6   | done         | Done completing task |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent stands next the correct door performing the `done` action.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `MiniGrid-GoToDoor-5x5-v0`
-    - `MiniGrid-GoToDoor-6x6-v0`
-    - `MiniGrid-GoToDoor-8x8-v0`
-
-    """
-
-    def __init__(self, size=5, max_steps: int | None = None, **kwargs):
-        assert size >= 5
-        self.size = size
-        mission_space = MissionSpace(
-            mission_func=self._gen_mission,
-            ordered_placeholders=[COLOR_NAMES],
-        )
-
-        if max_steps is None:
-            max_steps = 4 * size**2
-
-        super().__init__(
-            mission_space=mission_space,
-            width=size,
-            height=size,
-            # Set this to True for maximum speed
-            see_through_walls=True,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission(color: str):
-        return f"go to the {color} door"
-
-    def _gen_grid(self, width, height):
-        # Create the grid
-        self.grid = Grid(width, height)
-
-        # Randomly vary the room width and height
-        width = self._rand_int(5, width + 1)
-        height = self._rand_int(5, height + 1)
-
-        # Generate the surrounding walls
-        self.grid.wall_rect(0, 0, width, height)
-
-        # Generate the 4 doors at random positions
-        doorPos = []
-        doorPos.append((self._rand_int(2, width - 2), 0))
-        doorPos.append((self._rand_int(2, width - 2), height - 1))
-        doorPos.append((0, self._rand_int(2, height - 2)))
-        doorPos.append((width - 1, self._rand_int(2, height - 2)))
-
-        # Generate the door colors
-        doorColors = []
-        while len(doorColors) < len(doorPos):
-            color = self._rand_elem(COLOR_NAMES)
-            if color in doorColors:
-                continue
-            doorColors.append(color)
-
-        # Place the doors in the grid
-        for idx, pos in enumerate(doorPos):
-            color = doorColors[idx]
-            self.grid.set(*pos, Door(color))
-
-        # Randomize the agent start position and orientation
-        self.place_agent(size=(width, height))
-
-        # Select a random target door
-        doorIdx = self._rand_int(0, len(doorPos))
-        self.target_pos = doorPos[doorIdx]
-        self.target_color = doorColors[doorIdx]
-
-        # Generate the mission string
-        self.mission = "go to the %s door" % self.target_color
-
-    def step(self, action):
-        obs, reward, terminated, truncated, info = super().step(action)
-
-        ax, ay = self.agent_pos
-        tx, ty = self.target_pos
-
-        # Don't let the agent open any of the doors
-        if action == self.actions.toggle:
-            terminated = True
-
-        # Reward performing done action in front of the target door
-        if action == self.actions.done:
-            if (ax == tx and abs(ay - ty) == 1) or (ay == ty and abs(ax - tx) == 1):
-                reward = self._reward()
-            terminated = True
-
-        return obs, reward, terminated, truncated, info
diff --git a/rl-starter-files/Minigrid/minigrid/envs/gotoobject.py b/rl-starter-files/Minigrid/minigrid/envs/gotoobject.py
deleted file mode 100644
index a9a8445..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/gotoobject.py
+++ /dev/null
@@ -1,161 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.constants import COLOR_NAMES
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Ball, Box, Key
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class GoToObjectEnv(MiniGridEnv):
-    """
-    ## Description
-
-    This environment is a room with colored objects. The agent
-    receives a textual (mission) string as input, telling it which colored object to go
-    to, (eg: "go to the red key"). It receives a positive reward for performing
-    the `done` action next to the correct object, as indicated in the mission
-    string.
-
-    ## Mission Space
-
-    "go to the {color} {obj_type}"
-
-    {color} is the color of the object. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-    {obj_type} is the type of the object. Can be "key", "ball", "box".
-
-    ## Action Space
-
-    | Num | Name         | Action               |
-    |-----|--------------|----------------------|
-    | 0   | left         | Turn left            |
-    | 1   | right        | Turn right           |
-    | 2   | forward      | Move forward         |
-    | 3   | pickup       | Unused               |
-    | 4   | drop         | Unused               |
-    | 5   | toggle       | Unused               |
-    | 6   | done         | Done completing task |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent stands next the correct door performing the `done` action.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `MiniGrid-GoToObject-6x6-N2-v0`
-    - `MiniGrid-GoToObject-8x8-N2-v0`
-
-    """
-
-    def __init__(self, size=6, numObjs=2, max_steps: int | None = None, **kwargs):
-
-        self.numObjs = numObjs
-        self.size = size
-        # Types of objects to be generated
-        self.obj_types = ["key", "ball", "box"]
-
-        mission_space = MissionSpace(
-            mission_func=self._gen_mission,
-            ordered_placeholders=[COLOR_NAMES, self.obj_types],
-        )
-
-        if max_steps is None:
-            max_steps = 5 * size**2
-
-        super().__init__(
-            mission_space=mission_space,
-            width=size,
-            height=size,
-            # Set this to True for maximum speed
-            see_through_walls=True,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission(color: str, obj_type: str):
-        return f"go to the {color} {obj_type}"
-
-    def _gen_grid(self, width, height):
-        self.grid = Grid(width, height)
-
-        # Generate the surrounding walls
-        self.grid.wall_rect(0, 0, width, height)
-
-        # Types and colors of objects we can generate
-        types = ["key", "ball", "box"]
-
-        objs = []
-        objPos = []
-
-        # Until we have generated all the objects
-        while len(objs) < self.numObjs:
-            objType = self._rand_elem(types)
-            objColor = self._rand_elem(COLOR_NAMES)
-
-            # If this object already exists, try again
-            if (objType, objColor) in objs:
-                continue
-
-            if objType == "key":
-                obj = Key(objColor)
-            elif objType == "ball":
-                obj = Ball(objColor)
-            elif objType == "box":
-                obj = Box(objColor)
-            else:
-                raise ValueError(
-                    "{} object type given. Object type can only be of values key, ball and box.".format(
-                        objType
-                    )
-                )
-
-            pos = self.place_obj(obj)
-            objs.append((objType, objColor))
-            objPos.append(pos)
-
-        # Randomize the agent start position and orientation
-        self.place_agent()
-
-        # Choose a random object to be picked up
-        objIdx = self._rand_int(0, len(objs))
-        self.targetType, self.target_color = objs[objIdx]
-        self.target_pos = objPos[objIdx]
-
-        descStr = f"{self.target_color} {self.targetType}"
-        self.mission = "go to the %s" % descStr
-        # print(self.mission)
-
-    def step(self, action):
-        obs, reward, terminated, truncated, info = super().step(action)
-
-        ax, ay = self.agent_pos
-        tx, ty = self.target_pos
-
-        # Toggle/pickup action terminates the episode
-        if action == self.actions.toggle:
-            terminated = True
-
-        # Reward performing the done action next to the target object
-        if action == self.actions.done:
-            if (ax == tx and abs(ay - ty) == 1) or (ay == ty and abs(ax - tx) == 1):
-                reward = self._reward()
-            terminated = True
-
-        return obs, reward, terminated, truncated, info
diff --git a/rl-starter-files/Minigrid/minigrid/envs/keycorridor.py b/rl-starter-files/Minigrid/minigrid/envs/keycorridor.py
deleted file mode 100644
index 69a1b2f..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/keycorridor.py
+++ /dev/null
@@ -1,137 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.constants import COLOR_NAMES
-from minigrid.core.mission import MissionSpace
-from minigrid.core.roomgrid import RoomGrid
-
-
-class KeyCorridorEnv(RoomGrid):
-
-    """
-    ## Description
-
-    This environment is similar to the locked room environment, but there are
-    multiple registered environment configurations of increasing size,
-    making it easier to use curriculum learning to train an agent to solve it.
-    The agent has to pick up an object which is behind a locked door. The key is
-    hidden in another room, and the agent has to explore the environment to find
-    it. The mission string does not give the agent any clues as to where the
-    key is placed. This environment can be solved without relying on language.
-
-    ## Mission Space
-
-    "pick up the {color} {obj_type}"
-
-    {color} is the color of the object. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {type} is the type of the object. Can be "ball" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Unused            |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the correct object.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    S: room size.
-    R: Number of rows.
-
-    - `MiniGrid-KeyCorridorS3R1-v0`
-    - `MiniGrid-KeyCorridorS3R2-v0`
-    - `MiniGrid-KeyCorridorS3R3-v0`
-    - `MiniGrid-KeyCorridorS4R3-v0`
-    - `MiniGrid-KeyCorridorS5R3-v0`
-    - `MiniGrid-KeyCorridorS6R3-v0`
-
-    """
-
-    def __init__(
-        self,
-        num_rows=3,
-        obj_type="ball",
-        room_size=6,
-        max_steps: int | None = None,
-        **kwargs,
-    ):
-        self.obj_type = obj_type
-        mission_space = MissionSpace(
-            mission_func=self._gen_mission,
-            ordered_placeholders=[COLOR_NAMES, [obj_type]],
-        )
-
-        if max_steps is None:
-            max_steps = 30 * room_size**2
-
-        super().__init__(
-            mission_space=mission_space,
-            room_size=room_size,
-            num_rows=num_rows,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission(color: str, obj_type: str):
-        return f"pick up the {color} {obj_type}"
-
-    def _gen_grid(self, width, height):
-        super()._gen_grid(width, height)
-
-        # Connect the middle column rooms into a hallway
-        for j in range(1, self.num_rows):
-            self.remove_wall(1, j, 3)
-
-        # Add a locked door on the bottom right
-        # Add an object behind the locked door
-        room_idx = self._rand_int(0, self.num_rows)
-        door, _ = self.add_door(2, room_idx, 2, locked=True)
-        obj, _ = self.add_object(2, room_idx, kind=self.obj_type)
-
-        # Add a key in a random room on the left side
-        self.add_object(0, self._rand_int(0, self.num_rows), "key", door.color)
-
-        # Place the agent in the middle
-        self.place_agent(1, self.num_rows // 2)
-
-        # Make sure all rooms are accessible
-        self.connect_all()
-
-        self.obj = obj
-        self.mission = f"pick up the {obj.color} {obj.type}"
-
-    def step(self, action):
-        obs, reward, terminated, truncated, info = super().step(action)
-
-        if action == self.actions.pickup:
-            if self.carrying and self.carrying == self.obj:
-                reward = self._reward()
-                terminated = True
-
-        return obs, reward, terminated, truncated, info
diff --git a/rl-starter-files/Minigrid/minigrid/envs/lavagap.py b/rl-starter-files/Minigrid/minigrid/envs/lavagap.py
deleted file mode 100644
index 76b280d..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/lavagap.py
+++ /dev/null
@@ -1,136 +0,0 @@
-from __future__ import annotations
-
-import numpy as np
-
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Goal, Lava
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class LavaGapEnv(MiniGridEnv):
-
-    """
-    ## Description
-
-    The agent has to reach the green goal square at the opposite corner of the
-    room, and must pass through a narrow gap in a vertical strip of deadly lava.
-    Touching the lava terminate the episode with a zero reward. This environment
-    is useful for studying safety and safe exploration.
-
-    ## Mission Space
-
-    Depending on the `obstacle_type` parameter:
-    - `Lava`: "avoid the lava and get to the green goal square"
-    - otherwise: "find the opening and get to the green goal square"
-
-    ## Action Space
-
-    | Num | Name         | Action       |
-    |-----|--------------|--------------|
-    | 0   | left         | Turn left    |
-    | 1   | right        | Turn right   |
-    | 2   | forward      | Move forward |
-    | 3   | pickup       | Unused       |
-    | 4   | drop         | Unused       |
-    | 5   | toggle       | Unused       |
-    | 6   | done         | Unused       |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent reaches the goal.
-    2. The agent falls into lava.
-    3. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    S: size of map SxS.
-
-    - `MiniGrid-LavaGapS5-v0`
-    - `MiniGrid-LavaGapS6-v0`
-    - `MiniGrid-LavaGapS7-v0`
-
-    """
-
-    def __init__(
-        self, size, obstacle_type=Lava, max_steps: int | None = None, **kwargs
-    ):
-        self.obstacle_type = obstacle_type
-        self.size = size
-
-        if obstacle_type == Lava:
-            mission_space = MissionSpace(mission_func=self._gen_mission_lava)
-        else:
-            mission_space = MissionSpace(mission_func=self._gen_mission)
-
-        if max_steps is None:
-            max_steps = 4 * size**2
-
-        super().__init__(
-            mission_space=mission_space,
-            width=size,
-            height=size,
-            # Set this to True for maximum speed
-            see_through_walls=False,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission_lava():
-        return "avoid the lava and get to the green goal square"
-
-    @staticmethod
-    def _gen_mission():
-        return "find the opening and get to the green goal square"
-
-    def _gen_grid(self, width, height):
-        assert width >= 5 and height >= 5
-
-        # Create an empty grid
-        self.grid = Grid(width, height)
-
-        # Generate the surrounding walls
-        self.grid.wall_rect(0, 0, width, height)
-
-        # Place the agent in the top-left corner
-        self.agent_pos = np.array((1, 1))
-        self.agent_dir = 0
-
-        # Place a goal square in the bottom-right corner
-        self.goal_pos = np.array((width - 2, height - 2))
-        self.put_obj(Goal(), *self.goal_pos)
-
-        # Generate and store random gap position
-        self.gap_pos = np.array(
-            (
-                self._rand_int(2, width - 2),
-                self._rand_int(1, height - 1),
-            )
-        )
-
-        # Place the obstacle wall
-        self.grid.vert_wall(self.gap_pos[0], 1, height - 2, self.obstacle_type)
-
-        # Put a hole in the wall
-        self.grid.set(*self.gap_pos, None)
-
-        self.mission = (
-            "avoid the lava and get to the green goal square"
-            if self.obstacle_type == Lava
-            else "find the opening and get to the green goal square"
-        )
diff --git a/rl-starter-files/Minigrid/minigrid/envs/lockedroom.py b/rl-starter-files/Minigrid/minigrid/envs/lockedroom.py
deleted file mode 100644
index d604a1a..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/lockedroom.py
+++ /dev/null
@@ -1,174 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.constants import COLOR_NAMES
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Door, Goal, Key, Wall
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class LockedRoom:
-    def __init__(self, top, size, doorPos):
-        self.top = top
-        self.size = size
-        self.doorPos = doorPos
-        self.color = None
-        self.locked = False
-
-    def rand_pos(self, env):
-        topX, topY = self.top
-        sizeX, sizeY = self.size
-        return env._rand_pos(topX + 1, topX + sizeX - 1, topY + 1, topY + sizeY - 1)
-
-
-class LockedRoomEnv(MiniGridEnv):
-
-    """
-    ## Description
-
-    The environment has six rooms, one of which is locked. The agent receives
-    a textual mission string as input, telling it which room to go to in order
-    to get the key that opens the locked room. It then has to go into the locked
-    room in order to reach the final goal. This environment is extremely
-    difficult to solve with vanilla reinforcement learning alone.
-
-    ## Mission Space
-
-    "get the {lockedroom_color} key from the {keyroom_color} room, unlock the {door_color} door and go to the goal"
-
-    {lockedroom_color}, {keyroom_color}, and {door_color} can be "red", "green",
-    "blue", "purple", "yellow" or "grey".
-
-    ## Action Space
-
-    | Num | Name         | Action                    |
-    |-----|--------------|---------------------------|
-    | 0   | left         | Turn left                 |
-    | 1   | right        | Turn right                |
-    | 2   | forward      | Move forward              |
-    | 3   | pickup       | Pick up an object         |
-    | 4   | drop         | Unused                    |
-    | 5   | toggle       | Toggle/activate an object |
-    | 6   | done         | Unused                    |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent reaches the goal.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `MiniGrid-LockedRoom-v0`
-
-    """
-
-    def __init__(self, size=19, max_steps: int | None = None, **kwargs):
-        self.size = size
-
-        if max_steps is None:
-            max_steps = 10 * size
-        mission_space = MissionSpace(
-            mission_func=self._gen_mission,
-            ordered_placeholders=[COLOR_NAMES] * 3,
-        )
-        super().__init__(
-            mission_space=mission_space,
-            width=size,
-            height=size,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission(lockedroom_color: str, keyroom_color: str, door_color: str):
-        return (
-            f"get the {lockedroom_color} key from the {keyroom_color} room,"
-            f" unlock the {door_color} door and go to the goal"
-        )
-
-    def _gen_grid(self, width, height):
-        # Create the grid
-        self.grid = Grid(width, height)
-
-        # Generate the surrounding walls
-        for i in range(0, width):
-            self.grid.set(i, 0, Wall())
-            self.grid.set(i, height - 1, Wall())
-        for j in range(0, height):
-            self.grid.set(0, j, Wall())
-            self.grid.set(width - 1, j, Wall())
-
-        # Hallway walls
-        lWallIdx = width // 2 - 2
-        rWallIdx = width // 2 + 2
-        for j in range(0, height):
-            self.grid.set(lWallIdx, j, Wall())
-            self.grid.set(rWallIdx, j, Wall())
-
-        self.rooms = []
-
-        # Room splitting walls
-        for n in range(0, 3):
-            j = n * (height // 3)
-            for i in range(0, lWallIdx):
-                self.grid.set(i, j, Wall())
-            for i in range(rWallIdx, width):
-                self.grid.set(i, j, Wall())
-
-            roomW = lWallIdx + 1
-            roomH = height // 3 + 1
-            self.rooms.append(LockedRoom((0, j), (roomW, roomH), (lWallIdx, j + 3)))
-            self.rooms.append(
-                LockedRoom((rWallIdx, j), (roomW, roomH), (rWallIdx, j + 3))
-            )
-
-        # Choose one random room to be locked
-        lockedRoom = self._rand_elem(self.rooms)
-        lockedRoom.locked = True
-        goalPos = lockedRoom.rand_pos(self)
-        self.grid.set(*goalPos, Goal())
-
-        # Assign the door colors
-        colors = set(COLOR_NAMES)
-        for room in self.rooms:
-            color = self._rand_elem(sorted(colors))
-            colors.remove(color)
-            room.color = color
-            if room.locked:
-                self.grid.set(*room.doorPos, Door(color, is_locked=True))
-            else:
-                self.grid.set(*room.doorPos, Door(color))
-
-        # Select a random room to contain the key
-        while True:
-            keyRoom = self._rand_elem(self.rooms)
-            if keyRoom != lockedRoom:
-                break
-        keyPos = keyRoom.rand_pos(self)
-        self.grid.set(*keyPos, Key(lockedRoom.color))
-
-        # Randomize the player start position and orientation
-        self.agent_pos = self.place_agent(
-            top=(lWallIdx, 0), size=(rWallIdx - lWallIdx, height)
-        )
-
-        # Generate the mission string
-        self.mission = (
-            "get the %s key from the %s room, "
-            "unlock the %s door and "
-            "go to the goal"
-        ) % (lockedRoom.color, keyRoom.color, lockedRoom.color)
diff --git a/rl-starter-files/Minigrid/minigrid/envs/memory.py b/rl-starter-files/Minigrid/minigrid/envs/memory.py
deleted file mode 100644
index 2d48f80..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/memory.py
+++ /dev/null
@@ -1,165 +0,0 @@
-from __future__ import annotations
-
-import numpy as np
-
-from minigrid.core.actions import Actions
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Ball, Key, Wall
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class MemoryEnv(MiniGridEnv):
-
-    """
-    ## Description
-
-    This environment is a memory test. The agent starts in a small room where it
-    sees an object. It then has to go through a narrow hallway which ends in a
-    split. At each end of the split there is an object, one of which is the same
-    as the object in the starting room. The agent has to remember the initial
-    object, and go to the matching object at split.
-
-    ## Mission Space
-
-    "go to the matching object at the end of the hallway"
-
-    ## Action Space
-
-    | Num | Name         | Action                    |
-    |-----|--------------|---------------------------|
-    | 0   | left         | Turn left                 |
-    | 1   | right        | Turn right                |
-    | 2   | forward      | Move forward              |
-    | 3   | pickup       | Pick up an object         |
-    | 4   | drop         | Unused                    |
-    | 5   | toggle       | Toggle/activate an object |
-    | 6   | done         | Unused                    |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent reaches the correct matching object.
-    2. The agent reaches the wrong matching object.
-    3. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    S: size of map SxS.
-
-    - `MiniGrid-MemoryS17Random-v0`
-    - `MiniGrid-MemoryS13Random-v0`
-    - `MiniGrid-MemoryS13-v0`
-    - `MiniGrid-MemoryS11-v0`
-
-    """
-
-    def __init__(
-        self, size=8, random_length=False, max_steps: int | None = None, **kwargs
-    ):
-        self.size = size
-        self.random_length = random_length
-
-        if max_steps is None:
-            max_steps = 5 * size**2
-
-        mission_space = MissionSpace(mission_func=self._gen_mission)
-        super().__init__(
-            mission_space=mission_space,
-            width=size,
-            height=size,
-            # Set this to True for maximum speed
-            see_through_walls=False,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission():
-        return "go to the matching object at the end of the hallway"
-
-    def _gen_grid(self, width, height):
-        self.grid = Grid(width, height)
-
-        # Generate the surrounding walls
-        self.grid.horz_wall(0, 0)
-        self.grid.horz_wall(0, height - 1)
-        self.grid.vert_wall(0, 0)
-        self.grid.vert_wall(width - 1, 0)
-
-        assert height % 2 == 1
-        upper_room_wall = height // 2 - 2
-        lower_room_wall = height // 2 + 2
-        if self.random_length:
-            hallway_end = self._rand_int(4, width - 2)
-        else:
-            hallway_end = width - 3
-
-        # Start room
-        for i in range(1, 5):
-            self.grid.set(i, upper_room_wall, Wall())
-            self.grid.set(i, lower_room_wall, Wall())
-        self.grid.set(4, upper_room_wall + 1, Wall())
-        self.grid.set(4, lower_room_wall - 1, Wall())
-
-        # Horizontal hallway
-        for i in range(5, hallway_end):
-            self.grid.set(i, upper_room_wall + 1, Wall())
-            self.grid.set(i, lower_room_wall - 1, Wall())
-
-        # Vertical hallway
-        for j in range(0, height):
-            if j != height // 2:
-                self.grid.set(hallway_end, j, Wall())
-            self.grid.set(hallway_end + 2, j, Wall())
-
-        # Fix the player's start position and orientation
-        self.agent_pos = np.array((self._rand_int(1, hallway_end + 1), height // 2))
-        self.agent_dir = 0
-
-        # Place objects
-        start_room_obj = self._rand_elem([Key, Ball])
-        self.grid.set(1, height // 2 - 1, start_room_obj("green"))
-
-        other_objs = self._rand_elem([[Ball, Key], [Key, Ball]])
-        pos0 = (hallway_end + 1, height // 2 - 2)
-        pos1 = (hallway_end + 1, height // 2 + 2)
-        self.grid.set(*pos0, other_objs[0]("green"))
-        self.grid.set(*pos1, other_objs[1]("green"))
-
-        # Choose the target objects
-        if start_room_obj == other_objs[0]:
-            self.success_pos = (pos0[0], pos0[1] + 1)
-            self.failure_pos = (pos1[0], pos1[1] - 1)
-        else:
-            self.success_pos = (pos1[0], pos1[1] - 1)
-            self.failure_pos = (pos0[0], pos0[1] + 1)
-
-        self.mission = "go to the matching object at the end of the hallway"
-
-    def step(self, action):
-        if action == Actions.pickup:
-            action = Actions.toggle
-        obs, reward, terminated, truncated, info = super().step(action)
-
-        if tuple(self.agent_pos) == self.success_pos:
-            reward = self._reward()
-            terminated = True
-        if tuple(self.agent_pos) == self.failure_pos:
-            reward = 0
-            terminated = True
-
-        return obs, reward, terminated, truncated, info
diff --git a/rl-starter-files/Minigrid/minigrid/envs/multiroom.py b/rl-starter-files/Minigrid/minigrid/envs/multiroom.py
deleted file mode 100644
index 82ceff4..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/multiroom.py
+++ /dev/null
@@ -1,281 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.constants import COLOR_NAMES
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Door, Goal, Wall
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class MultiRoom:
-    def __init__(self, top, size, entryDoorPos, exitDoorPos):
-        self.top = top
-        self.size = size
-        self.entryDoorPos = entryDoorPos
-        self.exitDoorPos = exitDoorPos
-
-
-class MultiRoomEnv(MiniGridEnv):
-
-    """
-    ## Description
-
-    This environment has a series of connected rooms with doors that must be
-    opened in order to get to the next room. The final room has the green goal
-    square the agent must get to. This environment is extremely difficult to
-    solve using RL alone. However, by gradually increasing the number of rooms
-    and building a curriculum, the environment can be solved.
-
-    ## Mission Space
-
-    "traverse the rooms to get to the goal"
-
-    ## Action Space
-
-    | Num | Name         | Action                    |
-    |-----|--------------|---------------------------|
-    | 0   | left         | Turn left                 |
-    | 1   | right        | Turn right                |
-    | 2   | forward      | Move forward              |
-    | 3   | pickup       | Unused                    |
-    | 4   | drop         | Unused                    |
-    | 5   | toggle       | Toggle/activate an object |
-    | 6   | done         | Unused                    |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent reaches the goal.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    S: size of map SxS.
-    N: number of rooms.
-
-    - `MiniGrid-MultiRoom-N2-S4-v0` (two small rooms)
-    - `MiniGrid-MultiRoom-N4-S5-v0` (four rooms)
-    - `MiniGrid-MultiRoom-N6-v0` (six rooms)
-
-    """
-
-    def __init__(
-        self,
-        minNumRooms,
-        maxNumRooms,
-        maxRoomSize=10,
-        max_steps: int | None = None,
-        **kwargs,
-    ):
-        assert minNumRooms > 0
-        assert maxNumRooms >= minNumRooms
-        assert maxRoomSize >= 4
-
-        self.minNumRooms = minNumRooms
-        self.maxNumRooms = maxNumRooms
-        self.maxRoomSize = maxRoomSize
-
-        self.rooms = []
-
-        mission_space = MissionSpace(mission_func=self._gen_mission)
-
-        self.size = 25
-
-        if max_steps is None:
-            max_steps = maxNumRooms * 20
-
-        super().__init__(
-            mission_space=mission_space,
-            width=self.size,
-            height=self.size,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission():
-        return "traverse the rooms to get to the goal"
-
-    def _gen_grid(self, width, height):
-        roomList = []
-
-        # Choose a random number of rooms to generate
-        numRooms = self._rand_int(self.minNumRooms, self.maxNumRooms + 1)
-
-        while len(roomList) < numRooms:
-            curRoomList = []
-
-            entryDoorPos = (self._rand_int(0, width - 2), self._rand_int(0, width - 2))
-
-            # Recursively place the rooms
-            self._placeRoom(
-                numRooms,
-                roomList=curRoomList,
-                minSz=4,
-                maxSz=self.maxRoomSize,
-                entryDoorWall=2,
-                entryDoorPos=entryDoorPos,
-            )
-
-            if len(curRoomList) > len(roomList):
-                roomList = curRoomList
-
-        # Store the list of rooms in this environment
-        assert len(roomList) > 0
-        self.rooms = roomList
-
-        # Create the grid
-        self.grid = Grid(width, height)
-        wall = Wall()
-
-        prevDoorColor = None
-
-        # For each room
-        for idx, room in enumerate(roomList):
-
-            topX, topY = room.top
-            sizeX, sizeY = room.size
-
-            # Draw the top and bottom walls
-            for i in range(0, sizeX):
-                self.grid.set(topX + i, topY, wall)
-                self.grid.set(topX + i, topY + sizeY - 1, wall)
-
-            # Draw the left and right walls
-            for j in range(0, sizeY):
-                self.grid.set(topX, topY + j, wall)
-                self.grid.set(topX + sizeX - 1, topY + j, wall)
-
-            # If this isn't the first room, place the entry door
-            if idx > 0:
-                # Pick a door color different from the previous one
-                doorColors = set(COLOR_NAMES)
-                if prevDoorColor:
-                    doorColors.remove(prevDoorColor)
-                # Note: the use of sorting here guarantees determinism,
-                # This is needed because Python's set is not deterministic
-                doorColor = self._rand_elem(sorted(doorColors))
-
-                entryDoor = Door(doorColor)
-                self.grid.set(room.entryDoorPos[0], room.entryDoorPos[1], entryDoor)
-                prevDoorColor = doorColor
-
-                prevRoom = roomList[idx - 1]
-                prevRoom.exitDoorPos = room.entryDoorPos
-
-        # Randomize the starting agent position and direction
-        self.place_agent(roomList[0].top, roomList[0].size)
-
-        # Place the final goal in the last room
-        self.goal_pos = self.place_obj(Goal(), roomList[-1].top, roomList[-1].size)
-
-        self.mission = "traverse the rooms to get to the goal"
-
-    def _placeRoom(self, numLeft, roomList, minSz, maxSz, entryDoorWall, entryDoorPos):
-        # Choose the room size randomly
-        sizeX = self._rand_int(minSz, maxSz + 1)
-        sizeY = self._rand_int(minSz, maxSz + 1)
-
-        # The first room will be at the door position
-        if len(roomList) == 0:
-            topX, topY = entryDoorPos
-        # Entry on the right
-        elif entryDoorWall == 0:
-            topX = entryDoorPos[0] - sizeX + 1
-            y = entryDoorPos[1]
-            topY = self._rand_int(y - sizeY + 2, y)
-        # Entry wall on the south
-        elif entryDoorWall == 1:
-            x = entryDoorPos[0]
-            topX = self._rand_int(x - sizeX + 2, x)
-            topY = entryDoorPos[1] - sizeY + 1
-        # Entry wall on the left
-        elif entryDoorWall == 2:
-            topX = entryDoorPos[0]
-            y = entryDoorPos[1]
-            topY = self._rand_int(y - sizeY + 2, y)
-        # Entry wall on the top
-        elif entryDoorWall == 3:
-            x = entryDoorPos[0]
-            topX = self._rand_int(x - sizeX + 2, x)
-            topY = entryDoorPos[1]
-        else:
-            assert False, entryDoorWall
-
-        # If the room is out of the grid, can't place a room here
-        if topX < 0 or topY < 0:
-            return False
-        if topX + sizeX > self.width or topY + sizeY >= self.height:
-            return False
-
-        # If the room intersects with previous rooms, can't place it here
-        for room in roomList[:-1]:
-            nonOverlap = (
-                topX + sizeX < room.top[0]
-                or room.top[0] + room.size[0] <= topX
-                or topY + sizeY < room.top[1]
-                or room.top[1] + room.size[1] <= topY
-            )
-
-            if not nonOverlap:
-                return False
-
-        # Add this room to the list
-        roomList.append(MultiRoom((topX, topY), (sizeX, sizeY), entryDoorPos, None))
-
-        # If this was the last room, stop
-        if numLeft == 1:
-            return True
-
-        # Try placing the next room
-        for i in range(0, 8):
-
-            # Pick which wall to place the out door on
-            wallSet = {0, 1, 2, 3}
-            wallSet.remove(entryDoorWall)
-            exitDoorWall = self._rand_elem(sorted(wallSet))
-            nextEntryWall = (exitDoorWall + 2) % 4
-
-            # Pick the exit door position
-            # Exit on right wall
-            if exitDoorWall == 0:
-                exitDoorPos = (topX + sizeX - 1, topY + self._rand_int(1, sizeY - 1))
-            # Exit on south wall
-            elif exitDoorWall == 1:
-                exitDoorPos = (topX + self._rand_int(1, sizeX - 1), topY + sizeY - 1)
-            # Exit on left wall
-            elif exitDoorWall == 2:
-                exitDoorPos = (topX, topY + self._rand_int(1, sizeY - 1))
-            # Exit on north wall
-            elif exitDoorWall == 3:
-                exitDoorPos = (topX + self._rand_int(1, sizeX - 1), topY)
-            else:
-                assert False
-
-            # Recursively create the other rooms
-            success = self._placeRoom(
-                numLeft - 1,
-                roomList=roomList,
-                minSz=minSz,
-                maxSz=maxSz,
-                entryDoorWall=nextEntryWall,
-                entryDoorPos=exitDoorPos,
-            )
-
-            if success:
-                break
-
-        return True
diff --git a/rl-starter-files/Minigrid/minigrid/envs/obstructedmaze.py b/rl-starter-files/Minigrid/minigrid/envs/obstructedmaze.py
deleted file mode 100644
index 17b9954..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/obstructedmaze.py
+++ /dev/null
@@ -1,271 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.constants import COLOR_NAMES, DIR_TO_VEC
-from minigrid.core.mission import MissionSpace
-from minigrid.core.roomgrid import RoomGrid
-from minigrid.core.world_object import Ball, Box, Key
-
-
-class ObstructedMazeEnv(RoomGrid):
-
-    """
-    ## Description
-
-    The agent has to pick up a box which is placed in a corner of a 3x3 maze.
-    The doors are locked, the keys are hidden in boxes and doors are obstructed
-    by balls. This environment can be solved without relying on language.
-
-    ## Mission Space
-
-    "pick up the {COLOR_NAMES[0]} ball"
-
-    ## Action Space
-
-    | Num | Name         | Action                    |
-    |-----|--------------|---------------------------|
-    | 0   | left         | Turn left                 |
-    | 1   | right        | Turn right                |
-    | 2   | forward      | Move forward              |
-    | 3   | pickup       | Pick up an object         |
-    | 4   | drop         | Unused                    |
-    | 5   | toggle       | Toggle/activate an object |
-    | 6   | done         | Unused                    |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the blue ball.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    "NDl" are the number of doors locked.
-    "h" if the key is hidden in a box.
-    "b" if the door is obstructed by a ball.
-    "Q" number of quarters that will have doors and keys out of the 9 that the
-    map already has.
-    "Full" 3x3 maze with "h" and "b" options.
-    "v1" prevents the key from being covered by the blocking ball. Only 2Dlhb, 1Q, 2Q, and Full are
-    updated to v1. Other configurations won't face this issue because there is no blocking ball (1Dl,
-    1Dlh, 2Dl, 2Dlh) or the only blocking ball is added before the key (1Dlhb).
-
-    - `MiniGrid-ObstructedMaze-1Dl-v0`
-    - `MiniGrid-ObstructedMaze-1Dlh-v0`
-    - `MiniGrid-ObstructedMaze-1Dlhb-v0`
-    - `MiniGrid-ObstructedMaze-2Dl-v0`
-    - `MiniGrid-ObstructedMaze-2Dlh-v0`
-    - `MiniGrid-ObstructedMaze-2Dlhb-v0`
-    - `MiniGrid-ObstructedMaze-2Dlhb-v1`
-    - `MiniGrid-ObstructedMaze-1Q-v0`
-    - `MiniGrid-ObstructedMaze-1Q-v1`
-    - `MiniGrid-ObstructedMaze-2Q-v0`
-    - `MiniGrid-ObstructedMaze-2Q-v1`
-    - `MiniGrid-ObstructedMaze-Full-v0`
-    - `MiniGrid-ObstructedMaze-Full-v1`
-
-    """
-
-    def __init__(
-        self,
-        num_rows,
-        num_cols,
-        num_rooms_visited,
-        max_steps: int | None = None,
-        **kwargs,
-    ):
-        room_size = 6
-
-        if max_steps is None:
-            max_steps = 4 * num_rooms_visited * room_size**2
-
-        mission_space = MissionSpace(
-            mission_func=self._gen_mission,
-            ordered_placeholders=[[COLOR_NAMES[0]]],
-        )
-        super().__init__(
-            mission_space=mission_space,
-            room_size=room_size,
-            num_rows=num_rows,
-            num_cols=num_cols,
-            max_steps=max_steps,
-            **kwargs,
-        )
-        self.obj = Ball()  # initialize the obj attribute, that will be changed later on
-
-    @staticmethod
-    def _gen_mission(color: str):
-        return f"pick up the {color} ball"
-
-    def _gen_grid(self, width, height):
-        super()._gen_grid(width, height)
-
-        # Define all possible colors for doors
-        self.door_colors = self._rand_subset(COLOR_NAMES, len(COLOR_NAMES))
-        # Define the color of the ball to pick up
-        self.ball_to_find_color = COLOR_NAMES[0]
-        # Define the color of the balls that obstruct doors
-        self.blocking_ball_color = COLOR_NAMES[1]
-        # Define the color of boxes in which keys are hidden
-        self.box_color = COLOR_NAMES[2]
-
-        self.mission = "pick up the %s ball" % self.ball_to_find_color
-
-    def step(self, action):
-        obs, reward, terminated, truncated, info = super().step(action)
-
-        if action == self.actions.pickup:
-            if self.carrying and self.carrying == self.obj:
-                reward = self._reward()
-                terminated = True
-
-        return obs, reward, terminated, truncated, info
-
-    def add_door(
-        self,
-        i,
-        j,
-        door_idx=0,
-        color=None,
-        locked=False,
-        key_in_box=False,
-        blocked=False,
-    ):
-        """
-        Add a door. If the door must be locked, it also adds the key.
-        If the key must be hidden, it is put in a box. If the door must
-        be obstructed, it adds a ball in front of the door.
-        """
-
-        door, door_pos = super().add_door(i, j, door_idx, color, locked=locked)
-
-        if blocked:
-            vec = DIR_TO_VEC[door_idx]
-            blocking_ball = Ball(self.blocking_ball_color) if blocked else None
-            self.grid.set(door_pos[0] - vec[0], door_pos[1] - vec[1], blocking_ball)
-
-        if locked:
-            obj = Key(door.color)
-            if key_in_box:
-                box = Box(self.box_color)
-                box.contains = obj
-                obj = box
-            self.place_in_room(i, j, obj)
-
-        return door, door_pos
-
-
-class ObstructedMaze_1Dlhb(ObstructedMazeEnv):
-    """
-    A blue ball is hidden in a 2x1 maze. A locked door separates
-    rooms. Doors are obstructed by a ball and keys are hidden in boxes.
-    """
-
-    def __init__(self, key_in_box=True, blocked=True, **kwargs):
-        self.key_in_box = key_in_box
-        self.blocked = blocked
-
-        super().__init__(num_rows=1, num_cols=2, num_rooms_visited=2, **kwargs)
-
-    def _gen_grid(self, width, height):
-        super()._gen_grid(width, height)
-
-        self.add_door(
-            0,
-            0,
-            door_idx=0,
-            color=self.door_colors[0],
-            locked=True,
-            key_in_box=self.key_in_box,
-            blocked=self.blocked,
-        )
-
-        self.obj, _ = self.add_object(1, 0, "ball", color=self.ball_to_find_color)
-        self.place_agent(0, 0)
-
-
-class ObstructedMaze_Full(ObstructedMazeEnv):
-    """
-    A blue ball is hidden in one of the 4 corners of a 3x3 maze. Doors
-    are locked, doors are obstructed by a ball and keys are hidden in
-    boxes.
-    """
-
-    def __init__(
-        self,
-        agent_room=(1, 1),
-        key_in_box=True,
-        blocked=True,
-        num_quarters=4,
-        num_rooms_visited=25,
-        **kwargs,
-    ):
-        self.agent_room = agent_room
-        self.key_in_box = key_in_box
-        self.blocked = blocked
-        self.num_quarters = num_quarters
-
-        super().__init__(
-            num_rows=3, num_cols=3, num_rooms_visited=num_rooms_visited, **kwargs
-        )
-
-    def _gen_grid(self, width, height):
-        super()._gen_grid(width, height)
-
-        middle_room = (1, 1)
-        # Define positions of "side rooms" i.e. rooms that are neither
-        # corners nor the center.
-        side_rooms = [(2, 1), (1, 2), (0, 1), (1, 0)][: self.num_quarters]
-        for i in range(len(side_rooms)):
-            side_room = side_rooms[i]
-
-            # Add a door between the center room and the side room
-            self.add_door(
-                *middle_room, door_idx=i, color=self.door_colors[i], locked=False
-            )
-
-            for k in [-1, 1]:
-                # Add a door to each side of the side room
-                self.add_door(
-                    *side_room,
-                    locked=True,
-                    door_idx=(i + k) % 4,
-                    color=self.door_colors[(i + k) % len(self.door_colors)],
-                    key_in_box=self.key_in_box,
-                    blocked=self.blocked,
-                )
-
-        corners = [(2, 0), (2, 2), (0, 2), (0, 0)][: self.num_quarters]
-        ball_room = self._rand_elem(corners)
-
-        self.obj, _ = self.add_object(
-            ball_room[0], ball_room[1], "ball", color=self.ball_to_find_color
-        )
-        self.place_agent(*self.agent_room)
-
-
-class ObstructedMaze_2Dl(ObstructedMaze_Full):
-    def __init__(self, **kwargs):
-        super().__init__((2, 1), False, False, 1, 4, **kwargs)
-
-
-class ObstructedMaze_2Dlh(ObstructedMaze_Full):
-    def __init__(self, **kwargs):
-        super().__init__((2, 1), True, False, 1, 4, **kwargs)
-
-
-class ObstructedMaze_2Dlhb(ObstructedMaze_Full):
-    def __init__(self, **kwargs):
-        super().__init__((2, 1), True, True, 1, 4, **kwargs)
diff --git a/rl-starter-files/Minigrid/minigrid/envs/obstructedmaze_v1.py b/rl-starter-files/Minigrid/minigrid/envs/obstructedmaze_v1.py
deleted file mode 100644
index 08f6022..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/obstructedmaze_v1.py
+++ /dev/null
@@ -1,99 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.constants import DIR_TO_VEC
-from minigrid.core.roomgrid import RoomGrid
-from minigrid.core.world_object import Ball, Box, Key
-from minigrid.envs.obstructedmaze import ObstructedMazeEnv
-
-
-class ObstructedMaze_Full(ObstructedMazeEnv):
-    """
-    A blue ball is hidden in one of the 4 corners of a 3x3 maze. Doors
-    are locked, doors are obstructed by a ball and keys are hidden in
-    boxes.
-
-    All doors and their corresponding blocking balls will be added first,
-    followed by the boxes containing the keys.
-    """
-
-    def __init__(
-        self,
-        agent_room=(1, 1),
-        key_in_box=True,
-        blocked=True,
-        num_quarters=4,
-        num_rooms_visited=25,
-        **kwargs,
-    ):
-        self.agent_room = agent_room
-        self.key_in_box = key_in_box
-        self.blocked = blocked
-        self.num_quarters = num_quarters
-
-        super().__init__(
-            num_rows=3, num_cols=3, num_rooms_visited=num_rooms_visited, **kwargs
-        )
-
-    def _gen_grid(self, width, height):
-        super()._gen_grid(width, height)
-
-        middle_room = (1, 1)
-        # Define positions of "side rooms" i.e. rooms that are neither
-        # corners nor the center.
-        side_rooms = [(2, 1), (1, 2), (0, 1), (1, 0)][: self.num_quarters]
-        for i in range(len(side_rooms)):
-            side_room = side_rooms[i]
-
-            # Add a door between the center room and the side room
-            self.add_door(
-                *middle_room, door_idx=i, color=self.door_colors[i], locked=False
-            )
-
-            for k in [-1, 1]:
-                # Add a door to each side of the side room w/o placing a key
-                self.add_locked_door(
-                    *side_room,
-                    door_idx=(i + k) % 4,
-                    color=self.door_colors[(i + k) % len(self.door_colors)],
-                    blocked=self.blocked,
-                )
-
-            # Add keys after all doors and their blocking balls are added
-            for k in [-1, 1]:
-                self.add_key(
-                    *side_room,
-                    color=self.door_colors[(i + k) % len(self.door_colors)],
-                    key_in_box=self.key_in_box,
-                )
-
-        corners = [(2, 0), (2, 2), (0, 2), (0, 0)][: self.num_quarters]
-        ball_room = self._rand_elem(corners)
-
-        self.obj, _ = self.add_object(
-            ball_room[0], ball_room[1], "ball", color=self.ball_to_find_color
-        )
-        self.place_agent(*self.agent_room)
-
-    def add_locked_door(self, i, j, door_idx=0, color=None, blocked=False):
-        door, door_pos = RoomGrid.add_door(self, i, j, door_idx, color, locked=True)
-
-        if blocked:
-            vec = DIR_TO_VEC[door_idx]
-            blocking_ball = Ball(self.blocking_ball_color) if blocked else None
-            self.grid.set(door_pos[0] - vec[0], door_pos[1] - vec[1], blocking_ball)
-
-        return door, door_pos
-
-    def add_key(
-        self,
-        i,
-        j,
-        color=None,
-        key_in_box=False,
-    ):
-        obj = Key(color)
-        if key_in_box:
-            box = Box(self.box_color)
-            box.contains = obj
-            obj = box
-        self.place_in_room(i, j, obj)
diff --git a/rl-starter-files/Minigrid/minigrid/envs/playground.py b/rl-starter-files/Minigrid/minigrid/envs/playground.py
deleted file mode 100644
index 0a0341c..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/playground.py
+++ /dev/null
@@ -1,91 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.constants import COLOR_NAMES
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Ball, Box, Door, Key
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class PlaygroundEnv(MiniGridEnv):
-    """
-    Environment with multiple rooms and random objects.
-    This environment has no specific goals or rewards.
-    """
-
-    def __init__(self, max_steps=100, **kwargs):
-        mission_space = MissionSpace(mission_func=self._gen_mission)
-        self.size = 19
-        super().__init__(
-            mission_space=mission_space,
-            width=self.size,
-            height=self.size,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission():
-        return ""
-
-    def _gen_grid(self, width, height):
-        # Create the grid
-        self.grid = Grid(width, height)
-
-        # Generate the surrounding walls
-        self.grid.horz_wall(0, 0)
-        self.grid.horz_wall(0, height - 1)
-        self.grid.vert_wall(0, 0)
-        self.grid.vert_wall(width - 1, 0)
-
-        roomW = width // 3
-        roomH = height // 3
-
-        # For each row of rooms
-        for j in range(0, 3):
-
-            # For each column
-            for i in range(0, 3):
-                xL = i * roomW
-                yT = j * roomH
-                xR = xL + roomW
-                yB = yT + roomH
-
-                # Bottom wall and door
-                if i + 1 < 3:
-                    self.grid.vert_wall(xR, yT, roomH)
-                    pos = (xR, self._rand_int(yT + 1, yB - 1))
-                    color = self._rand_elem(COLOR_NAMES)
-                    self.grid.set(*pos, Door(color))
-
-                # Bottom wall and door
-                if j + 1 < 3:
-                    self.grid.horz_wall(xL, yB, roomW)
-                    pos = (self._rand_int(xL + 1, xR - 1), yB)
-                    color = self._rand_elem(COLOR_NAMES)
-                    self.grid.set(*pos, Door(color))
-
-        # Randomize the player start position and orientation
-        self.place_agent()
-
-        # Place random objects in the world
-        types = ["key", "ball", "box"]
-        for i in range(0, 12):
-            objType = self._rand_elem(types)
-            objColor = self._rand_elem(COLOR_NAMES)
-            if objType == "key":
-                obj = Key(objColor)
-            elif objType == "ball":
-                obj = Ball(objColor)
-            elif objType == "box":
-                obj = Box(objColor)
-            else:
-                raise ValueError(
-                    "{} object type given. Object type can only be of values key, ball and box.".format(
-                        objType
-                    )
-                )
-            self.place_obj(obj)
-
-        # No explicit mission in this environment
-        self.mission = ""
diff --git a/rl-starter-files/Minigrid/minigrid/envs/putnear.py b/rl-starter-files/Minigrid/minigrid/envs/putnear.py
deleted file mode 100644
index d7104fd..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/putnear.py
+++ /dev/null
@@ -1,200 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.constants import COLOR_NAMES
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Ball, Box, Key
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class PutNearEnv(MiniGridEnv):
-
-    """
-    ## Description
-
-    The agent is instructed through a textual string to pick up an object and
-    place it next to another object. This environment is easy to solve with two
-    objects, but difficult to solve with more, as it involves both textual
-    understanding and spatial reasoning involving multiple objects.
-
-    ## Mission Space
-
-    "put the {move_color} {move_type} near the {target_color} {target_type}"
-
-    {move_color} and {target_color} can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    {move_type} and {target_type} Can be "box", "ball" or "key".
-
-    ## Action Space
-
-    | Num | Name         | Action            |
-    |-----|--------------|-------------------|
-    | 0   | left         | Turn left         |
-    | 1   | right        | Turn right        |
-    | 2   | forward      | Move forward      |
-    | 3   | pickup       | Pick up an object |
-    | 4   | drop         | Drop an object    |
-    | 5   | toggle       | Unused            |
-    | 6   | done         | Unused            |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the wrong object.
-    2. The agent drop the correct object near the target.
-    3. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    N: number of objects.
-
-    - `MiniGrid-PutNear-6x6-N2-v0`
-    - `MiniGrid-PutNear-8x8-N3-v0`
-
-    """
-
-    def __init__(self, size=6, numObjs=2, max_steps: int | None = None, **kwargs):
-        self.size = size
-        self.numObjs = numObjs
-        self.obj_types = ["key", "ball", "box"]
-        mission_space = MissionSpace(
-            mission_func=self._gen_mission,
-            ordered_placeholders=[
-                COLOR_NAMES,
-                self.obj_types,
-                COLOR_NAMES,
-                self.obj_types,
-            ],
-        )
-
-        if max_steps is None:
-            max_steps = 5 * size
-
-        super().__init__(
-            mission_space=mission_space,
-            width=size,
-            height=size,
-            # Set this to True for maximum speed
-            see_through_walls=True,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission(
-        move_color: str, move_type: str, target_color: str, target_type: str
-    ):
-        return f"put the {move_color} {move_type} near the {target_color} {target_type}"
-
-    def _gen_grid(self, width, height):
-        self.grid = Grid(width, height)
-
-        # Generate the surrounding walls
-        self.grid.horz_wall(0, 0)
-        self.grid.horz_wall(0, height - 1)
-        self.grid.vert_wall(0, 0)
-        self.grid.vert_wall(width - 1, 0)
-
-        # Types and colors of objects we can generate
-        types = ["key", "ball", "box"]
-
-        objs = []
-        objPos = []
-
-        def near_obj(env, p1):
-            for p2 in objPos:
-                dx = p1[0] - p2[0]
-                dy = p1[1] - p2[1]
-                if abs(dx) <= 1 and abs(dy) <= 1:
-                    return True
-            return False
-
-        # Until we have generated all the objects
-        while len(objs) < self.numObjs:
-            objType = self._rand_elem(types)
-            objColor = self._rand_elem(COLOR_NAMES)
-
-            # If this object already exists, try again
-            if (objType, objColor) in objs:
-                continue
-
-            if objType == "key":
-                obj = Key(objColor)
-            elif objType == "ball":
-                obj = Ball(objColor)
-            elif objType == "box":
-                obj = Box(objColor)
-            else:
-                raise ValueError(
-                    "{} object type given. Object type can only be of values key, ball and box.".format(
-                        objType
-                    )
-                )
-
-            pos = self.place_obj(obj, reject_fn=near_obj)
-
-            objs.append((objType, objColor))
-            objPos.append(pos)
-
-        # Randomize the agent start position and orientation
-        self.place_agent()
-
-        # Choose a random object to be moved
-        objIdx = self._rand_int(0, len(objs))
-        self.move_type, self.moveColor = objs[objIdx]
-        self.move_pos = objPos[objIdx]
-
-        # Choose a target object (to put the first object next to)
-        while True:
-            targetIdx = self._rand_int(0, len(objs))
-            if targetIdx != objIdx:
-                break
-        self.target_type, self.target_color = objs[targetIdx]
-        self.target_pos = objPos[targetIdx]
-
-        self.mission = "put the {} {} near the {} {}".format(
-            self.moveColor,
-            self.move_type,
-            self.target_color,
-            self.target_type,
-        )
-
-    def step(self, action):
-        preCarrying = self.carrying
-
-        obs, reward, terminated, truncated, info = super().step(action)
-
-        u, v = self.dir_vec
-        ox, oy = (self.agent_pos[0] + u, self.agent_pos[1] + v)
-        tx, ty = self.target_pos
-
-        # If we picked up the wrong object, terminate the episode
-        if action == self.actions.pickup and self.carrying:
-            if (
-                self.carrying.type != self.move_type
-                or self.carrying.color != self.moveColor
-            ):
-                terminated = True
-
-        # If successfully dropping an object near the target
-        if action == self.actions.drop and preCarrying:
-            if self.grid.get(ox, oy) is preCarrying:
-                if abs(ox - tx) <= 1 and abs(oy - ty) <= 1:
-                    reward = self._reward()
-            terminated = True
-
-        return obs, reward, terminated, truncated, info
diff --git a/rl-starter-files/Minigrid/minigrid/envs/redbluedoors.py b/rl-starter-files/Minigrid/minigrid/envs/redbluedoors.py
deleted file mode 100644
index e59f58c..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/redbluedoors.py
+++ /dev/null
@@ -1,127 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Door
-from minigrid.minigrid_env import MiniGridEnv
-
-
-class RedBlueDoorEnv(MiniGridEnv):
-
-    """
-    ## Description
-
-    The agent is randomly placed within a room with one red and one blue door
-    facing opposite directions. The agent has to open the red door and then open
-    the blue door, in that order. Note that, surprisingly, this environment is
-    solvable without memory.
-
-    ## Mission Space
-
-    "open the red door then the blue door"
-
-    ## Action Space
-
-    | Num | Name         | Action                    |
-    |-----|--------------|---------------------------|
-    | 0   | left         | Turn left                 |
-    | 1   | right        | Turn right                |
-    | 2   | forward      | Move forward              |
-    | 3   | pickup       | Unused                    |
-    | 4   | drop         | Unused                    |
-    | 5   | toggle       | Toggle/activate an object |
-    | 6   | done         | Unused                    |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent opens the blue door having already opened the red door.
-    2. The agent opens the blue door without having opened the red door yet.
-    3. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `MiniGrid-RedBlueDoors-6x6-v0`
-    - `MiniGrid-RedBlueDoors-8x8-v0`
-
-    """
-
-    def __init__(self, size=8, max_steps: int | None = None, **kwargs):
-        self.size = size
-        mission_space = MissionSpace(mission_func=self._gen_mission)
-
-        if max_steps is None:
-            max_steps = 20 * size**2
-
-        super().__init__(
-            mission_space=mission_space,
-            width=2 * size,
-            height=size,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission():
-        return "open the red door then the blue door"
-
-    def _gen_grid(self, width, height):
-        # Create an empty grid
-        self.grid = Grid(width, height)
-
-        # Generate the grid walls
-        self.grid.wall_rect(0, 0, 2 * self.size, self.size)
-        self.grid.wall_rect(self.size // 2, 0, self.size, self.size)
-
-        # Place the agent in the top-left corner
-        self.place_agent(top=(self.size // 2, 0), size=(self.size, self.size))
-
-        # Add a red door at a random position in the left wall
-        pos = self._rand_int(1, self.size - 1)
-        self.red_door = Door("red")
-        self.grid.set(self.size // 2, pos, self.red_door)
-
-        # Add a blue door at a random position in the right wall
-        pos = self._rand_int(1, self.size - 1)
-        self.blue_door = Door("blue")
-        self.grid.set(self.size // 2 + self.size - 1, pos, self.blue_door)
-
-        # Generate the mission string
-        self.mission = "open the red door then the blue door"
-
-    def step(self, action):
-        red_door_opened_before = self.red_door.is_open
-        blue_door_opened_before = self.blue_door.is_open
-
-        obs, reward, terminated, truncated, info = super().step(action)
-
-        red_door_opened_after = self.red_door.is_open
-        blue_door_opened_after = self.blue_door.is_open
-
-        if blue_door_opened_after:
-            if red_door_opened_before:
-                reward = self._reward()
-                terminated = True
-            else:
-                reward = 0
-                terminated = True
-
-        elif red_door_opened_after:
-            if blue_door_opened_before:
-                reward = 0
-                terminated = True
-
-        return obs, reward, terminated, truncated, info
diff --git a/rl-starter-files/Minigrid/minigrid/envs/unlock.py b/rl-starter-files/Minigrid/minigrid/envs/unlock.py
deleted file mode 100644
index 0b2e06b..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/unlock.py
+++ /dev/null
@@ -1,97 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.mission import MissionSpace
-from minigrid.core.roomgrid import RoomGrid
-
-
-class UnlockEnv(RoomGrid):
-
-    """
-    ## Description
-
-    The agent has to open a locked door. This environment can be solved without
-    relying on language.
-
-    ## Mission Space
-
-    "open the door"
-
-    ## Action Space
-
-    | Num | Name         | Action                    |
-    |-----|--------------|---------------------------|
-    | 0   | left         | Turn left                 |
-    | 1   | right        | Turn right                |
-    | 2   | forward      | Move forward              |
-    | 3   | pickup       | Unused                    |
-    | 4   | drop         | Unused                    |
-    | 5   | toggle       | Toggle/activate an object |
-    | 6   | done         | Unused                    |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent opens the door.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `MiniGrid-Unlock-v0`
-
-    """
-
-    def __init__(self, max_steps: int | None = None, **kwargs):
-        room_size = 6
-        mission_space = MissionSpace(mission_func=self._gen_mission)
-
-        if max_steps is None:
-            max_steps = 8 * room_size**2
-
-        super().__init__(
-            mission_space=mission_space,
-            num_rows=1,
-            num_cols=2,
-            room_size=room_size,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission():
-        return "open the door"
-
-    def _gen_grid(self, width, height):
-        super()._gen_grid(width, height)
-
-        # Make sure the two rooms are directly connected by a locked door
-        door, _ = self.add_door(0, 0, 0, locked=True)
-        # Add a key to unlock the door
-        self.add_object(0, 0, "key", door.color)
-
-        self.place_agent(0, 0)
-
-        self.door = door
-        self.mission = "open the door"
-
-    def step(self, action):
-        obs, reward, terminated, truncated, info = super().step(action)
-
-        if action == self.actions.toggle:
-            if self.door.is_open:
-                reward = self._reward()
-                terminated = True
-
-        return obs, reward, terminated, truncated, info
diff --git a/rl-starter-files/Minigrid/minigrid/envs/unlockpickup.py b/rl-starter-files/Minigrid/minigrid/envs/unlockpickup.py
deleted file mode 100644
index 820ce4c..0000000
--- a/rl-starter-files/Minigrid/minigrid/envs/unlockpickup.py
+++ /dev/null
@@ -1,106 +0,0 @@
-from __future__ import annotations
-
-from minigrid.core.constants import COLOR_NAMES
-from minigrid.core.mission import MissionSpace
-from minigrid.core.roomgrid import RoomGrid
-
-
-class UnlockPickupEnv(RoomGrid):
-
-    """
-    ## Description
-
-    The agent has to pick up a box which is placed in another room, behind a
-    locked door. This environment can be solved without relying on language.
-
-    ## Mission Space
-
-    "pick up the {color} box"
-
-    {color} is the color of the box. Can be "red", "green", "blue", "purple",
-    "yellow" or "grey".
-
-    ## Action Space
-
-    | Num | Name         | Action                    |
-    |-----|--------------|---------------------------|
-    | 0   | left         | Turn left                 |
-    | 1   | right        | Turn right                |
-    | 2   | forward      | Move forward              |
-    | 3   | pickup       | Pick up an object         |
-    | 4   | drop         | Unused                    |
-    | 5   | toggle       | Toggle/activate an object |
-    | 6   | done         | Unused                    |
-
-    ## Observation Encoding
-
-    - Each tile is encoded as a 3 dimensional tuple:
-        `(OBJECT_IDX, COLOR_IDX, STATE)`
-    - `OBJECT_TO_IDX` and `COLOR_TO_IDX` mapping can be found in
-        [minigrid/minigrid.py](minigrid/minigrid.py)
-    - `STATE` refers to the door state with 0=open, 1=closed and 2=locked
-
-    ## Rewards
-
-    A reward of '1 - 0.9 * (step_count / max_steps)' is given for success, and '0' for failure.
-
-    ## Termination
-
-    The episode ends if any one of the following conditions is met:
-
-    1. The agent picks up the correct box.
-    2. Timeout (see `max_steps`).
-
-    ## Registered Configurations
-
-    - `MiniGrid-Unlock-v0`
-
-    """
-
-    def __init__(self, max_steps: int | None = None, **kwargs):
-        room_size = 6
-        mission_space = MissionSpace(
-            mission_func=self._gen_mission,
-            ordered_placeholders=[COLOR_NAMES],
-        )
-
-        if max_steps is None:
-            max_steps = 8 * room_size**2
-
-        super().__init__(
-            mission_space=mission_space,
-            num_rows=1,
-            num_cols=2,
-            room_size=room_size,
-            max_steps=max_steps,
-            **kwargs,
-        )
-
-    @staticmethod
-    def _gen_mission(color: str):
-        return f"pick up the {color} box"
-
-    def _gen_grid(self, width, height):
-        super()._gen_grid(width, height)
-
-        # Add a box to the room on the right
-        obj, _ = self.add_object(1, 0, kind="box")
-        # Make sure the two rooms are directly connected by a locked door
-        door, _ = self.add_door(0, 0, 0, locked=True)
-        # Add a key to unlock the door
-        self.add_object(0, 0, "key", door.color)
-
-        self.place_agent(0, 0)
-
-        self.obj = obj
-        self.mission = f"pick up the {obj.color} {obj.type}"
-
-    def step(self, action):
-        obs, reward, terminated, truncated, info = super().step(action)
-
-        if action == self.actions.pickup:
-            if self.carrying and self.carrying == self.obj:
-                reward = self._reward()
-                terminated = True
-
-        return obs, reward, terminated, truncated, info
diff --git a/rl-starter-files/Minigrid/minigrid/manual_control.py b/rl-starter-files/Minigrid/minigrid/manual_control.py
deleted file mode 100755
index 07be2e0..0000000
--- a/rl-starter-files/Minigrid/minigrid/manual_control.py
+++ /dev/null
@@ -1,139 +0,0 @@
-#!/usr/bin/env python3
-
-from __future__ import annotations
-
-import gymnasium as gym
-import pygame
-from gymnasium import Env
-
-from minigrid.core.actions import Actions
-from minigrid.minigrid_env import MiniGridEnv
-from minigrid.wrappers import ImgObsWrapper, RGBImgPartialObsWrapper
-
-
-class ManualControl:
-    def __init__(
-        self,
-        env: Env,
-        seed=None,
-    ) -> None:
-        self.env = env
-        self.seed = seed
-        self.closed = False
-
-    def start(self):
-        """Start the window display with blocking event loop"""
-        self.reset(self.seed)
-
-        while not self.closed:
-            for event in pygame.event.get():
-                if event.type == pygame.QUIT:
-                    self.env.close()
-                    break
-                if event.type == pygame.KEYDOWN:
-                    event.key = pygame.key.name(int(event.key))
-                    self.key_handler(event)
-
-    def step(self, action: Actions):
-        _, reward, terminated, truncated, _ = self.env.step(action)
-        print(f"step={self.env.step_count}, reward={reward:.2f}")
-
-        if terminated:
-            print("terminated!")
-            self.reset(self.seed)
-        elif truncated:
-            print("truncated!")
-            self.reset(self.seed)
-        else:
-            self.env.render()
-
-    def reset(self, seed=None):
-        self.env.reset(seed=seed)
-        self.env.render()
-
-    def key_handler(self, event):
-        key: str = event.key
-        print("pressed", key)
-
-        if key == "escape":
-            self.env.close()
-            return
-        if key == "backspace":
-            self.reset()
-            return
-
-        key_to_action = {
-            "left": Actions.left,
-            "right": Actions.right,
-            "up": Actions.forward,
-            "space": Actions.toggle,
-            "pageup": Actions.pickup,
-            "pagedown": Actions.drop,
-            "tab": Actions.pickup,
-            "left shift": Actions.drop,
-            "enter": Actions.done,
-        }
-        if key in key_to_action.keys():
-            action = key_to_action[key]
-            self.step(action)
-        else:
-            print(key)
-
-
-if __name__ == "__main__":
-    import argparse
-
-    parser = argparse.ArgumentParser()
-    parser.add_argument(
-        "--env-id",
-        type=str,
-        help="gym environment to load",
-        choices=gym.envs.registry.keys(),
-        default="MiniGrid-MultiRoom-N6-v0",
-    )
-    parser.add_argument(
-        "--seed",
-        type=int,
-        help="random seed to generate the environment with",
-        default=None,
-    )
-    parser.add_argument(
-        "--tile-size", type=int, help="size at which to render tiles", default=32
-    )
-    parser.add_argument(
-        "--agent-view",
-        action="store_true",
-        help="draw the agent sees (partially observable view)",
-    )
-    parser.add_argument(
-        "--agent-view-size",
-        type=int,
-        default=7,
-        help="set the number of grid spaces visible in agent-view ",
-    )
-    parser.add_argument(
-        "--screen-size",
-        type=int,
-        default="640",
-        help="set the resolution for pygame rendering (width and height)",
-    )
-
-    args = parser.parse_args()
-
-    env: MiniGridEnv = gym.make(
-        args.env_id,
-        tile_size=args.tile_size,
-        render_mode="human",
-        agent_pov=args.agent_view,
-        agent_view_size=args.agent_view_size,
-        screen_size=args.screen_size,
-    )
-
-    # TODO: check if this can be removed
-    if args.agent_view:
-        print("Using agent view")
-        env = RGBImgPartialObsWrapper(env, args.tile_size)
-        env = ImgObsWrapper(env)
-
-    manual_control = ManualControl(env, seed=args.seed)
-    manual_control.start()
diff --git a/rl-starter-files/Minigrid/minigrid/minigrid_env.py b/rl-starter-files/Minigrid/minigrid/minigrid_env.py
deleted file mode 100755
index 910435f..0000000
--- a/rl-starter-files/Minigrid/minigrid/minigrid_env.py
+++ /dev/null
@@ -1,780 +0,0 @@
-from __future__ import annotations
-
-import hashlib
-import math
-from abc import abstractmethod
-from typing import Any, Iterable, SupportsFloat, TypeVar
-
-import gymnasium as gym
-import numpy as np
-import pygame
-import pygame.freetype
-from gymnasium import spaces
-from gymnasium.core import ActType, ObsType
-
-from minigrid.core.actions import Actions
-from minigrid.core.constants import COLOR_NAMES, DIR_TO_VEC, TILE_PIXELS
-from minigrid.core.grid import Grid
-from minigrid.core.mission import MissionSpace
-from minigrid.core.world_object import Point, WorldObj
-
-T = TypeVar("T")
-
-
-class MiniGridEnv(gym.Env):
-    """
-    2D grid world game environment
-    """
-
-    metadata = {
-        "render_modes": ["human", "rgb_array"],
-        "render_fps": 10,
-    }
-
-    def __init__(
-        self,
-        mission_space: MissionSpace,
-        grid_size: int | None = None,
-        width: int | None = None,
-        height: int | None = None,
-        max_steps: int = 100,
-        see_through_walls: bool = False,
-        agent_view_size: int = 7,
-        render_mode: str | None = None,
-        screen_size: int | None = 640,
-        highlight: bool = True,
-        tile_size: int = TILE_PIXELS,
-        agent_pov: bool = False,
-    ):
-        # Initialize mission
-        self.mission = mission_space.sample()
-
-        # Can't set both grid_size and width/height
-        if grid_size:
-            assert width is None and height is None
-            width = grid_size
-            height = grid_size
-        assert width is not None and height is not None
-
-        # Action enumeration for this environment
-        self.actions = Actions
-
-        # Actions are discrete integer values
-        self.action_space = spaces.Discrete(len(self.actions))
-
-        # Number of cells (width and height) in the agent view
-        assert agent_view_size % 2 == 1
-        assert agent_view_size >= 3
-        self.agent_view_size = agent_view_size
-
-        # Observations are dictionaries containing an
-        # encoding of the grid and a textual 'mission' string
-        image_observation_space = spaces.Box(
-            low=0,
-            high=255,
-            shape=(self.agent_view_size, self.agent_view_size, 3),
-            dtype="uint8",
-        )
-        self.observation_space = spaces.Dict(
-            {
-                "image": image_observation_space,
-                "direction": spaces.Discrete(4),
-                "mission": mission_space,
-            }
-        )
-
-        # Range of possible rewards
-        self.reward_range = (0, 1)
-
-        self.screen_size = screen_size
-        self.render_size = None
-        self.window = None
-        self.clock = None
-
-        # Environment configuration
-        self.width = width
-        self.height = height
-
-        assert isinstance(
-            max_steps, int
-        ), f"The argument max_steps must be an integer, got: {type(max_steps)}"
-        self.max_steps = max_steps
-
-        self.see_through_walls = see_through_walls
-
-        # Current position and direction of the agent
-        self.agent_pos: np.ndarray | tuple[int, int] = None
-        self.agent_dir: int = None
-
-        # Current grid and mission and carrying
-        self.grid = Grid(width, height)
-        self.carrying = None
-
-        # Rendering attributes
-        self.render_mode = render_mode
-        self.highlight = highlight
-        self.tile_size = tile_size
-        self.agent_pov = agent_pov
-
-    def reset(
-        self,
-        *,
-        seed: int | None = None,
-        options: dict[str, Any] | None = None,
-    ) -> tuple[ObsType, dict[str, Any]]:
-        super().reset(seed=seed)
-
-        # Reinitialize episode-specific variables
-        self.agent_pos = (-1, -1)
-        self.agent_dir = -1
-
-        # Generate a new random grid at the start of each episode
-        self._gen_grid(self.width, self.height)
-
-        # These fields should be defined by _gen_grid
-        assert (
-            self.agent_pos >= (0, 0)
-            if isinstance(self.agent_pos, tuple)
-            else all(self.agent_pos >= 0) and self.agent_dir >= 0
-        )
-
-        # Check that the agent doesn't overlap with an object
-        start_cell = self.grid.get(*self.agent_pos)
-        assert start_cell is None or start_cell.can_overlap()
-
-        # Item picked up, being carried, initially nothing
-        self.carrying = None
-
-        # Step count since episode start
-        self.step_count = 0
-
-        if self.render_mode == "human":
-            self.render()
-
-        # Return first observation
-        obs = self.gen_obs()
-
-        return obs, {}
-
-    def hash(self, size=16):
-        """Compute a hash that uniquely identifies the current state of the environment.
-        :param size: Size of the hashing
-        """
-        sample_hash = hashlib.sha256()
-
-        to_encode = [self.grid.encode().tolist(), self.agent_pos, self.agent_dir]
-        for item in to_encode:
-            sample_hash.update(str(item).encode("utf8"))
-
-        return sample_hash.hexdigest()[:size]
-
-    @property
-    def steps_remaining(self):
-        return self.max_steps - self.step_count
-
-    def __str__(self):
-        """
-        Produce a pretty string of the environment's grid along with the agent.
-        A grid cell is represented by 2-character string, the first one for
-        the object and the second one for the color.
-        """
-
-        # Map of object types to short string
-        OBJECT_TO_STR = {
-            "wall": "W",
-            "floor": "F",
-            "door": "D",
-            "key": "K",
-            "ball": "A",
-            "box": "B",
-            "goal": "G",
-            "lava": "V",
-        }
-
-        # Map agent's direction to short string
-        AGENT_DIR_TO_STR = {0: ">", 1: "V", 2: "<", 3: "^"}
-
-        output = ""
-
-        for j in range(self.grid.height):
-            for i in range(self.grid.width):
-                if i == self.agent_pos[0] and j == self.agent_pos[1]:
-                    output += 2 * AGENT_DIR_TO_STR[self.agent_dir]
-                    continue
-
-                tile = self.grid.get(i, j)
-
-                if tile is None:
-                    output += "  "
-                    continue
-
-                if tile.type == "door":
-                    if tile.is_open:
-                        output += "__"
-                    elif tile.is_locked:
-                        output += "L" + tile.color[0].upper()
-                    else:
-                        output += "D" + tile.color[0].upper()
-                    continue
-
-                output += OBJECT_TO_STR[tile.type] + tile.color[0].upper()
-
-            if j < self.grid.height - 1:
-                output += "\n"
-
-        return output
-
-    @abstractmethod
-    def _gen_grid(self, width, height):
-        pass
-
-    def _reward(self) -> float:
-        """
-        Compute the reward to be given upon success
-        """
-
-        return 1 - 0.9 * (self.step_count / self.max_steps)
-
-    def _rand_int(self, low: int, high: int) -> int:
-        """
-        Generate random integer in [low,high[
-        """
-
-        return self.np_random.integers(low, high)
-
-    def _rand_float(self, low: float, high: float) -> float:
-        """
-        Generate random float in [low,high[
-        """
-
-        return self.np_random.uniform(low, high)
-
-    def _rand_bool(self) -> bool:
-        """
-        Generate random boolean value
-        """
-
-        return self.np_random.integers(0, 2) == 0
-
-    def _rand_elem(self, iterable: Iterable[T]) -> T:
-        """
-        Pick a random element in a list
-        """
-
-        lst = list(iterable)
-        idx = self._rand_int(0, len(lst))
-        return lst[idx]
-
-    def _rand_subset(self, iterable: Iterable[T], num_elems: int) -> list[T]:
-        """
-        Sample a random subset of distinct elements of a list
-        """
-
-        lst = list(iterable)
-        assert num_elems <= len(lst)
-
-        out: list[T] = []
-
-        while len(out) < num_elems:
-            elem = self._rand_elem(lst)
-            lst.remove(elem)
-            out.append(elem)
-
-        return out
-
-    def _rand_color(self) -> str:
-        """
-        Generate a random color name (string)
-        """
-
-        return self._rand_elem(COLOR_NAMES)
-
-    def _rand_pos(
-        self, x_low: int, x_high: int, y_low: int, y_high: int
-    ) -> tuple[int, int]:
-        """
-        Generate a random (x,y) position tuple
-        """
-
-        return (
-            self.np_random.integers(x_low, x_high),
-            self.np_random.integers(y_low, y_high),
-        )
-
-    def place_obj(
-        self,
-        obj: WorldObj | None,
-        top: Point = None,
-        size: tuple[int, int] = None,
-        reject_fn=None,
-        max_tries=math.inf,
-    ):
-        """
-        Place an object at an empty position in the grid
-
-        :param top: top-left position of the rectangle where to place
-        :param size: size of the rectangle where to place
-        :param reject_fn: function to filter out potential positions
-        """
-
-        if top is None:
-            top = (0, 0)
-        else:
-            top = (max(top[0], 0), max(top[1], 0))
-
-        if size is None:
-            size = (self.grid.width, self.grid.height)
-
-        num_tries = 0
-
-        while True:
-            # This is to handle with rare cases where rejection sampling
-            # gets stuck in an infinite loop
-            if num_tries > max_tries:
-                raise RecursionError("rejection sampling failed in place_obj")
-
-            num_tries += 1
-
-            pos = (
-                self._rand_int(top[0], min(top[0] + size[0], self.grid.width)),
-                self._rand_int(top[1], min(top[1] + size[1], self.grid.height)),
-            )
-
-            # Don't place the object on top of another object
-            if self.grid.get(*pos) is not None:
-                continue
-
-            # Don't place the object where the agent is
-            if np.array_equal(pos, self.agent_pos):
-                continue
-
-            # Check if there is a filtering criterion
-            if reject_fn and reject_fn(self, pos):
-                continue
-
-            break
-
-        self.grid.set(pos[0], pos[1], obj)
-
-        if obj is not None:
-            obj.init_pos = pos
-            obj.cur_pos = pos
-
-        return pos
-
-    def put_obj(self, obj: WorldObj, i: int, j: int):
-        """
-        Put an object at a specific position in the grid
-        """
-
-        self.grid.set(i, j, obj)
-        obj.init_pos = (i, j)
-        obj.cur_pos = (i, j)
-
-    def place_agent(self, top=None, size=None, rand_dir=True, max_tries=math.inf):
-        """
-        Set the agent's starting point at an empty position in the grid
-        """
-
-        self.agent_pos = (-1, -1)
-        pos = self.place_obj(None, top, size, max_tries=max_tries)
-        self.agent_pos = pos
-
-        if rand_dir:
-            self.agent_dir = self._rand_int(0, 4)
-
-        return pos
-
-    @property
-    def dir_vec(self):
-        """
-        Get the direction vector for the agent, pointing in the direction
-        of forward movement.
-        """
-
-        assert (
-            self.agent_dir >= 0 and self.agent_dir < 4
-        ), f"Invalid agent_dir: {self.agent_dir} is not within range(0, 4)"
-        return DIR_TO_VEC[self.agent_dir]
-
-    @property
-    def right_vec(self):
-        """
-        Get the vector pointing to the right of the agent.
-        """
-
-        dx, dy = self.dir_vec
-        return np.array((-dy, dx))
-
-    @property
-    def front_pos(self):
-        """
-        Get the position of the cell that is right in front of the agent
-        """
-
-        return self.agent_pos + self.dir_vec
-
-    def get_view_coords(self, i, j):
-        """
-        Translate and rotate absolute grid coordinates (i, j) into the
-        agent's partially observable view (sub-grid). Note that the resulting
-        coordinates may be negative or outside of the agent's view size.
-        """
-
-        ax, ay = self.agent_pos
-        dx, dy = self.dir_vec
-        rx, ry = self.right_vec
-
-        # Compute the absolute coordinates of the top-left view corner
-        sz = self.agent_view_size
-        hs = self.agent_view_size // 2
-        tx = ax + (dx * (sz - 1)) - (rx * hs)
-        ty = ay + (dy * (sz - 1)) - (ry * hs)
-
-        lx = i - tx
-        ly = j - ty
-
-        # Project the coordinates of the object relative to the top-left
-        # corner onto the agent's own coordinate system
-        vx = rx * lx + ry * ly
-        vy = -(dx * lx + dy * ly)
-
-        return vx, vy
-
-    def get_view_exts(self, agent_view_size=None):
-        """
-        Get the extents of the square set of tiles visible to the agent
-        Note: the bottom extent indices are not included in the set
-        if agent_view_size is None, use self.agent_view_size
-        """
-
-        agent_view_size = agent_view_size or self.agent_view_size
-
-        # Facing right
-        if self.agent_dir == 0:
-            topX = self.agent_pos[0]
-            topY = self.agent_pos[1] - agent_view_size // 2
-        # Facing down
-        elif self.agent_dir == 1:
-            topX = self.agent_pos[0] - agent_view_size // 2
-            topY = self.agent_pos[1]
-        # Facing left
-        elif self.agent_dir == 2:
-            topX = self.agent_pos[0] - agent_view_size + 1
-            topY = self.agent_pos[1] - agent_view_size // 2
-        # Facing up
-        elif self.agent_dir == 3:
-            topX = self.agent_pos[0] - agent_view_size // 2
-            topY = self.agent_pos[1] - agent_view_size + 1
-        else:
-            assert False, "invalid agent direction"
-
-        botX = topX + agent_view_size
-        botY = topY + agent_view_size
-
-        return topX, topY, botX, botY
-
-    def relative_coords(self, x, y):
-        """
-        Check if a grid position belongs to the agent's field of view, and returns the corresponding coordinates
-        """
-
-        vx, vy = self.get_view_coords(x, y)
-
-        if vx < 0 or vy < 0 or vx >= self.agent_view_size or vy >= self.agent_view_size:
-            return None
-
-        return vx, vy
-
-    def in_view(self, x, y):
-        """
-        check if a grid position is visible to the agent
-        """
-
-        return self.relative_coords(x, y) is not None
-
-    def agent_sees(self, x, y):
-        """
-        Check if a non-empty grid position is visible to the agent
-        """
-
-        coordinates = self.relative_coords(x, y)
-        if coordinates is None:
-            return False
-        vx, vy = coordinates
-
-        obs = self.gen_obs()
-
-        obs_grid, _ = Grid.decode(obs["image"])
-        obs_cell = obs_grid.get(vx, vy)
-        world_cell = self.grid.get(x, y)
-
-        assert world_cell is not None
-
-        return obs_cell is not None and obs_cell.type == world_cell.type
-
-    def step(
-        self, action: ActType
-    ) -> tuple[ObsType, SupportsFloat, bool, bool, dict[str, Any]]:
-        self.step_count += 1
-
-        reward = 0
-        terminated = False
-        truncated = False
-
-        # Get the position in front of the agent
-        fwd_pos = self.front_pos
-
-        # Get the contents of the cell in front of the agent
-        fwd_cell = self.grid.get(*fwd_pos)
-
-        # Rotate left
-        if action == self.actions.left:
-            self.agent_dir -= 1
-            if self.agent_dir < 0:
-                self.agent_dir += 4
-
-        # Rotate right
-        elif action == self.actions.right:
-            self.agent_dir = (self.agent_dir + 1) % 4
-
-        # Move forward
-        elif action == self.actions.forward:
-            if fwd_cell is None or fwd_cell.can_overlap():
-                self.agent_pos = tuple(fwd_pos)
-            if fwd_cell is not None and fwd_cell.type == "goal":
-                terminated = True
-                reward = self._reward()
-            if fwd_cell is not None and fwd_cell.type == "lava":
-                terminated = True
-
-        # Pick up an object
-        elif action == self.actions.pickup:
-            if fwd_cell and fwd_cell.can_pickup():
-                if self.carrying is None:
-                    self.carrying = fwd_cell
-                    self.carrying.cur_pos = np.array([-1, -1])
-                    self.grid.set(fwd_pos[0], fwd_pos[1], None)
-
-        # Drop an object
-        elif action == self.actions.drop:
-            if not fwd_cell and self.carrying:
-                self.grid.set(fwd_pos[0], fwd_pos[1], self.carrying)
-                self.carrying.cur_pos = fwd_pos
-                self.carrying = None
-
-        # Toggle/activate an object
-        elif action == self.actions.toggle:
-            if fwd_cell:
-                fwd_cell.toggle(self, fwd_pos)
-
-        # Done action (not used by default)
-        elif action == self.actions.done:
-            pass
-
-        else:
-            raise ValueError(f"Unknown action: {action}")
-
-        if self.step_count >= self.max_steps:
-            truncated = True
-
-        if self.render_mode == "human":
-            self.render()
-
-        obs = self.gen_obs()
-
-        return obs, reward, terminated, truncated, {}
-
-    def gen_obs_grid(self, agent_view_size=None):
-        """
-        Generate the sub-grid observed by the agent.
-        This method also outputs a visibility mask telling us which grid
-        cells the agent can actually see.
-        if agent_view_size is None, self.agent_view_size is used
-        """
-
-        topX, topY, botX, botY = self.get_view_exts(agent_view_size)
-
-        agent_view_size = agent_view_size or self.agent_view_size
-
-        grid = self.grid.slice(topX, topY, agent_view_size, agent_view_size)
-
-        for i in range(self.agent_dir + 1):
-            grid = grid.rotate_left()
-
-        # Process occluders and visibility
-        # Note that this incurs some performance cost
-        if not self.see_through_walls:
-            vis_mask = grid.process_vis(
-                agent_pos=(agent_view_size // 2, agent_view_size - 1)
-            )
-        else:
-            vis_mask = np.ones(shape=(grid.width, grid.height), dtype=bool)
-
-        # Make it so the agent sees what it's carrying
-        # We do this by placing the carried object at the agent's position
-        # in the agent's partially observable view
-        agent_pos = grid.width // 2, grid.height - 1
-        if self.carrying:
-            grid.set(*agent_pos, self.carrying)
-        else:
-            grid.set(*agent_pos, None)
-
-        return grid, vis_mask
-
-    def gen_obs(self):
-        """
-        Generate the agent's view (partially observable, low-resolution encoding)
-        """
-
-        grid, vis_mask = self.gen_obs_grid()
-
-        # Encode the partially observable view into a numpy array
-        image = grid.encode(vis_mask)
-
-        # Observations are dictionaries containing:
-        # - an image (partially observable view of the environment)
-        # - the agent's direction/orientation (acting as a compass)
-        # - a textual mission string (instructions for the agent)
-        obs = {"image": image, "direction": self.agent_dir, "mission": self.mission}
-
-        return obs
-
-    def get_pov_render(self, tile_size):
-        """
-        Render an agent's POV observation for visualization
-        """
-        grid, vis_mask = self.gen_obs_grid()
-
-        # Render the whole grid
-        img = grid.render(
-            tile_size,
-            agent_pos=(self.agent_view_size // 2, self.agent_view_size - 1),
-            agent_dir=3,
-            highlight_mask=vis_mask,
-        )
-
-        return img
-
-    def get_full_render(self, highlight, tile_size):
-        """
-        Render a non-paratial observation for visualization
-        """
-        # Compute which cells are visible to the agent
-        _, vis_mask = self.gen_obs_grid()
-
-        # Compute the world coordinates of the bottom-left corner
-        # of the agent's view area
-        f_vec = self.dir_vec
-        r_vec = self.right_vec
-        top_left = (
-            self.agent_pos
-            + f_vec * (self.agent_view_size - 1)
-            - r_vec * (self.agent_view_size // 2)
-        )
-
-        # Mask of which cells to highlight
-        highlight_mask = np.zeros(shape=(self.width, self.height), dtype=bool)
-
-        # For each cell in the visibility mask
-        for vis_j in range(0, self.agent_view_size):
-            for vis_i in range(0, self.agent_view_size):
-                # If this cell is not visible, don't highlight it
-                if not vis_mask[vis_i, vis_j]:
-                    continue
-
-                # Compute the world coordinates of this cell
-                abs_i, abs_j = top_left - (f_vec * vis_j) + (r_vec * vis_i)
-
-                if abs_i < 0 or abs_i >= self.width:
-                    continue
-                if abs_j < 0 or abs_j >= self.height:
-                    continue
-
-                # Mark this cell to be highlighted
-                highlight_mask[abs_i, abs_j] = True
-
-        # Render the whole grid
-        img = self.grid.render(
-            tile_size,
-            self.agent_pos,
-            self.agent_dir,
-            highlight_mask=highlight_mask if highlight else None,
-        )
-
-        return img
-
-    def get_frame(
-        self,
-        highlight: bool = True,
-        tile_size: int = TILE_PIXELS,
-        agent_pov: bool = False,
-    ):
-        """Returns an RGB image corresponding to the whole environment or the agent's point of view.
-
-        Args:
-
-            highlight (bool): If true, the agent's field of view or point of view is highlighted with a lighter gray color.
-            tile_size (int): How many pixels will form a tile from the NxM grid.
-            agent_pov (bool): If true, the rendered frame will only contain the point of view of the agent.
-
-        Returns:
-
-            frame (np.ndarray): A frame of type numpy.ndarray with shape (x, y, 3) representing RGB values for the x-by-y pixel image.
-
-        """
-
-        if agent_pov:
-            return self.get_pov_render(tile_size)
-        else:
-            return self.get_full_render(highlight, tile_size)
-
-    def render(self):
-        img = self.get_frame(self.highlight, self.tile_size, self.agent_pov)
-
-        if self.render_mode == "human":
-            img = np.transpose(img, axes=(1, 0, 2))
-            if self.render_size is None:
-                self.render_size = img.shape[:2]
-            if self.window is None:
-                pygame.init()
-                pygame.display.init()
-                self.window = pygame.display.set_mode(
-                    (self.screen_size, self.screen_size)
-                )
-                pygame.display.set_caption("minigrid")
-            if self.clock is None:
-                self.clock = pygame.time.Clock()
-            surf = pygame.surfarray.make_surface(img)
-
-            # Create background with mission description
-            offset = surf.get_size()[0] * 0.1
-            # offset = 32 if self.agent_pov else 64
-            bg = pygame.Surface(
-                (int(surf.get_size()[0] + offset), int(surf.get_size()[1] + offset))
-            )
-            bg.convert()
-            bg.fill((255, 255, 255))
-            bg.blit(surf, (offset / 2, 0))
-
-            bg = pygame.transform.smoothscale(bg, (self.screen_size, self.screen_size))
-
-            font_size = 22
-            text = self.mission
-            font = pygame.freetype.SysFont(pygame.font.get_default_font(), font_size)
-            text_rect = font.get_rect(text, size=font_size)
-            text_rect.center = bg.get_rect().center
-            text_rect.y = bg.get_height() - font_size * 1.5
-            font.render_to(bg, text_rect, text, size=font_size)
-
-            self.window.blit(bg, (0, 0))
-            pygame.event.pump()
-            self.clock.tick(self.metadata["render_fps"])
-            pygame.display.flip()
-
-        elif self.render_mode == "rgb_array":
-            return img
-
-    def close(self):
-        if self.window:
-            pygame.quit()
diff --git a/rl-starter-files/Minigrid/minigrid/py.typed b/rl-starter-files/Minigrid/minigrid/py.typed
deleted file mode 100644
index e69de29..0000000
diff --git a/rl-starter-files/Minigrid/minigrid/utils/__init__.py b/rl-starter-files/Minigrid/minigrid/utils/__init__.py
deleted file mode 100644
index e69de29..0000000
diff --git a/rl-starter-files/Minigrid/minigrid/utils/rendering.py b/rl-starter-files/Minigrid/minigrid/utils/rendering.py
deleted file mode 100644
index 0f299a0..0000000
--- a/rl-starter-files/Minigrid/minigrid/utils/rendering.py
+++ /dev/null
@@ -1,133 +0,0 @@
-from __future__ import annotations
-
-import math
-
-import numpy as np
-
-
-def downsample(img, factor):
-    """
-    Downsample an image along both dimensions by some factor
-    """
-
-    assert img.shape[0] % factor == 0
-    assert img.shape[1] % factor == 0
-
-    img = img.reshape(
-        [img.shape[0] // factor, factor, img.shape[1] // factor, factor, 3]
-    )
-    img = img.mean(axis=3)
-    img = img.mean(axis=1)
-
-    return img
-
-
-def fill_coords(img, fn, color):
-    """
-    Fill pixels of an image with coordinates matching a filter function
-    """
-
-    for y in range(img.shape[0]):
-        for x in range(img.shape[1]):
-            yf = (y + 0.5) / img.shape[0]
-            xf = (x + 0.5) / img.shape[1]
-            if fn(xf, yf):
-                img[y, x] = color
-
-    return img
-
-
-def rotate_fn(fin, cx, cy, theta):
-    def fout(x, y):
-        x = x - cx
-        y = y - cy
-
-        x2 = cx + x * math.cos(-theta) - y * math.sin(-theta)
-        y2 = cy + y * math.cos(-theta) + x * math.sin(-theta)
-
-        return fin(x2, y2)
-
-    return fout
-
-
-def point_in_line(x0, y0, x1, y1, r):
-    p0 = np.array([x0, y0], dtype=np.float32)
-    p1 = np.array([x1, y1], dtype=np.float32)
-    dir = p1 - p0
-    dist = np.linalg.norm(dir)
-    dir = dir / dist
-
-    xmin = min(x0, x1) - r
-    xmax = max(x0, x1) + r
-    ymin = min(y0, y1) - r
-    ymax = max(y0, y1) + r
-
-    def fn(x, y):
-        # Fast, early escape test
-        if x < xmin or x > xmax or y < ymin or y > ymax:
-            return False
-
-        q = np.array([x, y])
-        pq = q - p0
-
-        # Closest point on line
-        a = np.dot(pq, dir)
-        a = np.clip(a, 0, dist)
-        p = p0 + a * dir
-
-        dist_to_line = np.linalg.norm(q - p)
-        return dist_to_line <= r
-
-    return fn
-
-
-def point_in_circle(cx, cy, r):
-    def fn(x, y):
-        return (x - cx) * (x - cx) + (y - cy) * (y - cy) <= r * r
-
-    return fn
-
-
-def point_in_rect(xmin, xmax, ymin, ymax):
-    def fn(x, y):
-        return x >= xmin and x <= xmax and y >= ymin and y <= ymax
-
-    return fn
-
-
-def point_in_triangle(a, b, c):
-    a = np.array(a, dtype=np.float32)
-    b = np.array(b, dtype=np.float32)
-    c = np.array(c, dtype=np.float32)
-
-    def fn(x, y):
-        v0 = c - a
-        v1 = b - a
-        v2 = np.array((x, y)) - a
-
-        # Compute dot products
-        dot00 = np.dot(v0, v0)
-        dot01 = np.dot(v0, v1)
-        dot02 = np.dot(v0, v2)
-        dot11 = np.dot(v1, v1)
-        dot12 = np.dot(v1, v2)
-
-        # Compute barycentric coordinates
-        inv_denom = 1 / (dot00 * dot11 - dot01 * dot01)
-        u = (dot11 * dot02 - dot01 * dot12) * inv_denom
-        v = (dot00 * dot12 - dot01 * dot02) * inv_denom
-
-        # Check if point is in triangle
-        return (u >= 0) and (v >= 0) and (u + v) < 1
-
-    return fn
-
-
-def highlight_img(img, color=(255, 255, 255), alpha=0.30):
-    """
-    Add highlighting to an image
-    """
-
-    blend_img = img + alpha * (np.array(color, dtype=np.uint8) - img)
-    blend_img = blend_img.clip(0, 255).astype(np.uint8)
-    img[:, :, :] = blend_img
diff --git a/rl-starter-files/Minigrid/minigrid/wrappers.py b/rl-starter-files/Minigrid/minigrid/wrappers.py
deleted file mode 100644
index 8f7a001..0000000
--- a/rl-starter-files/Minigrid/minigrid/wrappers.py
+++ /dev/null
@@ -1,866 +0,0 @@
-from __future__ import annotations
-
-import math
-import operator
-from functools import reduce
-from typing import Any
-
-import gymnasium as gym
-import numpy as np
-from gymnasium import logger, spaces
-from gymnasium.core import ActionWrapper, ObservationWrapper, ObsType, Wrapper
-
-from minigrid.core.constants import COLOR_TO_IDX, OBJECT_TO_IDX, STATE_TO_IDX
-from minigrid.core.world_object import Goal
-
-
-class ReseedWrapper(Wrapper):
-    """
-    Wrapper to always regenerate an environment with the same set of seeds.
-    This can be used to force an environment to always keep the same
-    configuration when reset.
-
-    Example:
-        >>> import minigrid
-        >>> import gymnasium as gym
-        >>> from minigrid.wrappers import ReseedWrapper
-        >>> env = gym.make("MiniGrid-Empty-5x5-v0")
-        >>> _ = env.reset(seed=123)
-        >>> [env.np_random.integers(10) for i in range(10)]
-        [0, 6, 5, 0, 9, 2, 2, 1, 3, 1]
-        >>> env = ReseedWrapper(env, seeds=[0, 1], seed_idx=0)
-        >>> _, _ = env.reset()
-        >>> [env.np_random.integers(10) for i in range(10)]
-        [8, 6, 5, 2, 3, 0, 0, 0, 1, 8]
-        >>> _, _ = env.reset()
-        >>> [env.np_random.integers(10) for i in range(10)]
-        [4, 5, 7, 9, 0, 1, 8, 9, 2, 3]
-        >>> _, _ = env.reset()
-        >>> [env.np_random.integers(10) for i in range(10)]
-        [8, 6, 5, 2, 3, 0, 0, 0, 1, 8]
-        >>> _, _ = env.reset()
-        >>> [env.np_random.integers(10) for i in range(10)]
-        [4, 5, 7, 9, 0, 1, 8, 9, 2, 3]
-    """
-
-    def __init__(self, env, seeds=(0,), seed_idx=0):
-        """A wrapper that always regenerate an environment with the same set of seeds.
-
-        Args:
-            env: The environment to apply the wrapper
-            seeds: A list of seed to be applied to the env
-            seed_idx: Index of the initial seed in seeds
-        """
-        self.seeds = list(seeds)
-        self.seed_idx = seed_idx
-        super().__init__(env)
-
-    def reset(
-        self, *, seed: int | None = None, options: dict[str, Any] | None = None
-    ) -> tuple[ObsType, dict[str, Any]]:
-        if seed is not None:
-            logger.warn(
-                "A seed has been passed to `ReseedWrapper.reset` which is ignored."
-            )
-        seed = self.seeds[self.seed_idx]
-        self.seed_idx = (self.seed_idx + 1) % len(self.seeds)
-        return self.env.reset(seed=seed, options=options)
-
-
-class ActionBonus(gym.Wrapper):
-    """
-    Wrapper which adds an exploration bonus.
-    This is a reward to encourage exploration of less
-    visited (state,action) pairs.
-
-    Example:
-        >>> import gymnasium as gym
-        >>> from minigrid.wrappers import ActionBonus
-        >>> env = gym.make("MiniGrid-Empty-5x5-v0")
-        >>> _, _ = env.reset(seed=0)
-        >>> _, reward, _, _, _ = env.step(1)
-        >>> print(reward)
-        0
-        >>> _, reward, _, _, _ = env.step(1)
-        >>> print(reward)
-        0
-        >>> env_bonus = ActionBonus(env)
-        >>> _, _ = env_bonus.reset(seed=0)
-        >>> _, reward, _, _, _ = env_bonus.step(1)
-        >>> print(reward)
-        1.0
-        >>> _, reward, _, _, _ = env_bonus.step(1)
-        >>> print(reward)
-        1.0
-    """
-
-    def __init__(self, env):
-        """A wrapper that adds an exploration bonus to less visited (state,action) pairs.
-
-        Args:
-            env: The environment to apply the wrapper
-        """
-        super().__init__(env)
-        self.counts = {}
-
-    def step(self, action):
-        """Steps through the environment with `action`."""
-        obs, reward, terminated, truncated, info = self.env.step(action)
-
-        env = self.unwrapped
-        tup = (tuple(env.agent_pos), env.agent_dir, action)
-
-        # Get the count for this (s,a) pair
-        pre_count = 0
-        if tup in self.counts:
-            pre_count = self.counts[tup]
-
-        # Update the count for this (s,a) pair
-        new_count = pre_count + 1
-        self.counts[tup] = new_count
-
-        bonus = 1 / math.sqrt(new_count)
-        reward += bonus
-
-        return obs, reward, terminated, truncated, info
-
-
-class PositionBonus(Wrapper):
-    """
-    Adds an exploration bonus based on which positions
-    are visited on the grid.
-
-    Note:
-        This wrapper was previously called ``StateBonus``.
-
-    Example:
-        >>> import gymnasium as gym
-        >>> from minigrid.wrappers import PositionBonus
-        >>> env = gym.make("MiniGrid-Empty-5x5-v0")
-        >>> _, _ = env.reset(seed=0)
-        >>> _, reward, _, _, _ = env.step(1)
-        >>> print(reward)
-        0
-        >>> _, reward, _, _, _ = env.step(1)
-        >>> print(reward)
-        0
-        >>> env_bonus = PositionBonus(env)
-        >>> obs, _ = env_bonus.reset(seed=0)
-        >>> obs, reward, terminated, truncated, info = env_bonus.step(1)
-        >>> print(reward)
-        1.0
-        >>> obs, reward, terminated, truncated, info = env_bonus.step(1)
-        >>> print(reward)
-        0.7071067811865475
-    """
-
-    def __init__(self, env):
-        """A wrapper that adds an exploration bonus to less visited positions.
-
-        Args:
-            env: The environment to apply the wrapper
-        """
-        super().__init__(env)
-        self.counts = {}
-
-    def step(self, action):
-        """Steps through the environment with `action`."""
-        obs, reward, terminated, truncated, info = self.env.step(action)
-
-        # Tuple based on which we index the counts
-        # We use the position after an update
-        env = self.unwrapped
-        tup = tuple(env.agent_pos)
-
-        # Get the count for this key
-        pre_count = 0
-        if tup in self.counts:
-            pre_count = self.counts[tup]
-
-        # Update the count for this key
-        new_count = pre_count + 1
-        self.counts[tup] = new_count
-
-        bonus = 1 / math.sqrt(new_count)
-        reward += bonus
-
-        return obs, reward, terminated, truncated, info
-
-
-class ImgObsWrapper(ObservationWrapper):
-    """
-    Use the image as the only observation output, no language/mission.
-
-    Example:
-        >>> import gymnasium as gym
-        >>> from minigrid.wrappers import ImgObsWrapper
-        >>> env = gym.make("MiniGrid-Empty-5x5-v0")
-        >>> obs, _ = env.reset()
-        >>> obs.keys()
-        dict_keys(['image', 'direction', 'mission'])
-        >>> env = ImgObsWrapper(env)
-        >>> obs, _ = env.reset()
-        >>> obs.shape
-        (7, 7, 3)
-    """
-
-    def __init__(self, env):
-        """A wrapper that makes image the only observation.
-
-        Args:
-            env: The environment to apply the wrapper
-        """
-        super().__init__(env)
-        self.observation_space = env.observation_space.spaces["image"]
-
-    def observation(self, obs):
-        return obs["image"]
-
-
-class OneHotPartialObsWrapper(ObservationWrapper):
-    """
-    Wrapper to get a one-hot encoding of a partially observable
-    agent view as observation.
-
-    Example:
-        >>> import gymnasium as gym
-        >>> from minigrid.wrappers import OneHotPartialObsWrapper
-        >>> env = gym.make("MiniGrid-Empty-5x5-v0")
-        >>> obs, _ = env.reset()
-        >>> obs["image"][0, :, :]
-        array([[2, 5, 0],
-               [2, 5, 0],
-               [2, 5, 0],
-               [2, 5, 0],
-               [2, 5, 0],
-               [2, 5, 0],
-               [2, 5, 0]], dtype=uint8)
-        >>> env = OneHotPartialObsWrapper(env)
-        >>> obs, _ = env.reset()
-        >>> obs["image"][0, :, :]
-        array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
-               [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
-               [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
-               [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
-               [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
-               [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
-               [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]],
-              dtype=uint8)
-    """
-
-    def __init__(self, env, tile_size=8):
-        """A wrapper that makes the image observation a one-hot encoding of a partially observable agent view.
-
-        Args:
-            env: The environment to apply the wrapper
-        """
-        super().__init__(env)
-
-        self.tile_size = tile_size
-
-        obs_shape = env.observation_space["image"].shape
-
-        # Number of bits per cell
-        num_bits = len(OBJECT_TO_IDX) + len(COLOR_TO_IDX) + len(STATE_TO_IDX)
-
-        new_image_space = spaces.Box(
-            low=0, high=255, shape=(obs_shape[0], obs_shape[1], num_bits), dtype="uint8"
-        )
-        self.observation_space = spaces.Dict(
-            {**self.observation_space.spaces, "image": new_image_space}
-        )
-
-    def observation(self, obs):
-        img = obs["image"]
-        out = np.zeros(self.observation_space.spaces["image"].shape, dtype="uint8")
-
-        for i in range(img.shape[0]):
-            for j in range(img.shape[1]):
-                type = img[i, j, 0]
-                color = img[i, j, 1]
-                state = img[i, j, 2]
-
-                out[i, j, type] = 1
-                out[i, j, len(OBJECT_TO_IDX) + color] = 1
-                out[i, j, len(OBJECT_TO_IDX) + len(COLOR_TO_IDX) + state] = 1
-
-        return {**obs, "image": out}
-
-
-class RGBImgObsWrapper(ObservationWrapper):
-    """
-    Wrapper to use fully observable RGB image as observation,
-    This can be used to have the agent to solve the gridworld in pixel space.
-
-    Example:
-        >>> import gymnasium as gym
-        >>> import matplotlib.pyplot as plt
-        >>> from minigrid.wrappers import RGBImgObsWrapper
-        >>> env = gym.make("MiniGrid-Empty-5x5-v0")
-        >>> obs, _ = env.reset()
-        >>> plt.imshow(obs['image'])  # doctest: +SKIP
-        ![NoWrapper](../figures/lavacrossing_NoWrapper.png)
-        >>> env = RGBImgObsWrapper(env)
-        >>> obs, _ = env.reset()
-        >>> plt.imshow(obs['image'])  # doctest: +SKIP
-        ![RGBImgObsWrapper](../figures/lavacrossing_RGBImgObsWrapper.png)
-    """
-
-    def __init__(self, env, tile_size=8):
-        super().__init__(env)
-
-        self.tile_size = tile_size
-
-        new_image_space = spaces.Box(
-            low=0,
-            high=255,
-            shape=(self.env.width * tile_size, self.env.height * tile_size, 3),
-            dtype="uint8",
-        )
-
-        self.observation_space = spaces.Dict(
-            {**self.observation_space.spaces, "image": new_image_space}
-        )
-
-    def observation(self, obs):
-        rgb_img = self.get_frame(highlight=True, tile_size=self.tile_size)
-
-        return {**obs, "image": rgb_img}
-
-
-class RGBImgPartialObsWrapper(ObservationWrapper):
-    """
-    Wrapper to use partially observable RGB image as observation.
-    This can be used to have the agent to solve the gridworld in pixel space.
-
-    Example:
-        >>> import gymnasium as gym
-        >>> import matplotlib.pyplot as plt
-        >>> from minigrid.wrappers import RGBImgObsWrapper, RGBImgPartialObsWrapper
-        >>> env = gym.make("MiniGrid-LavaCrossingS11N5-v0")
-        >>> obs, _ = env.reset()
-        >>> plt.imshow(obs["image"])  # doctest: +SKIP
-        ![NoWrapper](../figures/lavacrossing_NoWrapper.png)
-        >>> env_obs = RGBImgObsWrapper(env)
-        >>> obs, _ = env_obs.reset()
-        >>> plt.imshow(obs["image"])  # doctest: +SKIP
-        ![RGBImgObsWrapper](../figures/lavacrossing_RGBImgObsWrapper.png)
-        >>> env_obs = RGBImgPartialObsWrapper(env)
-        >>> obs, _ = env_obs.reset()
-        >>> plt.imshow(obs["image"])  # doctest: +SKIP
-        ![RGBImgPartialObsWrapper](../figures/lavacrossing_RGBImgPartialObsWrapper.png)
-    """
-
-    def __init__(self, env, tile_size=8):
-        super().__init__(env)
-
-        # Rendering attributes for observations
-        self.tile_size = tile_size
-
-        obs_shape = env.observation_space.spaces["image"].shape
-        new_image_space = spaces.Box(
-            low=0,
-            high=255,
-            shape=(obs_shape[0] * tile_size, obs_shape[1] * tile_size, 3),
-            dtype="uint8",
-        )
-
-        self.observation_space = spaces.Dict(
-            {**self.observation_space.spaces, "image": new_image_space}
-        )
-
-    def observation(self, obs):
-        rgb_img_partial = self.get_frame(tile_size=self.tile_size, agent_pov=True)
-
-        return {**obs, "image": rgb_img_partial}
-
-
-class FullyObsWrapper(ObservationWrapper):
-    """
-    Fully observable gridworld using a compact grid encoding instead of the agent view.
-
-    Example:
-        >>> import gymnasium as gym
-        >>> import matplotlib.pyplot as plt
-        >>> from minigrid.wrappers import FullyObsWrapper
-        >>> env = gym.make("MiniGrid-LavaCrossingS11N5-v0")
-        >>> obs, _ = env.reset()
-        >>> obs['image'].shape
-        (7, 7, 3)
-        >>> env_obs = FullyObsWrapper(env)
-        >>> obs, _ = env_obs.reset()
-        >>> obs['image'].shape
-        (11, 11, 3)
-    """
-
-    def __init__(self, env):
-        super().__init__(env)
-
-        new_image_space = spaces.Box(
-            low=0,
-            high=255,
-            shape=(self.env.width, self.env.height, 3),  # number of cells
-            dtype="uint8",
-        )
-
-        self.observation_space = spaces.Dict(
-            {**self.observation_space.spaces, "image": new_image_space}
-        )
-
-    def observation(self, obs):
-        env = self.unwrapped
-        full_grid = env.grid.encode()
-        full_grid[env.agent_pos[0]][env.agent_pos[1]] = np.array(
-            [OBJECT_TO_IDX["agent"], COLOR_TO_IDX["red"], env.agent_dir]
-        )
-
-        return {**obs, "image": full_grid}
-
-
-class DictObservationSpaceWrapper(ObservationWrapper):
-    """
-    Transforms the observation space (that has a textual component) to a fully numerical observation space,
-    where the textual instructions are replaced by arrays representing the indices of each word in a fixed vocabulary.
-
-    This wrapper is not applicable to BabyAI environments, given that these have their own language component.
-
-    Example:
-        >>> import gymnasium as gym
-        >>> import matplotlib.pyplot as plt
-        >>> from minigrid.wrappers import DictObservationSpaceWrapper
-        >>> env = gym.make("MiniGrid-LavaCrossingS11N5-v0")
-        >>> obs, _ = env.reset()
-        >>> obs['mission']
-        'avoid the lava and get to the green goal square'
-        >>> env_obs = DictObservationSpaceWrapper(env)
-        >>> obs, _ = env_obs.reset()
-        >>> obs['mission'][:10]
-        [19, 31, 17, 36, 20, 38, 31, 2, 15, 35]
-    """
-
-    def __init__(self, env, max_words_in_mission=50, word_dict=None):
-        """
-        max_words_in_mission is the length of the array to represent a mission, value 0 for missing words
-        word_dict is a dictionary of words to use (keys=words, values=indices from 1 to < max_words_in_mission),
-                  if None, use the Minigrid language
-        """
-        super().__init__(env)
-
-        if word_dict is None:
-            word_dict = self.get_minigrid_words()
-
-        self.max_words_in_mission = max_words_in_mission
-        self.word_dict = word_dict
-
-        self.observation_space = spaces.Dict(
-            {
-                "image": env.observation_space["image"],
-                "direction": spaces.Discrete(4),
-                "mission": spaces.MultiDiscrete(
-                    [len(self.word_dict.keys())] * max_words_in_mission
-                ),
-            }
-        )
-
-    @staticmethod
-    def get_minigrid_words():
-        colors = ["red", "green", "blue", "yellow", "purple", "grey"]
-        objects = [
-            "unseen",
-            "empty",
-            "wall",
-            "floor",
-            "box",
-            "key",
-            "ball",
-            "door",
-            "goal",
-            "agent",
-            "lava",
-        ]
-
-        verbs = [
-            "pick",
-            "avoid",
-            "get",
-            "find",
-            "put",
-            "use",
-            "open",
-            "go",
-            "fetch",
-            "reach",
-            "unlock",
-            "traverse",
-        ]
-
-        extra_words = [
-            "up",
-            "the",
-            "a",
-            "at",
-            ",",
-            "square",
-            "and",
-            "then",
-            "to",
-            "of",
-            "rooms",
-            "near",
-            "opening",
-            "must",
-            "you",
-            "matching",
-            "end",
-            "hallway",
-            "object",
-            "from",
-            "room",
-        ]
-
-        all_words = colors + objects + verbs + extra_words
-        assert len(all_words) == len(set(all_words))
-        return {word: i for i, word in enumerate(all_words)}
-
-    def string_to_indices(self, string, offset=1):
-        """
-        Convert a string to a list of indices.
-        """
-        indices = []
-        # adding space before and after commas
-        string = string.replace(",", " , ")
-        for word in string.split():
-            if word in self.word_dict.keys():
-                indices.append(self.word_dict[word] + offset)
-            else:
-                raise ValueError(f"Unknown word: {word}")
-        return indices
-
-    def observation(self, obs):
-        obs["mission"] = self.string_to_indices(obs["mission"])
-        assert len(obs["mission"]) < self.max_words_in_mission
-        obs["mission"] += [0] * (self.max_words_in_mission - len(obs["mission"]))
-
-        return obs
-
-
-class FlatObsWrapper(ObservationWrapper):
-    """
-    Encode mission strings using a one-hot scheme,
-    and combine these with observed images into one flat array.
-
-    This wrapper is not applicable to BabyAI environments, given that these have their own language component.
-
-    Example:
-        >>> import gymnasium as gym
-        >>> import matplotlib.pyplot as plt
-        >>> from minigrid.wrappers import FlatObsWrapper
-        >>> env = gym.make("MiniGrid-LavaCrossingS11N5-v0")
-        >>> env_obs = FlatObsWrapper(env)
-        >>> obs, _ = env_obs.reset()
-        >>> obs.shape
-        (2835,)
-    """
-
-    def __init__(self, env, maxStrLen=96):
-        super().__init__(env)
-
-        self.maxStrLen = maxStrLen
-        self.numCharCodes = 28
-
-        imgSpace = env.observation_space.spaces["image"]
-        imgSize = reduce(operator.mul, imgSpace.shape, 1)
-
-        self.observation_space = spaces.Box(
-            low=0,
-            high=255,
-            shape=(imgSize + self.numCharCodes * self.maxStrLen,),
-            dtype="uint8",
-        )
-
-        self.cachedStr: str = None
-
-    def observation(self, obs):
-        image = obs["image"]
-        mission = obs["mission"]
-
-        # Cache the last-encoded mission string
-        if mission != self.cachedStr:
-            assert (
-                len(mission) <= self.maxStrLen
-            ), f"mission string too long ({len(mission)} chars)"
-            mission = mission.lower()
-
-            strArray = np.zeros(
-                shape=(self.maxStrLen, self.numCharCodes), dtype="float32"
-            )
-
-            for idx, ch in enumerate(mission):
-                if ch >= "a" and ch <= "z":
-                    chNo = ord(ch) - ord("a")
-                elif ch == " ":
-                    chNo = ord("z") - ord("a") + 1
-                elif ch == ",":
-                    chNo = ord("z") - ord("a") + 2
-                else:
-                    raise ValueError(
-                        f"Character {ch} is not available in mission string."
-                    )
-                assert chNo < self.numCharCodes, "%s : %d" % (ch, chNo)
-                strArray[idx, chNo] = 1
-
-            self.cachedStr = mission
-            self.cachedArray = strArray
-
-        obs = np.concatenate((image.flatten(), self.cachedArray.flatten()))
-
-        return obs
-
-
-class ViewSizeWrapper(ObservationWrapper):
-    """
-    Wrapper to customize the agent field of view size.
-    This cannot be used with fully observable wrappers.
-
-    Example:
-        >>> import gymnasium as gym
-        >>> from minigrid.wrappers import ViewSizeWrapper
-        >>> env = gym.make("MiniGrid-LavaCrossingS11N5-v0")
-        >>> obs, _ = env.reset()
-        >>> obs['image'].shape
-        (7, 7, 3)
-        >>> env_obs = ViewSizeWrapper(env, agent_view_size=5)
-        >>> obs, _ = env_obs.reset()
-        >>> obs['image'].shape
-        (5, 5, 3)
-    """
-
-    def __init__(self, env, agent_view_size=7):
-        super().__init__(env)
-
-        assert agent_view_size % 2 == 1
-        assert agent_view_size >= 3
-
-        self.agent_view_size = agent_view_size
-
-        # Compute observation space with specified view size
-        new_image_space = gym.spaces.Box(
-            low=0, high=255, shape=(agent_view_size, agent_view_size, 3), dtype="uint8"
-        )
-
-        # Override the environment's observation spaceexit
-        self.observation_space = spaces.Dict(
-            {**self.observation_space.spaces, "image": new_image_space}
-        )
-
-    def observation(self, obs):
-        env = self.unwrapped
-
-        grid, vis_mask = env.gen_obs_grid(self.agent_view_size)
-
-        # Encode the partially observable view into a numpy array
-        image = grid.encode(vis_mask)
-
-        return {**obs, "image": image}
-
-
-class DirectionObsWrapper(ObservationWrapper):
-    """
-    Provides the slope/angular direction to the goal with the observations as modeled by (y2 - y2 )/( x2 - x1)
-    type = {slope , angle}
-
-    Example:
-        >>> import gymnasium as gym
-        >>> import matplotlib.pyplot as plt
-        >>> from minigrid.wrappers import DirectionObsWrapper
-        >>> env = gym.make("MiniGrid-LavaCrossingS11N5-v0")
-        >>> env_obs = DirectionObsWrapper(env, type="slope")
-        >>> obs, _ = env_obs.reset()
-        >>> obs['goal_direction']
-        1.0
-    """
-
-    def __init__(self, env, type="slope"):
-        super().__init__(env)
-        self.goal_position: tuple = None
-        self.type = type
-
-    def reset(
-        self, *, seed: int | None = None, options: dict[str, Any] | None = None
-    ) -> tuple[ObsType, dict[str, Any]]:
-        obs, info = self.env.reset()
-
-        if not self.goal_position:
-            self.goal_position = [
-                x for x, y in enumerate(self.grid.grid) if isinstance(y, Goal)
-            ]
-            # in case there are multiple goals , needs to be handled for other env types
-            if len(self.goal_position) >= 1:
-                self.goal_position = (
-                    int(self.goal_position[0] / self.height),
-                    self.goal_position[0] % self.width,
-                )
-
-        return self.observation(obs), info
-
-    def observation(self, obs):
-        slope = np.divide(
-            self.goal_position[1] - self.agent_pos[1],
-            self.goal_position[0] - self.agent_pos[0],
-        )
-
-        if self.type == "angle":
-            obs["goal_direction"] = np.arctan(slope)
-        else:
-            obs["goal_direction"] = slope
-
-        return obs
-
-
-class SymbolicObsWrapper(ObservationWrapper):
-    """
-    Fully observable grid with a symbolic state representation.
-    The symbol is a triple of (X, Y, IDX), where X and Y are
-    the coordinates on the grid, and IDX is the id of the object.
-
-    Example:
-        >>> import gymnasium as gym
-        >>> from minigrid.wrappers import SymbolicObsWrapper
-        >>> env = gym.make("MiniGrid-LavaCrossingS11N5-v0")
-        >>> obs, _ = env.reset()
-        >>> obs['image'].shape
-        (7, 7, 3)
-        >>> env_obs = SymbolicObsWrapper(env)
-        >>> obs, _ = env_obs.reset()
-        >>> obs['image'].shape
-        (11, 11, 3)
-    """
-
-    def __init__(self, env):
-        super().__init__(env)
-
-        new_image_space = spaces.Box(
-            low=0,
-            high=max(OBJECT_TO_IDX.values()),
-            shape=(self.env.width, self.env.height, 3),  # number of cells
-            dtype="uint8",
-        )
-        self.observation_space = spaces.Dict(
-            {**self.observation_space.spaces, "image": new_image_space}
-        )
-
-    def observation(self, obs):
-        objects = np.array(
-            [OBJECT_TO_IDX[o.type] if o is not None else -1 for o in self.grid.grid]
-        )
-        agent_pos = self.env.agent_pos
-        ncol, nrow = self.width, self.height
-        grid = np.mgrid[:ncol, :nrow]
-        _objects = np.transpose(objects.reshape(1, nrow, ncol), (0, 2, 1))
-
-        grid = np.concatenate([grid, _objects])
-        grid = np.transpose(grid, (1, 2, 0))
-        grid[agent_pos[0], agent_pos[1], 2] = OBJECT_TO_IDX["agent"]
-        obs["image"] = grid
-
-        return obs
-
-
-class StochasticActionWrapper(ActionWrapper):
-    """
-    Add stochasticity to the actions
-
-    If a random action is provided, it is returned with probability `1 - prob`.
-    Else, a random action is sampled from the action space.
-    """
-
-    def __init__(self, env=None, prob=0.9, random_action=None):
-        super().__init__(env)
-        self.prob = prob
-        self.random_action = random_action
-
-    def action(self, action):
-        """ """
-        if np.random.uniform() < self.prob:
-            return action
-        else:
-            if self.random_action is None:
-                return self.np_random.integers(0, high=6)
-            else:
-                return self.random_action
-
-
-class NoDeath(Wrapper):
-    """
-    Wrapper to prevent death in specific cells (e.g., lava cells).
-    Instead of dying, the agent will receive a negative reward.
-
-    Example:
-        >>> import gymnasium as gym
-        >>> from minigrid.wrappers import NoDeath
-        >>>
-        >>> env = gym.make("MiniGrid-LavaCrossingS9N1-v0")
-        >>> _, _ = env.reset(seed=2)
-        >>> _, _, _, _, _ = env.step(1)
-        >>> _, reward, term, *_ = env.step(2)
-        >>> reward, term
-        (0, True)
-        >>>
-        >>> env = NoDeath(env, no_death_types=("lava",), death_cost=-1.0)
-        >>> _, _ = env.reset(seed=2)
-        >>> _, _, _, _, _ = env.step(1)
-        >>> _, reward, term, *_ = env.step(2)
-        >>> reward, term
-        (-1.0, False)
-        >>>
-        >>>
-        >>> env = gym.make("MiniGrid-Dynamic-Obstacles-5x5-v0")
-        >>> _, _ = env.reset(seed=2)
-        >>> _, reward, term, *_ = env.step(2)
-        >>> reward, term
-        (-1, True)
-        >>>
-        >>> env = NoDeath(env, no_death_types=("ball",), death_cost=-1.0)
-        >>> _, _ = env.reset(seed=2)
-        >>> _, reward, term, *_ = env.step(2)
-        >>> reward, term
-        (-2.0, False)
-    """
-
-    def __init__(self, env, no_death_types: tuple[str, ...], death_cost: float = -1.0):
-        """A wrapper to prevent death in specific cells.
-
-        Args:
-            env: The environment to apply the wrapper
-            no_death_types: List of strings to identify death cells
-            death_cost: The negative reward received in death cells
-
-        """
-        assert "goal" not in no_death_types, "goal cannot be a death cell"
-
-        super().__init__(env)
-        self.death_cost = death_cost
-        self.no_death_types = no_death_types
-
-    def step(self, action):
-        # In Dynamic-Obstacles, obstacles move after the agent moves,
-        # so we need to check for collision before self.env.step()
-        front_cell = self.grid.get(*self.front_pos)
-        going_to_death = (
-            action == self.actions.forward
-            and front_cell is not None
-            and front_cell.type in self.no_death_types
-        )
-
-        obs, reward, terminated, truncated, info = self.env.step(action)
-
-        # We also check if the agent stays in death cells (e.g., lava)
-        # without moving
-        current_cell = self.grid.get(*self.agent_pos)
-        in_death = current_cell is not None and current_cell.type in self.no_death_types
-
-        if terminated and (going_to_death or in_death):
-            terminated = False
-            reward += self.death_cost
-
-        return obs, reward, terminated, truncated, info
diff --git a/rl-starter-files/README-rsrc/model.png b/rl-starter-files/README-rsrc/model.png
deleted file mode 100644
index 8791633..0000000
Binary files a/rl-starter-files/README-rsrc/model.png and /dev/null differ
diff --git a/rl-starter-files/README-rsrc/model.xml b/rl-starter-files/README-rsrc/model.xml
deleted file mode 100644
index e2bd6cf..0000000
--- a/rl-starter-files/README-rsrc/model.xml
+++ /dev/null
@@ -1 +0,0 @@
-<mxfile userAgent="Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) draw.io/9.3.1 Chrome/66.0.3359.181 Electron/3.0.6 Safari/537.36" version="9.3.4" editor="www.draw.io" type="device"><diagram id="81a450cc-4610-c693-ab1c-18701f2b71dc" name="Page-1">7Vtbj5s4FP41SLsPW8UYSHhMssnsQytVnV3t9tEBh9ACjohz66+vCXYwNpkyEweS0Y40Gvv4fs53bsZjwWl6eMrRevWJhDix7EF4sOCflm0De2izPwXlWFJcb1ASojwOeaeK8Bz/wJwoum3jEG9qHSkhCY3XdWJAsgwHtEZDeU729W5LktRXXaOIrzioCM8BSrDW7d84pKuSOnKl3n/hOFqJlcGAtyxQ8D3KyTbj61k2XJ5+yuYUibl4/80KhWQvkeDMgtOcEFqW0sMUJwVvBdvKcfMLred95zijbQaIERt6FGfHIWMFr5KcrkhEMpTMKurkdD5czDBgtRVNE1YErIgPMf2vIH9wee0r78S2kx+lpqL6lY/6hik9cgygLSWMVK37kZA176efTWyebPOA754Dj6I8wmfplLTiYNI4zpAnTFLMdsM65DhBNN7VMYA4lKJzv4qdrMA5eoG75RQ7lGz5pFOS7RhF53qdp/tVTPHzGp1OtWc6VufzRU7scE7x4cVD8lZbIJZrKBSI3Fd4B4K2krAOB9fzxdH4oqMwC8eFIrNakKDNJg4UqL0AqIvskVFhtwSFxA+3gR2C1ho7fIXPJGabq8ThKeIYKWwuMc5HyQqtTjT8xUQlD7SJTiI7H7uVFF1NinFa2FXbSxhzJpvtghWjokgFjU0pkQV1kVcUBQYMzbQu+A3NyXc8JQnJGSUjWWGRlnGSKCSUxFFWoIeBADP6pNCNmJn4MW9I4zA8mbMmZaurowl9cxS5+Lq+OQ34sg2om/Cqj2DkZUky5xkiPFoGmthZy9ifOrNJW7fg6QbA78sreJrezNIFDsM4i65zCwZ51x7YfwAF2KClI3EMIHuom6CMnfYdmqAlyagkQW84nvhzMxKE/Vmm0W0DAYMKIVsO765CB9dQ5KA4KMe9WeDgdJ902PfmkHwdVmBo2iOdhjLtQUepw7qQ4KY1noA3eBE2aiKh9GeFcgNvBYuvmYinL/+8Az955nMXfrLJrt5rBNhKfUCDWQZtUzrjEZ3YjZ7o63zvO9E/J4idJPqPm3ksRwEOGq3CHPhT32+N1KYbKac3pF68koL3h9Qur6SAaxSpZzzKaCzB2RaPAu1AxvpphlshFXaB1OYoAqhRh+PXp7gQxb4hoBDHlFRg9ZqE8RHSw9nYm3ieGbX0FckMXU0rb5Ue2jdxH7pCtVXJb9t0LRaPTlJ4SdFvpaaOrqZ2R2oKlWtq4Cpqai5JhH7nocPw7mKHBlGbzxJbu0j9s83H578/XRc3GOTc2yMN0DYmtv3r2WhfD2zdDt1ZdjZsMFFtb82M4xZe70UekuFub4ZCv5ZnSUaAKM7Y73X2woD2A+UTKWibZxjRfj3P6gCMv7oo7/kytDHzgH3Bt+F5woUEYQL+TxIuBIYNWcL5kZTpNAFen7vfu4EXxlzWENjbfWfD04/5NkmOvZt29eOF16Flh977R2HDMwrY3+s6/SHFfaDQ7xGE+pcIazq3im/C3IGtUaY+fpA913RmTUashtKCL9lis5Y6Nr+dKKjSrL+x5T9YQ7bVAXnNvVox4BUXcb/fqZM1EaCq6anfoS+1NQDtOsTOjRHzII99THhCNSBrwBAwgyFWrR6slzd91X8FwNlP</diagram></mxfile>
\ No newline at end of file
diff --git a/rl-starter-files/RNDmodel.py b/rl-starter-files/RNDmodel.py
deleted file mode 100644
index d27daea..0000000
--- a/rl-starter-files/RNDmodel.py
+++ /dev/null
@@ -1,179 +0,0 @@
-import torch.nn.functional as F
-import torch.nn as nn
-import torch
-import torch.optim as optim
-import numpy as np
-import math
-from torch.nn import init
-from model import init_params
-
-import torch_ac
-
-
-class Flatten(nn.Module):
-    def forward(self, input):
-        return input.view(input.size(0), -1)
-
-class RNDModel(nn.Module,torch_ac.RecurrentACModel):
-
-    """
-    RNDModel is an implementation of the Random Network Distillation (RND) 
-    technique, which is used for generating intrinsic rewards in reinforcement learning.
-    This technique encourages exploration by measuring the error of predicting the output of a
-    fixed randomly initialized neural network (the "target" network) using another neural network 
-    (the "predictor" network). The predictor network is trained to minimize the MSE loss between 
-    its predictions and the output of the target network.
-    """
-
-    def __init__(self, obs_space,use_memory=False, use_text=False):
-        super(RNDModel, self).__init__()
-
-        # Decide which components are enabled
-        self.use_text = use_text
-        self.use_memory = use_memory
-
-        # Define image embedding
-        self.image_conv = nn.Sequential(
-            nn.Conv2d(3, 16, (2, 2)),
-            nn.ReLU(),
-            nn.MaxPool2d((2, 2)),
-            nn.Conv2d(16, 32, (2, 2)),
-            nn.ReLU(),
-            nn.Conv2d(32, 64, (2, 2)),
-            nn.ReLU()
-        )
-        n = obs_space["image"][0]
-        m = obs_space["image"][1]
-        self.image_embedding_size = ((n-1)//2-2)*((m-1)//2-2)*64
-
-        # Define memory
-        if self.use_memory:
-            self.memory_rnn = nn.LSTMCell(self.image_embedding_size, self.semi_memory_size)
-
-        # Define text embedding/ keep it here but don't use text
-        if self.use_text:
-            self.word_embedding_size = 32
-            self.word_embedding = nn.Embedding(obs_space["text"], self.word_embedding_size)
-            self.text_embedding_size = 128
-            self.text_rnn = nn.GRU(self.word_embedding_size, self.text_embedding_size, batch_first=True)
-
-        # Define the embedding size
-        self.embedding_size = self.semi_memory_size
-        if self.use_text:
-            self.embedding_size += self.text_embedding_size
-
-        # The predictor network, which is trained to predict the output of the target network
-        self.predictor = nn.Sequential(
-            nn.Linear(self.embedding_size, 64),
-            nn.ReLU(),
-            nn.Linear(64, 64),
-            nn.ReLU()
-        )
-
-        # The target network, which is randomly initialized and then frozen
-        self.target = nn.Sequential(
-            nn.Linear(self.embedding_size, 64),
-            nn.ReLU(),
-            nn.Linear(64, 64),
-            nn.ReLU()
-        )
-
-        # Initialize parameters correctly
-        self.apply(init_params)
-
-        # The target network is not trained, so we freeze its parameters
-        for param in self.target.parameters():
-            param.requires_grad = False
-
-        for param in self.predictor.parameters():
-            param.requires_grad = True
-
-    @property
-    def memory_size(self):
-        return 2*self.semi_memory_size
-
-    @property
-    def semi_memory_size(self):
-        return self.image_embedding_size
-
-    # The forward pass calculates the output of the target and predictor networks
-    def forward(self, next_obs, memory):
-        x = next_obs.image.transpose(1, 3).transpose(2, 3)
-        x = self.image_conv(x)
-        x = x.reshape(x.shape[0], -1)
-
-        # use memory?
-        if self.use_memory:
-            hidden = (memory[:, :self.semi_memory_size], memory[:, self.semi_memory_size:])
-            hidden = self.memory_rnn(x, hidden)
-            embedding = hidden[0]
-            memory = torch.cat(hidden, dim=1)
-        else:
-            embedding = x
-
-        # use text?
-        if self.use_text:
-            embed_text = self._get_embed_text(next_obs.text)
-            embedding = torch.cat((embedding, embed_text), dim=1)
-
-        target_feature = self.target(embedding)
-        predict_feature = self.predictor(embedding)
-
-        return predict_feature, target_feature
-
-    def _get_embed_text(self, text):
-        _, hidden = self.text_rnn(self.word_embedding(text))
-        return hidden[-1]
-    
-    # def reset_memory(self, batch_size):
-    #     # Reset the LSTM hidden state. You can modify this code based on your requirements.
-    #     return torch.zeros((batch_size, self.memory_size)).to(self.memory_rnn.weight.device)
-
-
-
-class StateActionNet(nn.Module):
-    def __init__(self, obs_space,use_memory=False):
-        super(StateActionNet, self).__init__()
-        
-        # Decide which components are enabled
-        self.use_memory = use_memory
-
-        self.image_conv = nn.Sequential(
-            nn.Conv2d(3, 16, (2, 2)),
-            nn.ReLU(),
-            nn.MaxPool2d((2, 2)),
-            nn.Conv2d(16, 32, (2, 2)),
-            nn.ReLU(),
-            nn.Conv2d(32, 64, (2, 2)),
-            nn.ReLU()
-        )
-        n = obs_space["image"][0]
-        m = obs_space["image"][1]
-        self.image_embedding_size = ((n-1)//2-2)*((m-1)//2-2)*64
-        
-        #         # Define the feed-forward network for the action
-        # self.action_net = nn.Sequential(
-        #     nn.Linear(1, 3),
-        #     nn.ReLU()
-        # )
-        
-        # # Define the LSTM that will process the combined state-action embeddings
-        # self.lstm = nn.LSTM(input_size=self.image_embedding_size + 3, 
-        #                    hidden_size=hidden_size, 
-        #                    num_layers=num_layers)
-
-    def forward(self, obs, action):
-        # Pass each state and action through their respective networks
-        x = obs.transpose(1, 3).transpose(2, 3)
-        x = self.image_conv(x)
-        x = x.reshape(x.shape[0], -1)
-        # action_embeddings = self.action_net(action)
-
-        # Combine the state and action embeddings
-        # combined = torch.cat((x, action_embeddings), dim=-1)
-
-        # # Pass the combined embeddings through the RNN
-        # output, _ = self.lstm(combined)
-
-        return x
-
diff --git a/rl-starter-files/__init__.py b/rl-starter-files/__init__.py
deleted file mode 100644
index afd548e..0000000
--- a/rl-starter-files/__init__.py
+++ /dev/null
@@ -1 +0,0 @@
-from scripts import train
\ No newline at end of file
diff --git a/rl-starter-files/model.py b/rl-starter-files/model.py
deleted file mode 100644
index 56305d2..0000000
--- a/rl-starter-files/model.py
+++ /dev/null
@@ -1,141 +0,0 @@
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-from torch.distributions.categorical import Categorical
-import torch_ac
-
-
-
-# Function from https://github.com/ikostrikov/pytorch-a2c-ppo-acktr/blob/master/model.py
-def init_params(m):
-    # takes as input a pytorch class m and checks if the class is linear, if that's the case then the weights are sampled from a normal 0,1 distribution
-    # and rescaled by their squared root mean
-    # if the bias is none then it is initialized as 0
-    classname = m.__class__.__name__
-    if classname.find("Linear") != -1:
-        m.weight.data.normal_(0, 1)
-        m.weight.data *= 1 / torch.sqrt(m.weight.data.pow(2).sum(1, keepdim=True))
-        if m.bias is not None:
-            m.bias.data.fill_(0)
-
-
-class ACModel(nn.Module, torch_ac.RecurrentACModel):
-    def __init__(self, obs_space, action_space, use_memory=True, use_text=False, use_diayn=False, skill_size=0):
-        super().__init__()
-
-        # Decide which components are enabled
-        self.use_text = use_text
-        self.use_memory = use_memory
-
-        # Add a flag for DIAYN since in that method, the actor-critic has to take as input the skill as well
-        # the agent's policy (the actor) is rewarded for making the discriminator's job as difficult as possible
-        self.use_diayn = use_diayn
-        self.skill_size = skill_size
-
-        # Define image embedding
-        self.image_conv = nn.Sequential(
-            nn.Conv2d(3, 16, (2, 2)),
-            nn.ReLU(),
-            nn.MaxPool2d((2, 2)),
-            nn.Conv2d(16, 32, (2, 2)),
-            nn.ReLU(),
-            nn.Conv2d(32, 64, (2, 2)),
-            nn.ReLU()
-        )
-        n = obs_space["image"][0]
-        m = obs_space["image"][1]
-        self.image_embedding_size = ((n-1)//2-2)*((m-1)//2-2)*64
-
-        # Define memory
-        if self.use_memory:
-            self.memory_rnn = nn.LSTMCell(self.image_embedding_size, self.semi_memory_size)
-
-        # Define text embedding
-        if self.use_text:
-            self.word_embedding_size = 32
-            self.word_embedding = nn.Embedding(obs_space["text"], self.word_embedding_size)
-            self.text_embedding_size = 128
-            self.text_rnn = nn.GRU(self.word_embedding_size, self.text_embedding_size, batch_first=True)
-
-        # Resize image embedding
-        self.embedding_size = self.semi_memory_size
-        if self.use_text:
-            self.embedding_size += self.text_embedding_size
-    
-        # If we add the skill as input, the embedding size increases by the skill embedding size
-        if self.use_diayn == True:
-            self.embedding_size  += self.skill_size
-
-        # Define actor's model
-        self.actor = nn.Sequential(
-            nn.Linear(self.embedding_size, 64),
-            nn.Tanh(),
-            nn.Linear(64, action_space.n)
-        )
-
-        # Define critic's model
-        self.critic = nn.Sequential(
-            nn.Linear(self.embedding_size, 64),
-            nn.Tanh(),
-            nn.Linear(64, 1)
-        )
-
-        # Initialize parameters correctly
-        self.apply(init_params)
-
-    @property
-    def memory_size(self):
-        return 2*self.semi_memory_size
-
-    @property
-    def semi_memory_size(self):
-        return self.image_embedding_size
-
-    def forward(self, obs, memory, skills = None):
-        # transpose your image and put it through your image embedding net
-        x = obs.image.transpose(1, 3).transpose(2, 3)
-        x = self.image_conv(x)
-        x = x.reshape(x.shape[0], -1)
-
-        if self.use_memory:
-            hidden = (memory[:, :self.semi_memory_size], memory[:, self.semi_memory_size:])
-            hidden = self.memory_rnn(x, hidden)
-            embedding = hidden[0]
-            lstm_embedding = embedding
-            memory = torch.cat(hidden, dim=1)
-        else:
-            embedding = x
-            lstm_embedding = None
-
-        if self.use_text:
-            embed_text = self._get_embed_text(obs.text)
-            embedding = torch.cat((embedding, embed_text), dim=1)
-
-        # print("embedding size", embedding.shape )
-        # print("skill size", skills.shape)
-
-        if self.use_diayn == True:
-            # Expand dimensions to match the batch size of the embeddings
-            # skills = skills.unsqueeze(0).expand(embedding.size(0), -1)
-            embedding = torch.cat((embedding, skills), dim=1)
-
-        # print("embedding size", embedding.shape )
-
-        # The output x is typically a tensor where each element represents the raw (unnormalized) 
-        # log-probability of taking a particular action. These raw log-probabilities are often called "logits".
-        x = self.actor(embedding)
-
-        # log_softmax will exponentiate and normalize the tensor to get an actual
-        # tensor of probabilities over the space of actions then Categorical creates a Pytorch categorical distribution
-        dist = Categorical(logits=F.log_softmax(x, dim=1))
-
-        # the critic component will output the expected value of the state under the current policy
-        x = self.critic(embedding)
-        value = x.squeeze(1)
-
-        # return the true distribution over states, the value obtained from the critic network
-        return dist, value, memory, lstm_embedding
-
-    def _get_embed_text(self, text):
-        _, hidden = self.text_rnn(self.word_embedding(text))
-        return hidden[-1]
diff --git a/rl-starter-files/params_test.txt b/rl-starter-files/params_test.txt
deleted file mode 100644
index 9352ae5..0000000
--- a/rl-starter-files/params_test.txt
+++ /dev/null
@@ -1,218 +0,0 @@
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 None 0.01 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 count 0.005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 RND 0.05 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 DIAYN 0.1 10 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 TrajectoryCount 0.001 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 TrajectoryWindowCount 0.005 1 3
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 TrajectoryRND 0.05 1 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 TrajectoryRND 0.001 1 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 TrajectoryRND 0.0005 1 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 TrajectoryRND 0.01 1 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 TrajectoryRND 0.05 1 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 count 0.1 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 count 0.005 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 count 0.001 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 count 0.0005 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 count 0.01 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 count 0.05 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 count 0.1 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 TrajectoryRND 0.005 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 TrajectoryRND 0.001 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 TrajectoryRND 0.0005 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 TrajectoryRND 0.01 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 TrajectoryRND 0.05 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 count 0.1 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 count 0.005 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 count 0.001 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 count 0.0005 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 count 0.01 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 count 0.05 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 1 30000000 count 0.1 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 TrajectoryRND 0.005 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 TrajectoryRND 0.001 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 TrajectoryRND 0.0005 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 TrajectoryRND 0.01 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 TrajectoryRND 0.05 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 count 0.1 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 count 0.005 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 count 0.001 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 count 0.0005 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 count 0.01 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 count 0.05 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 count 0.1 15 0
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.005 1 3
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.001 1 3
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.0005 1 3
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.01 1 3
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.05 1 3
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.1 1 3
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.005 1 5
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.001 1 5
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.0005 1 5
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.01 1 5
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.05 1 5
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.1 1 5
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.005 1 10
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.001 1 10
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.0005 1 10
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.01 1 10
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.05 1 10
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 3 30000000 TrajectoryWindowCount 0.1 1 10
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.005 1 3
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.001 1 3
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.0005 1 3
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.01 1 3
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.05 1 3
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.1 1 3
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.005 1 5
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.001 1 5
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.0005 1 5
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.01 1 5
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.05 1 5
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.1 1 5
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.005 1 10
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.001 1 10
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.0005 1 10
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.01 1 10
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.05 1 10
-MiniGrid-MultiRoom-N7-S4-v0 MultiroomN7S4 2 30000000 TrajectoryWindowCount 0.1 1 10
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryCount 0.005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryCount 0.001 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryCount 0.0005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryCount 0.01 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryCount 0.05 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryCount 0.1 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryCount 0.005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryCount 0.001 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryCount 0.0005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryCount 0.01 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryCount 0.05 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryCount 0.1 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 TrajectoryRND 0.005 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 TrajectoryRND 0.001 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 TrajectoryRND 0.0005 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 TrajectoryRND 0.01 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 TrajectoryRND 0.05 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 1 30000000 TrajectoryRND 0.1 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 None 0.005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 RND 0.005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 RND 0.001 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 RND 0.0005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 RND 0.01 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 RND 0.05 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 RND 0.1 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 count 0.005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 count 0.001 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 count 0.0005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 count 0.01 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 count 0.05 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 count 0.1 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryCount 0.005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryCount 0.001 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryCount 0.0005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryCount 0.01 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryCount 0.05 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryCount 0.1 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.005 10 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.001 10 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.0005 10 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.01 10 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.05 10 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.1 10 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.005 5 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.001 5 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.0005 5 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.01 5 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.05 5 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.1 5 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.005 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.001 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.0005 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.01 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.05 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 DIAYN 0.1 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.005 1 3
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.001 1 3
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.0005 1 3
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.01 1 3
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.05 1 3
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.1 1 3
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.005 1 5
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.001 1 5
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.0005 1 5
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.01 1 5
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.05 1 5
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.1 1 5
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.005 1 10
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.001 1 10
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.0005 1 10
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.01 1 10
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.05 1 10
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryWindowCount 0.1 1 10
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryRND 0.005 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryRND 0.001 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryRND 0.0005 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryRND 0.01 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryRND 0.05 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 2 30000000 TrajectoryRND 0.1 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 None 0.005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 RND 0.005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 RND 0.001 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 RND 0.0005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 RND 0.01 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 RND 0.05 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 RND 0.1 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 count 0.005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 count 0.001 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 count 0.0005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 count 0.01 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 count 0.05 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 count 0.1 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryCount 0.005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryCount 0.001 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryCount 0.0005 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryCount 0.01 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryCount 0.05 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryCount 0.1 1 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.005 10 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.001 10 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.0005 10 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.01 10 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.05 10 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.1 10 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.005 5 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.001 5 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.0005 5 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.01 5 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.05 5 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.1 5 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.005 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.001 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.0005 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.01 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.05 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 DIAYN 0.1 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.005 1 3
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.001 1 3
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.0005 1 3
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.01 1 3
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.05 1 3
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.1 1 3
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.005 1 5
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.001 1 5
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.0005 1 5
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.01 1 5
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.05 1 5
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.1 1 5
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.005 1 10
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.001 1 10
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.0005 1 10
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.01 1 10
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.05 1 10
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryWindowCount 0.1 1 10
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryRND 0.005 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryRND 0.001 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryRND 0.0005 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryRND 0.01 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryRND 0.05 15 0
-MiniGrid-KeyCorridorS3R3-v0 KeyCorridor3R3 3 30000000 TrajectoryRND 0.1 15 0
\ No newline at end of file
diff --git a/rl-starter-files/return_per_episode.png b/rl-starter-files/return_per_episode.png
deleted file mode 100644
index 7235420..0000000
Binary files a/rl-starter-files/return_per_episode.png and /dev/null differ
diff --git a/rl-starter-files/run_script_test.sh b/rl-starter-files/run_script_test.sh
deleted file mode 100644
index 63c68bb..0000000
--- a/rl-starter-files/run_script_test.sh
+++ /dev/null
@@ -1,58 +0,0 @@
-# this line tells the scheduler to interpret the rest of the script as a bash script
-#$ -S /bin/bash
-
-# set a task increment
-#$ -t 1-7
-
-# amount of memory
-#$ -l tmem=10G
-
-# Limit of time
-#$ -l h_rt=10:00:00
-
-# Request a number of GPU cards, in this case 2 (the maximum)
-###$ -l gpu=true
-
-# GPU
-###$ -pe gpu 1
-###$ -l gpu_type=!(gtx1080ti|titanx)
-
-# reserves requested resources:
-#$ -R y
-
-# Set the name of the job.
-#$ -N Minigrid_KS3R3
-
-#activate the virtual environment
-#source /home/rmapkay/new-env/bin/activate
-# source /shared/ucl/apps/miniconda/4.10.3/etc/profile.d/conda.sh
-# conda activate minigrid
-
-
-# Set the working directory to somewhere in your scratch space.  
-#  This is a necessary step as compute nodes cannot write to $HOME.
-# Replace "<your_UCL_id>" with your UCL user ID.
-#$ -wd /cluster/project7/diversity_rl/diversity_study/rl-starter-files
-
-# # Checks which copy of Python is being run
-# command -v python3
-
-# # Checks which libraries that version of Python is using
-# ldd `command -v python3`
-
-
-# #read parameter values and run
-paramfile=/cluster/project7/diversity_rl/diversity_study/rl-starter-files/params_test.txt
-
-env="`sed -n ${SGE_TASK_ID}'{p;q}' $paramfile | awk '{print $1}'`"
-folder_name="`sed -n ${SGE_TASK_ID}'{p;q}' $paramfile | awk '{print $2}'`"
-seed="`sed -n ${SGE_TASK_ID}'{p;q}' $paramfile | awk '{print $3}'`"
-frames="`sed -n ${SGE_TASK_ID}'{p;q}' $paramfile | awk '{print $4}'`"
-intrinsic_reward_model="`sed -n ${SGE_TASK_ID}'{p;q}' $paramfile | awk '{print $5}'`"
-beta_coeff="`sed -n ${SGE_TASK_ID}'{p;q}' $paramfile | awk '{print $6}'`"
-no_skills="`sed -n ${SGE_TASK_ID}'{p;q}' $paramfile | awk '{print $7}'`"
-window_size="`sed -n ${SGE_TASK_ID}'{p;q}' $paramfile | awk '{print $8}'`"
-
-
-echo "$env" "$folder_name" "$seed" "$frames" "$intrinsic_reward_model" "$beta_coeff" "$no_skills" "$window_size"
-/home/ccaracon/miniconda3/condabin/conda run -n minigrid python3 -m scripts.train --algo ppo --env "$env" --model "$folder_name" --seed "$seed" --save-interval 10 --frames "$frames" --intrinsic-reward-model "$intrinsic_reward_model" --intrinsic-coef "$beta_coeff" --number-skills "$no_skills" --window-size "$window_size"
\ No newline at end of file
diff --git a/rl-starter-files/scripts/__init__.py b/rl-starter-files/scripts/__init__.py
deleted file mode 100644
index 92259f5..0000000
--- a/rl-starter-files/scripts/__init__.py
+++ /dev/null
@@ -1 +0,0 @@
-from .train import *
\ No newline at end of file
diff --git a/rl-starter-files/scripts/evaluate.py b/rl-starter-files/scripts/evaluate.py
deleted file mode 100644
index 750c10c..0000000
--- a/rl-starter-files/scripts/evaluate.py
+++ /dev/null
@@ -1,157 +0,0 @@
-import argparse
-import time
-import torch
-import matplotlib.pyplot as plt
-import wandb
-
-from torch_ac.utils.penv import ParallelEnv
-
-
-import utils
-from utils import device
-
-
-# Parse arguments
-
-parser = argparse.ArgumentParser()
-parser.add_argument("--env", required=True,
-                    help="name of the environment (REQUIRED)")
-parser.add_argument("--model", required=True,
-                    help="name of the trained model (REQUIRED)")
-parser.add_argument("--episodes", type=int, default=100,
-                    help="number of episodes of evaluation (default: 100)")
-parser.add_argument("--seed", type=int, default=0,
-                    help="random seed (default: 0)")
-parser.add_argument("--procs", type=int, default=16,
-                    help="number of processes (default: 16)")
-parser.add_argument("--argmax", action="store_true", default=False,
-                    help="action with highest probability is selected")
-parser.add_argument("--worst-episodes-to-show", type=int, default=10,
-                    help="how many worst episodes to show")
-parser.add_argument("--memory", action="store_true", default=False,
-                    help="add a LSTM to the model")
-parser.add_argument("--text", action="store_true", default=False,
-                    help="add a GRU to the model")
-parser.add_argument("--wadb-project-name", default="RL_evals",
-                    help="name of the project for Weights and Biases")
-parser.add_argument("--model-flag", default="",
-                    help="name of the method (default: "")")
-
-if __name__ == "__main__":
-    args = parser.parse_args()
-
-    # Set seed for all randomness sources
-
-    utils.seed(args.seed)
-
-    # Set device
-
-    print(f"Device: {device}\n")
-
-    # Load Weights & Biases
-    wandb.login()
-
-    # Load environments
-
-    envs = []
-    for i in range(args.procs):
-        env = utils.make_env(args.env, args.seed + 10000 * i)
-        envs.append(env)
-    env = ParallelEnv(envs)
-    print("Environments loaded\n")
-
-    # Load agent
-
-    model_dir = utils.get_model_dir(args.model)
-    agent = utils.Agent(env.observation_space, env.action_space,args.model_flag, model_dir,
-                        argmax=args.argmax, num_envs=args.procs,
-                        use_memory=args.memory, use_text=args.text)
-    print("Agent loaded\n")
-
-    # Initialize logs
-
-    logs = {"num_frames_per_episode": [], "return_per_episode": []}
-
-    # Run agent
-
-    start_time = time.time()
-
-    obss = env.reset()
-
-    log_done_counter = 0
-    # args.procs is the number of parallel environments
-    # placeholder for episode return and the episode ends when the episode ends or after a number of steps
-    log_episode_return = torch.zeros(args.procs, device=device)
-    log_episode_num_frames = torch.zeros(args.procs, device=device)
-
-    # Initialize run
-    run = wandb.init(
-    # Set the entity
-    entity = "cori-caraconcea",
-    # Set the project where this run will be logged
-    project="test for RL",
-    # Track hyperparameters and run metadata
-    config={
-        "model": args.model_flag    
-        })
-
-    # essentially run this until you have a certain number of done episodes
-    while log_done_counter < args.episodes:
-        actions = agent.get_actions(obss)
-        obss, rewards, terminateds, truncateds, _ = env.step(actions)
-        dones = tuple(a | b for a, b in zip(terminateds, truncateds))
-        agent.analyze_feedbacks(rewards, dones)
-
-        log_episode_return += torch.tensor(rewards, device=device, dtype=torch.float)
-        log_episode_num_frames += torch.ones(args.procs, device=device)
-
-        for i, done in enumerate(dones):
-            if done:
-                log_done_counter += 1
-                logs["return_per_episode"].append(log_episode_return[i].item())
-                logs["num_frames_per_episode"].append(log_episode_num_frames[i].item())
-                # wandb.log({"return_per_episode": log_episode_return[i].item(), "num_frames_per_episode": log_episode_num_frames[i].item()})
-
-        mask = 1 - torch.tensor(dones, device=device, dtype=torch.float)
-        log_episode_return *= mask
-        log_episode_num_frames *= mask
-
-    end_time = time.time()
-
-    # Print logs
-
-    num_frames = sum(logs["num_frames_per_episode"])
-    # calculate the frames per second
-    fps = num_frames / (end_time - start_time)
-    # calculate the total duration for all the episodes
-    duration = int(end_time - start_time)
-    # return per episodes and no of frames per episode -> the synthesize function will return mean, std, min and max
-    return_per_episode = utils.synthesize(logs["return_per_episode"])
-    num_frames_per_episode = utils.synthesize(logs["num_frames_per_episode"])
-
-    print("F {} | FPS {:.0f} | D {} | R:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {}"
-          .format(num_frames, fps, duration,
-                  *return_per_episode.values(),
-                  *num_frames_per_episode.values()))
-
-
-    print("return per episode", return_per_episode['mean'])
-
-    # Print worst episodes
-
-    n = args.worst_episodes_to_show
-    if n > 0:
-        print("\n{} worst episodes:".format(n))
-
-        indexes = sorted(range(len(logs["return_per_episode"])), key=lambda k: logs["return_per_episode"][k])
-        for i in indexes[:n]:
-            print("- episode {}: R={}, F={}".format(i, logs["return_per_episode"][i], logs["num_frames_per_episode"][i]))
-
-    # # Plot return per episode
-    # plt.figure(figsize=(10, 5))
-    # plt.plot(logs["return_per_episode"])
-    # plt.xlabel('Episode')
-    # plt.ylabel('Return')
-    # plt.title('Return per Episode')
-    # plt.show()
-    # plt.savefig('return_per_episode.png')
\ No newline at end of file
diff --git a/rl-starter-files/scripts/train.py b/rl-starter-files/scripts/train.py
deleted file mode 100644
index d12fc3c..0000000
--- a/rl-starter-files/scripts/train.py
+++ /dev/null
@@ -1,324 +0,0 @@
-import argparse
-import time
-import datetime
-# import torch_ac
-import tensorboardX
-import sys
-import wandb
-
-sys.path.insert(0, '/cluster/project7/diversity_rl/diversity_study/rl-starter-files')
-
-import utils 
-from utils import device
-from model import ACModel
-
-import sys
-import os
-
-# Add folder1 to system path
-# sys.path.insert(0, os.path.abspath('/Users/corinacaraconcea/Downloads/diversity_study/torch_ac_v2/torch_ac_v2/algos'))
-
-sys.path.insert(0, '/cluster/project7/diversity_rl/diversity_study/torch_ac_v2/torch_ac_v2/algos')
-
-
-import a2c
-import ppo
-
-from Minigrid.minigrid.__init__ import register_minigrid_envs
-
-register_minigrid_envs()
-
-# Parse arguments
-
-#The argparse module is a standard Python library for writing user-friendly command-line interfaces.
-parser = argparse.ArgumentParser()
-
-# General parameters
-# which algorithm
-parser.add_argument("--algo", required=True,
-                    help="algorithm to use: a2c | ppo (REQUIRED)")
-# which environment
-parser.add_argument("--env", required=True,
-                    help="name of the environment to train on (REQUIRED)")
-# which model
-parser.add_argument("--model", default=None,
-                    help="name of the model (default: {ENV}_{ALGO}_{TIME})")
-parser.add_argument("--seed", type=int, default=1,
-                    help="random seed (default: 1)")
-parser.add_argument("--log-interval", type=int, default=1,
-                    help="number of updates between two logs (default: 1)")
-parser.add_argument("--save-interval", type=int, default=10,
-                    help="number of updates between two saves (default: 10, 0 means no saving)")
-parser.add_argument("--procs", type=int, default=16,
-                    help="number of processes (default: 16)")
-parser.add_argument("--frames", type=int, default=10**7,
-                    help="number of frames of training (default: 1e7)")
-
-# Parameters for main algorithm
-parser.add_argument("--epochs", type=int, default=4,
-                    help="number of epochs for PPO (default: 4)")
-parser.add_argument("--batch-size", type=int, default=256,
-                    help="batch size for PPO (default: 256)")
-parser.add_argument("--frames-per-proc", type=int, default=None,
-                    help="number of frames per process before update (default: 5 for A2C and 128 for PPO)")
-parser.add_argument("--discount", type=float, default=0.99,
-                    help="discount factor (default: 0.99)")
-parser.add_argument("--lr", type=float, default=0.0001,
-                    help="learning rate (default: 0.0001)")
-parser.add_argument("--gae-lambda", type=float, default=0.95,
-                    help="lambda coefficient in GAE formula (default: 0.95, 1 means no gae)")
-parser.add_argument("--entropy-coef", type=float, default=0.0005,
-                    help="entropy term coefficient (default: 0.0005)")
-parser.add_argument("--value-loss-coef", type=float, default=0.5,
-                    help="value loss term coefficient (default: 0.5)")
-parser.add_argument("--max-grad-norm", type=float, default=0.5,
-                    help="maximum norm of gradient (default: 0.5)")
-parser.add_argument("--optim-eps", type=float, default=1e-8,
-                    help="Adam and RMSprop optimizer epsilon (default: 1e-8)")
-parser.add_argument("--optim-alpha", type=float, default=0.99,
-                    help="RMSprop optimizer alpha (default: 0.99)")
-parser.add_argument("--clip-eps", type=float, default=0.2,
-                    help="clipping epsilon for PPO (default: 0.2)")
-parser.add_argument("--recurrence", type=int, default=2,
-                    help="number of time-steps gradient is backpropagated (default: 1). If > 1, a LSTM is added to the model to have memory.")
-parser.add_argument("--text", action="store_true", default=False,
-                    help="add a GRU to the model to handle text input")
-
-parser.add_argument("--intrinsic-coef", type=float, default=0.005,
-                    help="beta coefficient for the intrinsic reward (default: 0.005)")
-
-parser.add_argument("--intrinsic-reward-model", default=None,
-                    help="ntrinsic-reward-model, pick from count, RND , DIAYN, TrajectoryCount (default: count)")
-
-parser.add_argument("--number-skills", type=int, default=10,
-                    help="number of skills for DIAYN (default: 10)")
-
-parser.add_argument("--window-size", type=int, default=5,
-                    help="window size (default: 5)")
-
-
-if __name__ == "__main__":
-
-
-    args = parser.parse_args()
-
-    args.mem = args.recurrence > 1
-
-    diayn_flag = args.intrinsic_reward_model == "DIAYN"
-
-    if args.intrinsic_reward_model == None:
-        model_flag = ""
-    else:
-        model_flag = args.intrinsic_reward_model
-        print(model_flag)
-
-    # Set run dir
-    # set te directory where you save the model and the logs
-
-    date = datetime.datetime.now().strftime("%y-%m-%d-%H-%M-%S")
-    default_model_name = f"{args.env}_{args.algo}_seed{args.seed}_{date}"
-
-    model_name = args.model or default_model_name
-    model_dir = utils.get_model_dir(model_name)
-    # Load loggers and Tensorboard writer
-
-    txt_logger = utils.get_txt_logger(model_dir)
-    csv_file, csv_logger = utils.get_csv_logger(model_dir)
-    tb_writer = tensorboardX.SummaryWriter(model_dir)
-
-    # Log command and all script arguments
-    # setup loggers to log information to the terminal, a text file, a CSV file and tensorboard
-
-    txt_logger.info("{}\n".format(" ".join(sys.argv)))
-    txt_logger.info("{}\n".format(args))
-
-    # Set seed for all randomness sources
-
-    utils.seed(args.seed)
-
-    # Set device
-
-    txt_logger.info(f"Device: {device}\n")
-
-    # Load environments
-
-    envs = []
-    for i in range(args.procs):
-        envs.append(utils.make_env(args.env, args.seed + 10000 * i))
-    txt_logger.info("Environments loaded\n")
-
-    # Load training status for ACmodel from the intrinsic reward directory
-    try:
-        status_base = utils.get_status(model_flag, model_dir)
-    except OSError:
-        status_base = {"num_frames": 0, "update": 0}
-    txt_logger.info("Training status loaded\n")
-
-    # print("status_base: ", status_base)
-
-    # Load observations preprocessor
-
-    obs_space, preprocess_obss = utils.get_obss_preprocessor(envs[0].observation_space)
-    action_space = envs[0].action_space
-    print("actions space", action_space)
-
-    if "vocab" in status_base:
-        preprocess_obss.vocab.load_vocab(status_base["vocab"])
-    txt_logger.info("Observations preprocessor loaded")
-
-    # Load model
-
-    acmodel = ACModel(obs_space, envs[0].action_space, args.mem, args.text,diayn_flag,args.number_skills)
-    if "model_state" in status_base:
-        acmodel.load_state_dict(status_base["model_state"])
-    acmodel = acmodel.to(device)
-    txt_logger.info("Model loaded\n")
-    txt_logger.info("{}\n".format(acmodel))
-
-    
-    # Load algo
-
-    if args.algo == "a2c":
-        if args.rnd_model_flag is not None:
-            algo = a2c.A2CAlgo(envs, acmodel,rndmodel, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,
-                            args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,
-                            args.optim_alpha, args.optim_eps, preprocess_obss,args.wrapper, args.intrinsic_coef)
-        else:
-            algo = a2c.A2CAlgo(envs, acmodel,None, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,
-                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,
-                args.optim_alpha, args.optim_eps, preprocess_obss,args.wrapper, args.intrinsic_coef)
-
-    elif args.algo == "ppo":
-        if args.intrinsic_reward_model == "count":
-            algo = ppo.PPOAlgo(envs, obs_space,action_space, acmodel,None, args.intrinsic_reward_model, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,
-                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,
-                                args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, args.intrinsic_coef, args.number_skills,args.window_size)
-        elif args.intrinsic_reward_model == "RND":
-            algo = ppo.PPOAlgo(envs, obs_space, action_space, acmodel,None, args.intrinsic_reward_model, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,
-                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,
-                                args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, args.intrinsic_coef,args.number_skills,args.window_size)
-        elif args.intrinsic_reward_model == "TrajectoryCount":
-            algo = ppo.PPOAlgo(envs,obs_space, action_space, acmodel,None, args.intrinsic_reward_model, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,
-                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,
-                                args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, args.intrinsic_coef,args.number_skills,args.window_size)
-        elif args.intrinsic_reward_model == "TrajectoryWindowCount":
-            algo = ppo.PPOAlgo(envs,obs_space, action_space, acmodel,None, args.intrinsic_reward_model, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,
-                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,
-                                args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, args.intrinsic_coef,args.number_skills,args.window_size)
-        elif args.intrinsic_reward_model == "DIAYN":
-            algo = ppo.PPOAlgo(envs,obs_space, action_space, acmodel, None, args.intrinsic_reward_model, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,
-                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,
-                                args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, args.intrinsic_coef,args.number_skills,args.window_size)
-        elif args.intrinsic_reward_model == "TrajectoryRND":
-            algo = ppo.PPOAlgo(envs,obs_space, action_space, acmodel, None, args.intrinsic_reward_model, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,
-                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,
-                                args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, args.intrinsic_coef,args.number_skills,args.window_size) 
-        elif args.intrinsic_reward_model == "None":
-            algo = ppo.PPOAlgo(envs, obs_space, action_space, acmodel, None, None, device, args.frames_per_proc, args.discount, args.lr, args.gae_lambda,
-                                args.entropy_coef, args.value_loss_coef, args.max_grad_norm, args.recurrence,
-                                args.optim_eps, args.clip_eps, args.epochs, args.batch_size, preprocess_obss, args.intrinsic_coef,args.number_skills,args.window_size)     
-        else:
-            raise ValueError("Incorrect algorithm name: {}".format(args.algo))
-
-    else:
-        raise ValueError("Incorrect algorithm name: {}".format(args.algo))
-
-    if "optimizer_state" in status_base:
-        algo.optimizer.load_state_dict(status_base["optimizer_state"])
-    txt_logger.info("Optimizer loaded\n")
-
-    # Initialize the Weights and Biases run
-    run = wandb.init(
-    # Set the entity
-    entity = "cori-caraconcea",
-    # Set the project where this run will be logged
-    project="Empty Minigrid 16x16",
-    # Track hyperparameters and run metadata
-    config={
-        "model": model_flag,
-        "env": args.env,
-        "seed": args.seed,
-        "intr_coeff": args.intrinsic_coef,
-        "window_size": args.window_size,
-        "no_skills": args.number_skills
-        })
-
-    # Train model
-
-    num_frames = status_base["num_frames"]
-    update = status_base["update"]
-    start_time = time.time()
-
-    while num_frames < args.frames:
-        # Update model parameters
-        update_start_time = time.time()
-        # collect experiece and logs
-        exps, logs1 = algo.collect_experiences()
-        # update parameters and get logs
-        logs2 = algo.update_parameters(exps)
-        # print("parameters update")
-        logs = {**logs1, **logs2}
-        update_end_time = time.time()
-
-        # increase the update count
-        num_frames += logs["num_frames"]
-        update += 1
-
-        # Print logs
-
-        if update % args.log_interval == 0:
-            # number of frames per second
-            fps = logs["num_frames"] / (update_end_time - update_start_time)
-            # duration
-            duration = int(time.time() - start_time)
-            # return per episode
-            return_per_episode = utils.synthesize(logs["return_per_episode"])
-            # reshaped retun per episode
-            rreturn_per_episode = utils.synthesize(logs["reshaped_return_per_episode"])
-            # number of frames per episode
-            num_frames_per_episode = utils.synthesize(logs["num_frames_per_episode"])
-            # external return per episode
-            external_return_per_episode = utils.synthesize(logs["ext_return_per_episode"])
-            # batch policies entropy 
-            entropy = utils.synthesize(logs["entropy"])            
-
-
-            # "mean_rreturn_per_episode_mean": rreturn_per_episode['mean'],
-            wandb.log({"mean_rreturn_per_episode_mean": rreturn_per_episode['mean'],
-                       "batch_entropy_mean": entropy['mean']
-                      })
-
-            header = ["update", "frames", "FPS", "duration"]
-            data = [update, num_frames, fps, duration]
-            header += ["rreturn_" + key for key in rreturn_per_episode.keys()]
-            data += rreturn_per_episode.values()
-            header += ["num_frames_" + key for key in num_frames_per_episode.keys()]
-            data += num_frames_per_episode.values()
-            header += ["entropy", "value", "policy_loss", "value_loss", "grad_norm"]
-            data += [logs["entropy"], logs["value"], logs["policy_loss"], logs["value_loss"], logs["grad_norm"]]
-
-            txt_logger.info(
-                "U {} | F {:010} | FPS {:04.0f} | D {} | rR:μσmM {:.2f} {:.2f} {:.2f} {:.2f} | F:μσmM {:.1f} {:.1f} {} {} | H {:.3f} | V {:.3f} | pL {:.3f} | vL {:.3f} | ∇ {:.3f}"
-                .format(*data))
-
-            header += ["return_" + key for key in return_per_episode.keys()]
-            data += return_per_episode.values()
-
-            if status_base["num_frames"] == 0:
-                csv_logger.writerow(header)
-            csv_logger.writerow(data)
-            csv_file.flush()
-
-            for field, value in zip(header, data):
-                tb_writer.add_scalar(field, value, num_frames)
-
-        # Save status
-
-        if args.save_interval > 0 and update % args.save_interval == 0:
-            status_base = {"model_name": "ACmodel","num_frames": num_frames, "update": update,
-                      "model_state": acmodel.state_dict(), "optimizer_state": algo.optimizer.state_dict()}
-            if hasattr(preprocess_obss, "vocab"):
-                status_base["vocab"] = preprocess_obss.vocab.vocab
-            utils.save_status(status_base,model_flag, model_dir)
-            txt_logger.info("Status saved")
-
diff --git a/rl-starter-files/scripts/visualize.py b/rl-starter-files/scripts/visualize.py
deleted file mode 100644
index 092efe2..0000000
--- a/rl-starter-files/scripts/visualize.py
+++ /dev/null
@@ -1,89 +0,0 @@
-import argparse
-import numpy
-
-import utils
-from utils import device
-
-from Minigrid.minigrid.__init__ import register_minigrid_envs
-
-register_minigrid_envs()
-
-# Parse arguments
-
-parser = argparse.ArgumentParser()
-parser.add_argument("--env", required=True,
-                    help="name of the environment to be run (REQUIRED)")
-parser.add_argument("--model", required=True,
-                    help="name of the trained model (REQUIRED)")
-parser.add_argument("--seed", type=int, default=0,
-                    help="random seed (default: 0)")
-parser.add_argument("--shift", type=int, default=0,
-                    help="number of times the environment is reset at the beginning (default: 0)")
-parser.add_argument("--argmax", action="store_true", default=False,
-                    help="select the action with highest probability (default: False)")
-parser.add_argument("--pause", type=float, default=0.1,
-                    help="pause duration between two consequent actions of the agent (default: 0.1)")
-parser.add_argument("--gif", type=str, default=None,
-                    help="store output as gif with the given filename")
-parser.add_argument("--episodes", type=int, default=1000000,
-                    help="number of episodes to visualize")
-parser.add_argument("--memory", action="store_true", default=False,
-                    help="add a LSTM to the model")
-parser.add_argument("--text", action="store_true", default=False,
-                    help="add a GRU to the model")
-
-args = parser.parse_args()
-
-# Set seed for all randomness sources
-
-utils.seed(args.seed)
-
-# Set device
-
-print(f"Device: {device}\n")
-
-# Load environment
-
-env = utils.make_env(args.env, args.seed, render_mode="human")
-for _ in range(args.shift):
-    env.reset()
-print("Environment loaded\n")
-
-# Load agent
-
-model_dir = utils.get_model_dir(args.model)
-agent = utils.Agent(env.observation_space, env.action_space, "" , model_dir,
-                    argmax=args.argmax, use_memory=args.memory, use_text=args.text)
-print("Agent loaded\n")
-
-# Run the agent
-
-if args.gif:
-    from array2gif import write_gif
-
-    frames = []
-
-# Create a window to view the environment
-env.render()
-
-for episode in range(args.episodes):
-    obs, _ = env.reset()
-
-    while True:
-        env.render()
-        if args.gif:
-            frames.append(numpy.moveaxis(env.get_frame(), 2, 0))
-
-        action = agent.get_action(obs)
-        obs, reward, terminated, truncated, _ = env.step(action)
-        print(env.agent_pos)
-        done = terminated | truncated
-        agent.analyze_feedback(reward, done)
-
-        if done:
-            break
-
-if args.gif:
-    print("Saving gif... ", end="")
-    write_gif(numpy.array(frames), args.gif+".gif", fps=1/args.pause)
-    print("Done.")
diff --git a/rl-starter-files/utils/__init__.py b/rl-starter-files/utils/__init__.py
deleted file mode 100644
index 25d9ad7..0000000
--- a/rl-starter-files/utils/__init__.py
+++ /dev/null
@@ -1,5 +0,0 @@
-from .agent import *
-from .env import *
-from .format import *
-from .other import *
-from .storage import *
diff --git a/rl-starter-files/utils/agent.py b/rl-starter-files/utils/agent.py
deleted file mode 100644
index fae7054..0000000
--- a/rl-starter-files/utils/agent.py
+++ /dev/null
@@ -1,74 +0,0 @@
-import torch
-
-import utils
-from .other import device
-from model import ACModel
-
-
-class Agent:
-    """An agent.
-
-    It is able:
-    - to choose an action given an observation,
-    - to analyze the feedback (i.e. reward and done state) of its action."""
-
-    def __init__(self, obs_space, action_space, model_name,model_dir,
-                 argmax=False, num_envs=1, use_memory=False, use_text=False):
-        # preprocess the observation space
-        obs_space, self.preprocess_obss = utils.get_obss_preprocessor(obs_space)
-        # initialize the model as A2C and check if the agent's model uses memory and if it uses a text input
-        self.acmodel = ACModel(obs_space, action_space, use_memory=use_memory, use_text=use_text)
-        # selects actions using argmax
-        self.argmax = argmax
-        # the number of environments in which the actor acts
-        self.num_envs = num_envs
-
-        # is the model recurrent, a memory tensor is initiated 
-        # the shape is no of environments x memory size
-        if self.acmodel.recurrent:
-            self.memories = torch.zeros(self.num_envs, self.acmodel.memory_size, device=device)
-
-        self.acmodel.load_state_dict(utils.get_model_state(model_name,model_dir))
-        # cpu/gpu
-        self.acmodel.to(device)
-        # evaluate function
-        self.acmodel.eval()
-        if hasattr(self.preprocess_obss, "vocab"):
-            self.preprocess_obss.vocab.load_vocab(utils.get_vocab(model_dir,model_name))
-
-    def get_actions(self, obss):
-        # takes the actions from the preprocessed environment
-        preprocessed_obss = self.preprocess_obss(obss, device=device)
-
-        with torch.no_grad():
-            # do you keep the memory of previous experiences?
-            # feeds them to the actor-critic model to get a distribution over actions
-            if self.acmodel.recurrent:
-                dist, _, self.memories,_ = self.acmodel(preprocessed_obss, self.memories)
-            else:
-                dist, _ = self.acmodel(preprocessed_obss)
-
-        # either take argmax and pick the action with the highest prob or sample from the action space
-        if self.argmax:
-            actions = dist.probs.max(1, keepdim=True)[1]
-        else:
-            actions = dist.sample()
-
-        return actions.cpu().numpy()
-
-    # simplified function for the case when the agent only acts in one environment
-    def get_action(self, obs):
-        return self.get_actions([obs])[0]
-
-    # This method is used when the agent is acting in multiple environments at once. 
-    # It takes a list of rewards and a list of boolean flags indicating whether each environment is done. 
-    # If the model is recurrent, it uses these to update the agent's memories, masking out 
-    # the memories of environments that are done.
-    def analyze_feedbacks(self, rewards, dones):
-        if self.acmodel.recurrent:
-            masks = 1 - torch.tensor(dones, dtype=torch.float, device=device).unsqueeze(1)
-            self.memories *= masks
-
-    # simplified version for when the agent only acts in one environment
-    def analyze_feedback(self, reward, done):
-        return self.analyze_feedbacks([reward], [done])
diff --git a/rl-starter-files/utils/env.py b/rl-starter-files/utils/env.py
deleted file mode 100644
index ddc1cbb..0000000
--- a/rl-starter-files/utils/env.py
+++ /dev/null
@@ -1,9 +0,0 @@
-import gymnasium as gym
-
-
-def make_env(env_key, seed=None, render_mode=None):
-    print(env_key)
-    env = gym.make(env_key, render_mode=render_mode)
-    env.reset(seed=seed)
-    return env
-
diff --git a/rl-starter-files/utils/format.py b/rl-starter-files/utils/format.py
deleted file mode 100644
index 4e581d1..0000000
--- a/rl-starter-files/utils/format.py
+++ /dev/null
@@ -1,92 +0,0 @@
-import os
-import json
-import numpy
-import re
-import torch
-import torch_ac
-import gymnasium as gym
-
-import utils
-
-
-def get_obss_preprocessor(obs_space):
-    # the function checks if the observed space is an image space
-    # then it processes the observation and wraps it around a DictList
-
-    # Check if obs_space is an image space
-    if isinstance(obs_space, gym.spaces.Box):
-        obs_space = {"image": obs_space.shape}
-
-        def preprocess_obss(obss, device=None):
-            return torch_ac.DictList({
-                "image": preprocess_images(obss, device=device)
-            })
-
-    # Check if it is a MiniGrid observation space
-    elif isinstance(obs_space, gym.spaces.Dict) and "image" in obs_space.spaces.keys():
-        obs_space = {"image": obs_space.spaces["image"].shape, "text": 100}
-
-        vocab = Vocabulary(obs_space["text"])
-
-        def preprocess_obss(obss, device=None):
-            return torch_ac.DictList({
-                "image": preprocess_images([obs["image"] for obs in obss], device=device),
-                "text": preprocess_texts([obs["mission"] for obs in obss], vocab, device=device)
-            })
-
-        preprocess_obss.vocab = vocab
-
-    else:
-        raise ValueError("Unknown observation space: " + str(obs_space))
-# The returned obs_space is a dictionary that describes the observation space 
-# (which might be different from the input obs_space), and preprocess_obss 
-# is the preprocessing function that's been defined.
-    return obs_space, preprocess_obss
-
-
-def preprocess_images(images, device=None):
-    # Bug of Pytorch: very slow if not first converted to numpy array
-    images = numpy.array(images)
-    return torch.tensor(images, device=device, dtype=torch.float)
-
-
-def preprocess_texts(texts, vocab, device=None):
-    var_indexed_texts = []
-    max_text_len = 0
-
-    for text in texts:
-        tokens = re.findall("([a-z]+)", text.lower())
-        var_indexed_text = numpy.array([vocab[token] for token in tokens])
-        var_indexed_texts.append(var_indexed_text)
-        max_text_len = max(len(var_indexed_text), max_text_len)
-
-    indexed_texts = numpy.zeros((len(texts), max_text_len))
-
-    for i, indexed_text in enumerate(var_indexed_texts):
-        indexed_texts[i, :len(indexed_text)] = indexed_text
-
-    return torch.tensor(indexed_texts, device=device, dtype=torch.long)
-
-
-class Vocabulary:
-    """A mapping from tokens to ids with a capacity of `max_size` words.
-    It can be saved in a `vocab.json` file."""
-
-# initializes a max size for the vocabulary and an empty vocabulary
-    def __init__(self, max_size):
-        self.max_size = max_size
-        self.vocab = {}
-
-# load an existing vocabulary into the class
-    def load_vocab(self, vocab):
-        self.vocab = vocab
-
-# check if the token is in the vocabulary, if it is return its id
-# if the vocab has reached the max size, then return an error
-# if the token is not in the vocab add it and return a new id
-    def __getitem__(self, token):
-        if not token in self.vocab.keys():
-            if len(self.vocab) >= self.max_size:
-                raise ValueError("Maximum vocabulary capacity reached")
-            self.vocab[token] = len(self.vocab) + 1
-        return self.vocab[token]
diff --git a/rl-starter-files/utils/other.py b/rl-starter-files/utils/other.py
deleted file mode 100644
index 8ab0eb4..0000000
--- a/rl-starter-files/utils/other.py
+++ /dev/null
@@ -1,25 +0,0 @@
-import random
-import numpy
-import torch
-import collections
-
-
-device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-# device = "cuda"
-
-
-def seed(seed):
-    random.seed(seed)
-    numpy.random.seed(seed)
-    torch.manual_seed(seed)
-    if torch.cuda.is_available():
-        torch.cuda.manual_seed_all(seed)
-
-
-def synthesize(array):
-    d = collections.OrderedDict()
-    d["mean"] = numpy.mean(array)
-    d["std"] = numpy.std(array)
-    d["min"] = numpy.amin(array)
-    d["max"] = numpy.amax(array)
-    return d
diff --git a/rl-starter-files/utils/storage.py b/rl-starter-files/utils/storage.py
deleted file mode 100644
index 424e739..0000000
--- a/rl-starter-files/utils/storage.py
+++ /dev/null
@@ -1,81 +0,0 @@
-import csv
-import os
-import torch
-import logging
-import sys
-
-import utils
-from .other import device
-
-
-def create_folders_if_necessary(path):
-    dirname = os.path.dirname(path)
-    if not os.path.isdir(dirname):
-        os.makedirs(dirname)
-
-
-def get_storage_dir():
-    if "RL_STORAGE" in os.environ:
-        return os.environ["RL_STORAGE"]
-    return "storage"
-
-
-def get_model_dir(model_name):
-    return os.path.join(get_storage_dir(), model_name)
-
-
-def get_status_path(model_name,model_dir):
-    return os.path.join(model_dir,model_name, "status.pt")
-
-def get_status_path_rnd(model_name,model_dir):
-    return os.path.join(model_dir,model_name,"rnd_status.pt")
-
-
-def get_status(model_name, model_dir):
-    path = get_status_path(model_name,model_dir)
-    print("this is the path from which I'm loading the model: ", path)
-    return torch.load(path, map_location=device)
-
-def get_status_rnd(model_name, model_dir):
-    path = get_status_path_rnd(model_name,model_dir)
-    return torch.load(path, map_location=device)
-
-def save_status(status, model_name,model_dir):
-    path = get_status_path(model_name,model_dir)
-    utils.create_folders_if_necessary(path)
-    torch.save(status, path)
-
-def save_status_rnd(status, model_name,model_dir):
-    path = get_status_path_rnd(model_name,model_dir)
-    utils.create_folders_if_necessary(path)
-    torch.save(status, path)
-
-def get_vocab(model_dir,model_name):
-    return get_status(model_name,model_dir)["vocab"]
-
-
-def get_model_state(model_name,model_dir):
-    return get_status(model_name,model_dir)["model_state"]
-
-
-def get_txt_logger(model_dir):
-    path = os.path.join(model_dir, "log.txt")
-    utils.create_folders_if_necessary(path)
-
-    logging.basicConfig(
-        level=logging.INFO,
-        format="%(message)s",
-        handlers=[
-            logging.FileHandler(filename=path),
-            logging.StreamHandler(sys.stdout)
-        ]
-    )
-
-    return logging.getLogger()
-
-
-def get_csv_logger(model_dir):
-    csv_path = os.path.join(model_dir, "log.csv")
-    utils.create_folders_if_necessary(csv_path)
-    csv_file = open(csv_path, "a")
-    return csv_file, csv.writer(csv_file)
diff --git a/rl-starter-files/wandb/debug-cli.corinacaraconcea.log b/rl-starter-files/wandb/debug-cli.corinacaraconcea.log
deleted file mode 100644
index e69de29..0000000
diff --git a/rl-starter-files/wandb/debug-internal.log b/rl-starter-files/wandb/debug-internal.log
deleted file mode 120000
index 63145df..0000000
--- a/rl-starter-files/wandb/debug-internal.log
+++ /dev/null
@@ -1 +0,0 @@
-run-20230726_165517-22z3wkhd/logs/debug-internal.log
\ No newline at end of file
diff --git a/rl-starter-files/wandb/debug.log b/rl-starter-files/wandb/debug.log
deleted file mode 120000
index 9688d59..0000000
--- a/rl-starter-files/wandb/debug.log
+++ /dev/null
@@ -1 +0,0 @@
-run-20230726_165517-22z3wkhd/logs/debug.log
\ No newline at end of file
diff --git a/rl-starter-files/wandb/latest-run b/rl-starter-files/wandb/latest-run
deleted file mode 120000
index 87e2862..0000000
--- a/rl-starter-files/wandb/latest-run
+++ /dev/null
@@ -1 +0,0 @@
-run-20230726_165517-22z3wkhd
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/config.yaml b/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/config.yaml
deleted file mode 100644
index 1e3d84a..0000000
--- a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/config.yaml
+++ /dev/null
@@ -1,32 +0,0 @@
-wandb_version: 1
-
-model:
-  desc: null
-  value: ''
-performance metric:
-  desc: null
-  value: extrinsic reward
-_wandb:
-  desc: null
-  value:
-    python_version: 3.9.6
-    cli_version: 0.15.5
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    start_time: 1690384069.599131
-    t:
-      1:
-      - 1
-      - 55
-      2:
-      - 1
-      - 55
-      3:
-      - 16
-      - 23
-      4: 3.9.6
-      5: 0.15.5
-      8:
-      - 4
-      - 5
diff --git a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log b/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
deleted file mode 100644
index 6fe0311..0000000
--- a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
+++ /dev/null
@@ -1,80 +0,0 @@
-log_done_counter 19
-U 1 | F 0000002048 | FPS 1484 | D 1 | rR:μσmM 0.18 0.28 0.00 0.77 | F:μσmM 84.1 26.1 26.0 100.0 | H 1.932 | V 0.123 | pL 0.011 | vL 0.006 | ∇ 0.023
-log_done_counter 26
-U 2 | F 0000004096 | FPS 1576 | D 2 | rR:μσmM 0.32 0.28 0.00 0.82 | F:μσmM 71.7 26.4 20.0 100.0 | H 1.921 | V 0.152 | pL -0.018 | vL 0.010 | ∇ 0.027
-log_done_counter 31
-U 3 | F 0000006144 | FPS 1567 | D 3 | rR:μσmM 0.33 0.30 0.00 0.93 | F:μσmM 70.2 29.3 8.0 100.0 | H 1.920 | V 0.152 | pL -0.017 | vL 0.012 | ∇ 0.038
-log_done_counter 30
-U 4 | F 0000008192 | FPS 1604 | D 5 | rR:μσmM 0.42 0.31 0.00 0.92 | F:μσmM 61.3 30.7 9.0 100.0 | H 1.882 | V 0.156 | pL -0.048 | vL 0.018 | ∇ 0.041
-log_done_counter 41
-U 5 | F 0000010240 | FPS 1510 | D 6 | rR:μσmM 0.54 0.28 0.00 0.95 | F:μσmM 49.9 29.0 6.0 100.0 | H 1.845 | V 0.247 | pL -0.064 | vL 0.023 | ∇ 0.079
-log_done_counter 73
-U 6 | F 0000012288 | FPS 1625 | D 7 | rR:μσmM 0.71 0.23 0.00 0.95 | F:μσmM 32.3 25.2 6.0 100.0 | H 1.765 | V 0.387 | pL -0.174 | vL 0.037 | ∇ 0.107
-log_done_counter 93
-U 7 | F 0000014336 | FPS 1573 | D 9 | rR:μσmM 0.79 0.14 0.36 0.95 | F:μσmM 23.4 15.1 6.0 71.0 | H 1.656 | V 0.543 | pL -0.172 | vL 0.023 | ∇ 0.084
-log_done_counter 132
-U 8 | F 0000016384 | FPS 1602 | D 10 | rR:μσmM 0.85 0.10 0.33 0.95 | F:μσmM 16.6 11.4 6.0 74.0 | H 1.530 | V 0.681 | pL -0.134 | vL 0.013 | ∇ 0.117
-log_done_counter 168
-U 9 | F 0000018432 | FPS 1507 | D 11 | rR:μσmM 0.89 0.06 0.64 0.95 | F:μσmM 12.4 6.8 5.0 40.0 | H 1.386 | V 0.781 | pL -0.091 | vL 0.008 | ∇ 0.082
-log_done_counter 208
-U 10 | F 0000020480 | FPS 1582 | D 13 | rR:μσmM 0.91 0.04 0.72 0.95 | F:μσmM 9.9 4.2 5.0 31.0 | H 1.202 | V 0.851 | pL -0.038 | vL 0.002 | ∇ 0.040
-log_done_counter 266
-U 11 | F 0000022528 | FPS 1601 | D 14 | rR:μσmM 0.93 0.03 0.76 0.95 | F:μσmM 7.9 3.0 5.0 27.0 | H 0.843 | V 0.886 | pL -0.029 | vL 0.001 | ∇ 0.032
-log_done_counter 306
-U 12 | F 0000024576 | FPS 1558 | D 15 | rR:μσmM 0.94 0.01 0.86 0.95 | F:μσmM 6.7 1.6 5.0 16.0 | H 0.523 | V 0.909 | pL -0.002 | vL 0.000 | ∇ 0.009
-log_done_counter 351
-U 13 | F 0000026624 | FPS 1521 | D 17 | rR:μσmM 0.95 0.01 0.90 0.95 | F:μσmM 5.8 1.0 5.0 11.0 | H 0.266 | V 0.923 | pL -0.009 | vL 0.000 | ∇ 0.010
-log_done_counter 397
-U 14 | F 0000028672 | FPS 1560 | D 18 | rR:μσmM 0.95 0.00 0.92 0.95 | F:μσmM 5.2 0.5 5.0 9.0 | H 0.153 | V 0.933 | pL -0.004 | vL 0.000 | ∇ 0.007
-log_done_counter 397
-U 15 | F 0000030720 | FPS 1597 | D 19 | rR:μσmM 0.95 0.00 0.94 0.95 | F:μσmM 5.1 0.4 5.0 7.0 | H 0.109 | V 0.934 | pL -0.003 | vL 0.000 | ∇ 0.004
-log_done_counter 403
-U 16 | F 0000032768 | FPS 1586 | D 20 | rR:μσmM 0.95 0.00 0.94 0.95 | F:μσmM 5.1 0.3 5.0 7.0 | H 0.085 | V 0.935 | pL -0.000 | vL 0.000 | ∇ 0.009
-log_done_counter 405
-U 17 | F 0000034816 | FPS 1632 | D 22 | rR:μσmM 0.95 0.00 0.94 0.95 | F:μσmM 5.1 0.3 5.0 7.0 | H 0.066 | V 0.935 | pL 0.001 | vL 0.000 | ∇ 0.006
-log_done_counter 405
-U 18 | F 0000036864 | FPS 1589 | D 23 | rR:μσmM 0.95 0.00 0.94 0.95 | F:μσmM 5.0 0.2 5.0 7.0 | H 0.054 | V 0.935 | pL -0.002 | vL 0.000 | ∇ 0.006
-log_done_counter 407
-U 19 | F 0000038912 | FPS 1550 | D 24 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.2 5.0 6.0 | H 0.047 | V 0.935 | pL -0.002 | vL 0.000 | ∇ 0.004
-log_done_counter 406
-U 20 | F 0000040960 | FPS 1610 | D 26 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.2 5.0 6.0 | H 0.048 | V 0.935 | pL -0.002 | vL 0.000 | ∇ 0.004
-log_done_counter 408
-U 21 | F 0000043008 | FPS 1571 | D 27 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.2 5.0 6.0 | H 0.039 | V 0.935 | pL -0.003 | vL 0.000 | ∇ 0.006
-log_done_counter 406
-U 22 | F 0000045056 | FPS 1576 | D 28 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.037 | V 0.935 | pL -0.003 | vL 0.000 | ∇ 0.012
-log_done_counter 412
-U 23 | F 0000047104 | FPS 1567 | D 30 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.031 | V 0.936 | pL 0.000 | vL 0.000 | ∇ 0.007
-log_done_counter 405
-U 24 | F 0000049152 | FPS 1576 | D 31 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.027 | V 0.936 | pL 0.002 | vL 0.000 | ∇ 0.016
-log_done_counter 409
-U 25 | F 0000051200 | FPS 1577 | D 32 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.024 | V 0.936 | pL 0.004 | vL 0.000 | ∇ 0.009
-log_done_counter 408
-U 26 | F 0000053248 | FPS 1565 | D 33 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.021 | V 0.935 | pL -0.000 | vL 0.000 | ∇ 0.018
-log_done_counter 411
-U 27 | F 0000055296 | FPS 1589 | D 35 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.020 | V 0.936 | pL 0.006 | vL 0.000 | ∇ 0.009
-log_done_counter 407
-U 28 | F 0000057344 | FPS 1555 | D 36 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.020 | V 0.936 | pL 0.003 | vL 0.000 | ∇ 0.002
-log_done_counter 408
-U 29 | F 0000059392 | FPS 1591 | D 37 | rR:μσmM 0.95 0.00 0.93 0.95 | F:μσmM 5.0 0.2 5.0 8.0 | H 0.017 | V 0.934 | pL 0.002 | vL 0.000 | ∇ 0.054
-log_done_counter 407
-U 30 | F 0000061440 | FPS 1547 | D 39 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.015 | V 0.937 | pL 0.015 | vL 0.000 | ∇ 0.010
-log_done_counter 410
-U 31 | F 0000063488 | FPS 1337 | D 40 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.013 | V 0.936 | pL 0.005 | vL 0.000 | ∇ 0.006
-log_done_counter 411
-U 32 | F 0000065536 | FPS 1617 | D 42 | rR:μσmM 0.95 0.00 0.94 0.95 | F:μσmM 5.0 0.1 5.0 7.0 | H 0.012 | V 0.937 | pL 0.003 | vL 0.000 | ∇ 0.014
-log_done_counter 404
-U 33 | F 0000067584 | FPS 1598 | D 43 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.012 | V 0.935 | pL -0.004 | vL 0.000 | ∇ 0.013
-log_done_counter 414
-U 34 | F 0000069632 | FPS 1586 | D 44 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.011 | V 0.936 | pL 0.005 | vL 0.000 | ∇ 0.023
-log_done_counter 405
-U 35 | F 0000071680 | FPS 1612 | D 45 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.0 5.0 6.0 | H 0.012 | V 0.937 | pL 0.007 | vL 0.000 | ∇ 0.008
-log_done_counter 412
-U 36 | F 0000073728 | FPS 1592 | D 47 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.0 5.0 6.0 | H 0.012 | V 0.936 | pL 0.003 | vL 0.000 | ∇ 0.005
-log_done_counter 410
-U 37 | F 0000075776 | FPS 1665 | D 48 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.012 | V 0.936 | pL 0.001 | vL 0.000 | ∇ 0.006
-log_done_counter 407
-U 38 | F 0000077824 | FPS 1562 | D 49 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.011 | V 0.936 | pL -0.001 | vL 0.000 | ∇ 0.005
-log_done_counter 413
-U 39 | F 0000079872 | FPS 1630 | D 50 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.0 5.0 6.0 | H 0.012 | V 0.936 | pL -0.002 | vL 0.000 | ∇ 0.037
-log_done_counter 404
-U 40 | F 0000081920 | FPS 1546 | D 52 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.011 | V 0.935 | pL -0.009 | vL 0.000 | ∇ 0.004
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/requirements.txt b/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/requirements.txt
deleted file mode 100644
index 05458c5..0000000
--- a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/requirements.txt
+++ /dev/null
@@ -1,85 +0,0 @@
-altgraph==0.17.2
-appdirs==1.4.4
-appnope==0.1.3
-asttokens==2.2.1
-backcall==0.2.0
-certifi==2023.5.7
-charset-normalizer==3.2.0
-click==8.1.4
-cloudpickle==2.2.1
-comm==0.1.2
-contourpy==1.1.0
-cycler==0.11.0
-debugpy==1.6.5
-decorator==5.1.1
-docker-pycreds==0.4.0
-entrypoints==0.4
-executing==1.2.0
-farama-notifications==0.0.4
-filelock==3.12.2
-fonttools==4.40.0
-future==0.18.2
-gitdb==4.0.10
-gitpython==3.1.31
-gym-minigrid==1.2.2
-gym-notices==0.0.8
-gym==0.26.2
-gymnasium==0.28.1
-idna==3.4
-importlib-metadata==6.6.0
-importlib-resources==6.0.0
-ipykernel==6.20.2
-ipython==8.8.0
-jax-jumpy==1.0.0
-jedi==0.18.2
-jinja2==3.1.2
-jupyter-client==7.4.9
-jupyter-core==5.1.3
-kiwisolver==1.4.4
-macholib==1.15.2
-markupsafe==2.1.3
-matplotlib-inline==0.1.6
-matplotlib==3.7.2
-minigrid==2.3.0
-mpmath==1.3.0
-nest-asyncio==1.5.6
-networkx==3.1
-numpy==1.24.3
-packaging==23.0
-parso==0.8.3
-pathtools==0.1.2
-pexpect==4.8.0
-pickleshare==0.7.5
-pillow==10.0.0
-pip==21.2.4
-platformdirs==2.6.2
-prompt-toolkit==3.0.36
-protobuf==3.20.3
-psutil==5.9.4
-ptyprocess==0.7.0
-pure-eval==0.2.2
-pygame==2.4.0
-pygments==2.14.0
-pyparsing==3.0.9
-python-dateutil==2.8.2
-pyyaml==6.0
-pyzmq==25.0.0
-requests==2.31.0
-sentry-sdk==1.28.0
-setproctitle==1.3.2
-setuptools==58.0.4
-six==1.15.0
-smmap==5.0.0
-stack-data==0.6.2
-sympy==1.12
-tensorboardx==2.6
-torch-ac==1.4.0
-torch==2.0.1
-tornado==6.2
-traitlets==5.8.1
-typing-extensions==4.6.3
-urllib3==2.0.3
-wandb==0.15.5
-wcwidth==0.2.6
-wheel==0.37.0
-zipp==3.15.0
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-metadata.json b/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-metadata.json
deleted file mode 100644
index 892dab1..0000000
--- a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-metadata.json
+++ /dev/null
@@ -1,44 +0,0 @@
-{
-    "os": "macOS-13.4-arm64-arm-64bit",
-    "python": "3.9.6",
-    "heartbeatAt": "2023-07-26T15:07:50.420864",
-    "startedAt": "2023-07-26T15:07:49.576314",
-    "docker": null,
-    "cuda": null,
-    "args": [
-        "--algo",
-        "ppo",
-        "--env",
-        "MiniGrid-Empty-5x5-v0",
-        "--model",
-        "Empty",
-        "--save-interval",
-        "10",
-        "--frames",
-        "80000"
-    ],
-    "state": "running",
-    "program": "-m scripts.train",
-    "git": {
-        "remote": "https://github.com/CorinaCaraconcea/diversity_study.git",
-        "commit": "bbd28515d7e4bbc2bcc39a9deff9cc255775ca99"
-    },
-    "email": "cori.caraconcea@gmail.com",
-    "root": "/Users/corinacaraconcea/Downloads/diversity_study",
-    "host": "Corinas-MacBook-Air.local",
-    "username": "corinacaraconcea",
-    "executable": "/Library/Developer/CommandLineTools/usr/bin/python3",
-    "cpu_count": 8,
-    "cpu_count_logical": 8,
-    "disk": {
-        "total": 228.27386474609375,
-        "used": 8.95040512084961
-    },
-    "gpuapple": {
-        "type": "arm",
-        "vendor": "Apple"
-    },
-    "memory": {
-        "total": 8.0
-    }
-}
diff --git a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json b/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
deleted file mode 100644
index 36d12c7..0000000
--- a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
+++ /dev/null
@@ -1 +0,0 @@
-{"external_return_per_episode": 0.9549331516027451, "_timestamp": 1690384122.7852402, "_runtime": 53.18610906600952, "_step": 39, "_wandb": {"runtime": 52}}
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/logs/debug-internal.log b/rl-starter-files/wandb/run-20230726_160749-frqb40bx/logs/debug-internal.log
deleted file mode 100644
index 9938aae..0000000
--- a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/logs/debug-internal.log
+++ /dev/null
@@ -1,419 +0,0 @@
-2023-07-26 16:07:49,599 INFO    StreamThr :75987 [internal.py:wandb_internal():86] W&B internal server running at pid: 75987, started at: 2023-07-26 16:07:49.599589
-2023-07-26 16:07:49,600 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: status
-2023-07-26 16:07:49,603 INFO    WriterThread:75987 [datastore.py:open_for_write():85] open: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/run-frqb40bx.wandb
-2023-07-26 16:07:49,604 DEBUG   SenderThread:75987 [sender.py:send():369] send: header
-2023-07-26 16:07:49,623 DEBUG   SenderThread:75987 [sender.py:send():369] send: run
-2023-07-26 16:07:50,277 INFO    SenderThread:75987 [dir_watcher.py:__init__():211] watching files in: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files
-2023-07-26 16:07:50,277 INFO    SenderThread:75987 [sender.py:_start_run_threads():1100] run started: frqb40bx with start time 1690384069.599131
-2023-07-26 16:07:50,279 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:07:50,279 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:07:50,282 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: check_version
-2023-07-26 16:07:50,282 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: check_version
-2023-07-26 16:07:50,412 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: run_start
-2023-07-26 16:07:50,419 DEBUG   HandlerThread:75987 [system_info.py:__init__():31] System info init
-2023-07-26 16:07:50,419 DEBUG   HandlerThread:75987 [system_info.py:__init__():46] System info init done
-2023-07-26 16:07:50,419 INFO    HandlerThread:75987 [system_monitor.py:start():181] Starting system monitor
-2023-07-26 16:07:50,419 INFO    SystemMonitor:75987 [system_monitor.py:_start():145] Starting system asset monitoring threads
-2023-07-26 16:07:50,419 INFO    HandlerThread:75987 [system_monitor.py:probe():201] Collecting system info
-2023-07-26 16:07:50,420 INFO    SystemMonitor:75987 [interfaces.py:start():190] Started cpu monitoring
-2023-07-26 16:07:50,420 DEBUG   HandlerThread:75987 [system_info.py:probe():195] Probing system
-2023-07-26 16:07:50,420 INFO    SystemMonitor:75987 [interfaces.py:start():190] Started disk monitoring
-2023-07-26 16:07:50,421 INFO    SystemMonitor:75987 [interfaces.py:start():190] Started gpuapple monitoring
-2023-07-26 16:07:50,423 INFO    SystemMonitor:75987 [interfaces.py:start():190] Started memory monitoring
-2023-07-26 16:07:50,424 INFO    SystemMonitor:75987 [interfaces.py:start():190] Started network monitoring
-2023-07-26 16:07:50,427 DEBUG   HandlerThread:75987 [system_info.py:_probe_git():180] Probing git
-2023-07-26 16:07:50,444 DEBUG   HandlerThread:75987 [system_info.py:_probe_git():188] Probing git done
-2023-07-26 16:07:50,444 DEBUG   HandlerThread:75987 [system_info.py:probe():240] Probing system done
-2023-07-26 16:07:50,444 DEBUG   HandlerThread:75987 [system_monitor.py:probe():210] {'os': 'macOS-13.4-arm64-arm-64bit', 'python': '3.9.6', 'heartbeatAt': '2023-07-26T15:07:50.420864', 'startedAt': '2023-07-26T15:07:49.576314', 'docker': None, 'cuda': None, 'args': ('--algo', 'ppo', '--env', 'MiniGrid-Empty-5x5-v0', '--model', 'Empty', '--save-interval', '10', '--frames', '80000'), 'state': 'running', 'program': '-m scripts.train', 'git': {'remote': 'https://github.com/CorinaCaraconcea/diversity_study.git', 'commit': 'bbd28515d7e4bbc2bcc39a9deff9cc255775ca99'}, 'email': 'cori.caraconcea@gmail.com', 'root': '/Users/corinacaraconcea/Downloads/diversity_study', 'host': 'Corinas-MacBook-Air.local', 'username': 'corinacaraconcea', 'executable': '/Library/Developer/CommandLineTools/usr/bin/python3', 'cpu_count': 8, 'cpu_count_logical': 8, 'disk': {'total': 228.27386474609375, 'used': 8.95040512084961}, 'gpuapple': {'type': 'arm', 'vendor': 'Apple'}, 'memory': {'total': 8.0}}
-2023-07-26 16:07:50,444 INFO    HandlerThread:75987 [system_monitor.py:probe():211] Finished collecting system info
-2023-07-26 16:07:50,444 INFO    HandlerThread:75987 [system_monitor.py:probe():214] Publishing system info
-2023-07-26 16:07:50,445 DEBUG   HandlerThread:75987 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment
-2023-07-26 16:07:50,445 DEBUG   HandlerThread:75987 [system_info.py:_save_pip():67] Saving pip packages done
-2023-07-26 16:07:50,445 DEBUG   HandlerThread:75987 [system_info.py:_save_code():89] Saving code
-2023-07-26 16:07:50,445 WARNING HandlerThread:75987 [system_info.py:_save_code():91] unable to save code -- program entry not found
-2023-07-26 16:07:50,445 DEBUG   HandlerThread:75987 [system_info.py:_save_patches():127] Saving git patches
-2023-07-26 16:07:50,480 DEBUG   HandlerThread:75987 [system_info.py:_save_patches():169] Saving git patches done
-2023-07-26 16:07:50,480 INFO    HandlerThread:75987 [system_monitor.py:probe():216] Finished publishing system info
-2023-07-26 16:07:50,482 DEBUG   SenderThread:75987 [sender.py:send():369] send: files
-2023-07-26 16:07:50,482 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-metadata.json with policy now
-2023-07-26 16:07:50,486 DEBUG   SenderThread:75987 [sender.py:send():369] send: telemetry
-2023-07-26 16:07:50,487 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:07:50,487 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:07:51,095 INFO    wandb-upload_0:75987 [upload_job.py:push():133] Uploaded file /var/folders/n4/lk2x7f1j3g35spnvp796gmx40000gn/T/tmpesrgk4e8wandb/my3ugwbe-wandb-metadata.json
-2023-07-26 16:07:51,283 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-metadata.json
-2023-07-26 16:07:51,283 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/requirements.txt
-2023-07-26 16:07:51,283 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:07:51,283 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:07:51,869 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:07:51,870 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:07:51,870 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:07:51,870 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:07:52,287 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:07:53,172 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:07:53,173 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:07:53,173 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:07:53,173 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:07:53,293 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:07:53,293 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:07:54,481 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:07:54,482 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:07:54,482 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:07:54,483 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:07:54,695 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:07:55,303 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:07:55,304 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:07:55,765 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:07:55,767 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:07:55,767 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:07:55,767 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:07:56,309 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:07:57,123 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:07:57,124 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:07:57,124 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:07:57,125 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:07:57,310 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:07:57,310 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:07:58,387 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:07:58,389 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:07:58,389 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:07:58,389 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:07:59,320 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:07:59,321 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:07:59,693 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:07:59,693 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:07:59,693 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:07:59,694 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:07:59,910 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:08:00,326 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:00,974 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:00,975 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:00,975 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:00,976 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:01,331 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:01,331 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:02,336 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:02,337 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:02,337 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:02,337 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:02,337 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:03,343 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:03,343 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:03,634 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:03,635 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:03,635 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:03,636 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:04,348 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:04,926 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:04,927 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:04,927 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:04,927 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:08:04,928 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:05,353 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:05,354 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:05,492 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:08:05,492 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:08:06,234 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:06,236 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:06,236 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:06,237 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:06,359 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:07,360 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:07,584 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:07,584 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:07,584 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:07,585 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:08,366 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:08,900 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:08,901 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:08,901 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:08,901 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:09,371 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:09,371 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:10,136 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:08:10,185 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:10,186 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:10,186 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:10,187 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:10,375 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:11,377 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:11,480 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:11,481 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:11,481 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:11,481 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:12,382 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:12,738 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:12,739 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:12,739 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:12,740 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:13,388 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:13,388 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:14,030 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:14,031 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:14,031 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:14,032 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:14,393 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:15,257 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:08:15,354 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:15,355 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:15,355 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:15,356 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:15,395 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:15,395 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:16,630 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:16,631 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:16,631 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:16,631 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:17,406 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:17,406 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:17,936 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:17,937 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:17,937 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:17,937 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:18,410 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:19,239 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:19,240 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:19,240 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:19,240 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:19,413 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:19,414 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:20,482 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:08:20,497 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:08:20,549 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:20,699 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:08:20,948 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:20,949 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:20,950 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:21,425 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/config.yaml
-2023-07-26 16:08:21,425 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:21,425 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:21,852 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:21,853 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:21,853 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:21,854 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:22,430 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:23,153 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:23,154 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:23,154 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:23,155 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:23,435 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:23,435 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:24,466 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:24,468 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:24,468 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:24,469 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:25,444 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:25,444 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:25,758 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:25,759 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:25,759 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:25,759 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:08:25,759 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:26,449 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:27,078 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:27,079 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:27,079 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:27,079 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:27,455 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:27,455 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:28,369 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:28,369 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:28,370 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:28,370 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:28,458 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:29,463 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:29,700 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:29,703 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:29,703 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:29,704 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:30,479 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:30,972 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:08:31,237 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:31,238 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:31,238 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:31,239 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:31,480 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:31,480 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:32,507 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:32,508 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:32,508 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:32,509 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:33,489 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:33,489 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:33,792 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:33,793 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:33,793 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:33,793 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:34,494 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:35,086 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:35,086 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:35,086 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:35,087 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:35,499 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:35,499 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:35,500 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:08:35,500 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:08:36,360 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:36,361 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:36,361 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:36,361 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:08:36,361 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:36,500 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:37,506 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:37,650 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:37,650 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:37,650 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:37,651 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:38,510 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:38,883 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:38,883 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:38,884 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:38,884 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:39,515 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:39,515 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:40,197 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:40,198 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:40,198 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:40,198 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:40,517 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:41,447 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:08:41,457 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:41,457 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:41,457 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:41,458 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:41,521 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:41,521 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:42,787 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:08:42,788 DEBUG   SenderThread:75987 [sender.py:send():369] send: history
-2023-07-26 16:08:42,788 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:08:42,789 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:42,791 DEBUG   SenderThread:75987 [sender.py:send():369] send: exit
-2023-07-26 16:08:42,791 INFO    SenderThread:75987 [sender.py:send_exit():574] handling exit code: 0
-2023-07-26 16:08:42,791 INFO    SenderThread:75987 [sender.py:send_exit():576] handling runtime: 52
-2023-07-26 16:08:42,791 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:42,792 INFO    SenderThread:75987 [sender.py:send_exit():582] send defer
-2023-07-26 16:08:42,792 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:42,792 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 0
-2023-07-26 16:08:42,792 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:42,792 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 0
-2023-07-26 16:08:42,792 INFO    SenderThread:75987 [sender.py:transition_state():602] send defer: 1
-2023-07-26 16:08:42,792 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:42,792 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 1
-2023-07-26 16:08:42,792 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:42,792 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 1
-2023-07-26 16:08:42,792 INFO    SenderThread:75987 [sender.py:transition_state():602] send defer: 2
-2023-07-26 16:08:42,792 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:42,792 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 2
-2023-07-26 16:08:42,792 INFO    HandlerThread:75987 [system_monitor.py:finish():190] Stopping system monitor
-2023-07-26 16:08:42,792 INFO    HandlerThread:75987 [interfaces.py:finish():202] Joined cpu monitor
-2023-07-26 16:08:42,792 DEBUG   SystemMonitor:75987 [system_monitor.py:_start():159] Starting system metrics aggregation loop
-2023-07-26 16:08:42,792 INFO    HandlerThread:75987 [interfaces.py:finish():202] Joined disk monitor
-2023-07-26 16:08:42,792 DEBUG   SystemMonitor:75987 [system_monitor.py:_start():166] Finished system metrics aggregation loop
-2023-07-26 16:08:42,792 INFO    HandlerThread:75987 [interfaces.py:finish():202] Joined gpuapple monitor
-2023-07-26 16:08:42,792 DEBUG   SystemMonitor:75987 [system_monitor.py:_start():170] Publishing last batch of metrics
-2023-07-26 16:08:42,793 INFO    HandlerThread:75987 [interfaces.py:finish():202] Joined memory monitor
-2023-07-26 16:08:42,793 INFO    HandlerThread:75987 [interfaces.py:finish():202] Joined network monitor
-2023-07-26 16:08:42,793 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:42,793 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 2
-2023-07-26 16:08:42,794 INFO    SenderThread:75987 [sender.py:transition_state():602] send defer: 3
-2023-07-26 16:08:42,794 DEBUG   SenderThread:75987 [sender.py:send():369] send: telemetry
-2023-07-26 16:08:42,794 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:42,794 DEBUG   SenderThread:75987 [sender.py:send():369] send: stats
-2023-07-26 16:08:42,794 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 3
-2023-07-26 16:08:42,794 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:42,794 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 3
-2023-07-26 16:08:42,794 INFO    SenderThread:75987 [sender.py:transition_state():602] send defer: 4
-2023-07-26 16:08:42,794 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:42,794 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 4
-2023-07-26 16:08:42,794 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:42,794 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 4
-2023-07-26 16:08:42,794 INFO    SenderThread:75987 [sender.py:transition_state():602] send defer: 5
-2023-07-26 16:08:42,794 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:42,794 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 5
-2023-07-26 16:08:42,794 DEBUG   SenderThread:75987 [sender.py:send():369] send: summary
-2023-07-26 16:08:42,794 INFO    SenderThread:75987 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:08:42,794 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:42,795 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 5
-2023-07-26 16:08:42,795 INFO    SenderThread:75987 [sender.py:transition_state():602] send defer: 6
-2023-07-26 16:08:42,795 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:42,795 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 6
-2023-07-26 16:08:42,795 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:42,795 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 6
-2023-07-26 16:08:42,797 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:08:43,031 INFO    SenderThread:75987 [sender.py:transition_state():602] send defer: 7
-2023-07-26 16:08:43,032 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:43,032 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 7
-2023-07-26 16:08:43,033 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:43,033 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 7
-2023-07-26 16:08:43,563 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/config.yaml
-2023-07-26 16:08:43,563 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:43,564 INFO    Thread-12 :75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:43,797 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: poll_exit
-2023-07-26 16:08:44,957 INFO    SenderThread:75987 [sender.py:transition_state():602] send defer: 8
-2023-07-26 16:08:44,958 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: poll_exit
-2023-07-26 16:08:44,958 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:44,960 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 8
-2023-07-26 16:08:44,961 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:44,961 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 8
-2023-07-26 16:08:44,962 INFO    SenderThread:75987 [job_builder.py:build():240] Attempting to build job artifact
-2023-07-26 16:08:44,963 INFO    SenderThread:75987 [job_builder.py:build():274] no source found
-2023-07-26 16:08:44,963 INFO    SenderThread:75987 [sender.py:transition_state():602] send defer: 9
-2023-07-26 16:08:44,963 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:44,963 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 9
-2023-07-26 16:08:44,963 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:44,964 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 9
-2023-07-26 16:08:44,964 INFO    SenderThread:75987 [dir_watcher.py:finish():359] shutting down directory watcher
-2023-07-26 16:08:45,576 INFO    SenderThread:75987 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:45,577 INFO    SenderThread:75987 [dir_watcher.py:finish():389] scan: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files
-2023-07-26 16:08:45,577 INFO    SenderThread:75987 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/requirements.txt requirements.txt
-2023-07-26 16:08:45,577 INFO    SenderThread:75987 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log output.log
-2023-07-26 16:08:45,582 INFO    SenderThread:75987 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/config.yaml config.yaml
-2023-07-26 16:08:45,582 INFO    SenderThread:75987 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json wandb-summary.json
-2023-07-26 16:08:45,586 INFO    SenderThread:75987 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-metadata.json wandb-metadata.json
-2023-07-26 16:08:45,587 INFO    SenderThread:75987 [sender.py:transition_state():602] send defer: 10
-2023-07-26 16:08:45,591 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:45,594 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 10
-2023-07-26 16:08:45,595 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:45,596 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 10
-2023-07-26 16:08:45,596 INFO    SenderThread:75987 [file_pusher.py:finish():159] shutting down file pusher
-2023-07-26 16:08:46,000 INFO    wandb-upload_0:75987 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/requirements.txt
-2023-07-26 16:08:46,124 INFO    wandb-upload_1:75987 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/output.log
-2023-07-26 16:08:46,147 INFO    wandb-upload_3:75987 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/wandb-summary.json
-2023-07-26 16:08:46,147 INFO    wandb-upload_2:75987 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/files/config.yaml
-2023-07-26 16:08:46,348 INFO    Thread-11 :75987 [sender.py:transition_state():602] send defer: 11
-2023-07-26 16:08:46,349 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:46,350 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 11
-2023-07-26 16:08:46,351 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:46,351 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 11
-2023-07-26 16:08:46,351 INFO    SenderThread:75987 [file_pusher.py:join():164] waiting for file pusher
-2023-07-26 16:08:46,351 INFO    SenderThread:75987 [sender.py:transition_state():602] send defer: 12
-2023-07-26 16:08:46,351 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:46,351 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 12
-2023-07-26 16:08:46,352 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:46,352 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 12
-2023-07-26 16:08:46,552 INFO    SenderThread:75987 [sender.py:transition_state():602] send defer: 13
-2023-07-26 16:08:46,553 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:46,553 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 13
-2023-07-26 16:08:46,554 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:46,554 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 13
-2023-07-26 16:08:46,554 INFO    SenderThread:75987 [sender.py:transition_state():602] send defer: 14
-2023-07-26 16:08:46,554 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:08:46,554 INFO    HandlerThread:75987 [handler.py:handle_request_defer():170] handle defer: 14
-2023-07-26 16:08:46,555 DEBUG   SenderThread:75987 [sender.py:send():369] send: final
-2023-07-26 16:08:46,555 DEBUG   SenderThread:75987 [sender.py:send():369] send: footer
-2023-07-26 16:08:46,555 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:08:46,555 INFO    SenderThread:75987 [sender.py:send_request_defer():598] handle sender defer: 14
-2023-07-26 16:08:46,556 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: poll_exit
-2023-07-26 16:08:46,557 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: poll_exit
-2023-07-26 16:08:46,558 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: server_info
-2023-07-26 16:08:46,558 DEBUG   SenderThread:75987 [sender.py:send_request():396] send_request: server_info
-2023-07-26 16:08:46,562 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: get_summary
-2023-07-26 16:08:46,563 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: sampled_history
-2023-07-26 16:08:46,851 INFO    MainThread:75987 [wandb_run.py:_footer_history_summary_info():3464] rendering history
-2023-07-26 16:08:46,852 INFO    MainThread:75987 [wandb_run.py:_footer_history_summary_info():3496] rendering summary
-2023-07-26 16:08:46,852 INFO    MainThread:75987 [wandb_run.py:_footer_sync_info():3423] logging synced files
-2023-07-26 16:08:46,853 DEBUG   HandlerThread:75987 [handler.py:handle_request():144] handle_request: shutdown
-2023-07-26 16:08:46,854 INFO    HandlerThread:75987 [handler.py:finish():854] shutting down handler
-2023-07-26 16:08:47,564 INFO    WriterThread:75987 [datastore.py:close():298] close: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/run-frqb40bx.wandb
-2023-07-26 16:08:47,856 INFO    SenderThread:75987 [sender.py:finish():1526] shutting down sender
-2023-07-26 16:08:47,856 INFO    SenderThread:75987 [file_pusher.py:finish():159] shutting down file pusher
-2023-07-26 16:08:47,857 INFO    SenderThread:75987 [file_pusher.py:join():164] waiting for file pusher
diff --git a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/logs/debug.log b/rl-starter-files/wandb/run-20230726_160749-frqb40bx/logs/debug.log
deleted file mode 100644
index 521d15e..0000000
--- a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/logs/debug.log
+++ /dev/null
@@ -1,29 +0,0 @@
-2023-07-26 16:07:49,580 INFO    MainThread:75959 [wandb_setup.py:_flush():76] Current SDK version is 0.15.5
-2023-07-26 16:07:49,580 INFO    MainThread:75959 [wandb_setup.py:_flush():76] Configure stats pid to 75959
-2023-07-26 16:07:49,580 INFO    MainThread:75959 [wandb_setup.py:_flush():76] Loading settings from /Users/corinacaraconcea/.config/wandb/settings
-2023-07-26 16:07:49,580 INFO    MainThread:75959 [wandb_setup.py:_flush():76] Loading settings from /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/settings
-2023-07-26 16:07:49,580 INFO    MainThread:75959 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
-2023-07-26 16:07:49,580 INFO    MainThread:75959 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
-2023-07-26 16:07:49,580 WARNING MainThread:75959 [wandb_setup.py:_flush():76] Could not find program at -m scripts.train
-2023-07-26 16:07:49,580 INFO    MainThread:75959 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': None, 'program': '-m scripts.train'}
-2023-07-26 16:07:49,580 INFO    MainThread:75959 [wandb_init.py:_log_setup():507] Logging user logs to /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/logs/debug.log
-2023-07-26 16:07:49,581 INFO    MainThread:75959 [wandb_init.py:_log_setup():508] Logging internal logs to /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_160749-frqb40bx/logs/debug-internal.log
-2023-07-26 16:07:49,581 INFO    MainThread:75959 [wandb_init.py:init():547] calling init triggers
-2023-07-26 16:07:49,581 INFO    MainThread:75959 [wandb_init.py:init():554] wandb.init called with sweep_config: {}
-config: {'model': '', 'performance metric': 'extrinsic reward'}
-2023-07-26 16:07:49,581 INFO    MainThread:75959 [wandb_init.py:init():596] starting backend
-2023-07-26 16:07:49,581 INFO    MainThread:75959 [wandb_init.py:init():600] setting up manager
-2023-07-26 16:07:49,594 INFO    MainThread:75959 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
-2023-07-26 16:07:49,598 INFO    MainThread:75959 [wandb_init.py:init():606] backend started and connected
-2023-07-26 16:07:49,603 INFO    MainThread:75959 [wandb_init.py:init():705] updated telemetry
-2023-07-26 16:07:49,620 INFO    MainThread:75959 [wandb_init.py:init():738] communicating run to backend with 60.0 second timeout
-2023-07-26 16:07:50,281 INFO    MainThread:75959 [wandb_run.py:_on_init():2173] communicating current version
-2023-07-26 16:07:50,399 INFO    MainThread:75959 [wandb_run.py:_on_init():2182] got version response upgrade_message: "wandb version 0.15.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
-
-2023-07-26 16:07:50,399 INFO    MainThread:75959 [wandb_init.py:init():789] starting run threads in backend
-2023-07-26 16:07:50,485 INFO    MainThread:75959 [wandb_run.py:_console_start():2152] atexit reg
-2023-07-26 16:07:50,485 INFO    MainThread:75959 [wandb_run.py:_redirect():2007] redirect: SettingsConsole.WRAP_RAW
-2023-07-26 16:07:50,486 INFO    MainThread:75959 [wandb_run.py:_redirect():2072] Wrapping output streams.
-2023-07-26 16:07:50,486 INFO    MainThread:75959 [wandb_run.py:_redirect():2097] Redirects installed.
-2023-07-26 16:07:50,486 INFO    MainThread:75959 [wandb_init.py:init():830] run started, returning control to user process
-2023-07-26 16:08:47,976 WARNING MsgRouterThr:75959 [router.py:message_loop():77] message_loop has been closed
diff --git a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/run-frqb40bx.wandb b/rl-starter-files/wandb/run-20230726_160749-frqb40bx/run-frqb40bx.wandb
deleted file mode 100644
index 49dd48a..0000000
Binary files a/rl-starter-files/wandb/run-20230726_160749-frqb40bx/run-frqb40bx.wandb and /dev/null differ
diff --git a/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/config.yaml b/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/config.yaml
deleted file mode 100644
index 1804008..0000000
--- a/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/config.yaml
+++ /dev/null
@@ -1,32 +0,0 @@
-wandb_version: 1
-
-model:
-  desc: null
-  value: ''
-performance metric:
-  desc: null
-  value: extrinsic reward
-_wandb:
-  desc: null
-  value:
-    python_version: 3.9.6
-    cli_version: 0.15.5
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    start_time: 1690385736.349594
-    t:
-      1:
-      - 1
-      - 55
-      2:
-      - 1
-      - 55
-      3:
-      - 16
-      - 23
-      4: 3.9.6
-      5: 0.15.5
-      8:
-      - 4
-      - 5
diff --git a/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/diff.patch b/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/diff.patch
deleted file mode 100644
index ee2a160..0000000
--- a/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/diff.patch
+++ /dev/null
@@ -1,24 +0,0 @@
-diff --git a/rl-starter-files/scripts/train.py b/rl-starter-files/scripts/train.py
-index 6b1b0c6..5a1de02 100644
---- a/rl-starter-files/scripts/train.py
-+++ b/rl-starter-files/scripts/train.py
-@@ -19,6 +19,10 @@ sys.path.insert(0, os.path.abspath('/Users/corinacaraconcea/Documents/UCL DSML/M
- import a2c
- import ppo
- 
-+from Minigrid.minigrid.__init__ import register_minigrid_envs
-+
-+register_minigrid_envs()
-+
- # Parse arguments
- 
- #The argparse module is a standard Python library for writing user-friendly command-line interfaces.
-diff --git a/rl-starter-files/utils/env.py b/rl-starter-files/utils/env.py
-index fa4f36d..24b9b4b 100644
---- a/rl-starter-files/utils/env.py
-+++ b/rl-starter-files/utils/env.py
-@@ -5,3 +5,4 @@ def make_env(env_key, seed=None, render_mode=None):
-     env = gym.make(env_key, render_mode=render_mode)
-     env.reset(seed=seed)
-     return env
-+
diff --git a/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log b/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
deleted file mode 100644
index 5ca3ac7..0000000
--- a/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
+++ /dev/null
@@ -1,80 +0,0 @@
-log_done_counter 0
-U 1 | F 0000002048 | FPS 1462 | D 1 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 0.0 0.0 0 0 | H 1.941 | V 0.066 | pL 0.011 | vL 0.000 | ∇ 0.012
-log_done_counter 16
-U 2 | F 0000004096 | FPS 1566 | D 2 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.938 | V 0.063 | pL 0.015 | vL 0.000 | ∇ 0.005
-log_done_counter 16
-U 3 | F 0000006144 | FPS 1540 | D 4 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.935 | V 0.046 | pL 0.013 | vL 0.000 | ∇ 0.004
-log_done_counter 16
-U 4 | F 0000008192 | FPS 1646 | D 5 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.937 | V 0.037 | pL 0.011 | vL 0.000 | ∇ 0.004
-log_done_counter 16
-U 5 | F 0000010240 | FPS 1437 | D 6 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.938 | V 0.027 | pL 0.009 | vL 0.000 | ∇ 0.003
-log_done_counter 16
-U 6 | F 0000012288 | FPS 1374 | D 8 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.942 | V 0.021 | pL 0.007 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 7 | F 0000014336 | FPS 1627 | D 9 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.943 | V 0.015 | pL 0.005 | vL 0.000 | ∇ 0.002
-log_done_counter 16
-U 8 | F 0000016384 | FPS 1639 | D 10 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.942 | V 0.012 | pL 0.004 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 9 | F 0000018432 | FPS 1625 | D 12 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.940 | V 0.010 | pL 0.004 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 10 | F 0000020480 | FPS 1624 | D 13 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.941 | V 0.008 | pL 0.003 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 11 | F 0000022528 | FPS 1585 | D 14 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.942 | V 0.005 | pL 0.002 | vL 0.000 | ∇ 0.000
-log_done_counter 0
-U 12 | F 0000024576 | FPS 1579 | D 15 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.942 | V 0.004 | pL 0.001 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 13 | F 0000026624 | FPS 1651 | D 17 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.943 | V 0.004 | pL 0.001 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 14 | F 0000028672 | FPS 1621 | D 18 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.943 | V 0.003 | pL 0.001 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 15 | F 0000030720 | FPS 1558 | D 19 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.943 | V 0.002 | pL 0.001 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 16 | F 0000032768 | FPS 1620 | D 20 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.943 | V 0.002 | pL 0.001 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 17 | F 0000034816 | FPS 1615 | D 22 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.944 | V 0.001 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 18 | F 0000036864 | FPS 1576 | D 23 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 19 | F 0000038912 | FPS 1564 | D 24 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 20 | F 0000040960 | FPS 1594 | D 26 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 21 | F 0000043008 | FPS 1501 | D 27 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 22 | F 0000045056 | FPS 1509 | D 28 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 23 | F 0000047104 | FPS 1596 | D 30 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 0
-U 24 | F 0000049152 | FPS 1624 | D 31 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 25 | F 0000051200 | FPS 1641 | D 32 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 26 | F 0000053248 | FPS 1496 | D 34 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 27 | F 0000055296 | FPS 1678 | D 35 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 28 | F 0000057344 | FPS 1587 | D 36 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 29 | F 0000059392 | FPS 1672 | D 37 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 30 | F 0000061440 | FPS 1648 | D 39 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 31 | F 0000063488 | FPS 1649 | D 40 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 32 | F 0000065536 | FPS 1433 | D 41 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 33 | F 0000067584 | FPS 1601 | D 42 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 34 | F 0000069632 | FPS 1566 | D 44 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 35 | F 0000071680 | FPS 1575 | D 45 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 0
-U 36 | F 0000073728 | FPS 1651 | D 46 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 37 | F 0000075776 | FPS 1625 | D 48 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 38 | F 0000077824 | FPS 1619 | D 49 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 39 | F 0000079872 | FPS 1424 | D 50 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 40 | F 0000081920 | FPS 1542 | D 52 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/requirements.txt b/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/requirements.txt
deleted file mode 100644
index 05458c5..0000000
--- a/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/requirements.txt
+++ /dev/null
@@ -1,85 +0,0 @@
-altgraph==0.17.2
-appdirs==1.4.4
-appnope==0.1.3
-asttokens==2.2.1
-backcall==0.2.0
-certifi==2023.5.7
-charset-normalizer==3.2.0
-click==8.1.4
-cloudpickle==2.2.1
-comm==0.1.2
-contourpy==1.1.0
-cycler==0.11.0
-debugpy==1.6.5
-decorator==5.1.1
-docker-pycreds==0.4.0
-entrypoints==0.4
-executing==1.2.0
-farama-notifications==0.0.4
-filelock==3.12.2
-fonttools==4.40.0
-future==0.18.2
-gitdb==4.0.10
-gitpython==3.1.31
-gym-minigrid==1.2.2
-gym-notices==0.0.8
-gym==0.26.2
-gymnasium==0.28.1
-idna==3.4
-importlib-metadata==6.6.0
-importlib-resources==6.0.0
-ipykernel==6.20.2
-ipython==8.8.0
-jax-jumpy==1.0.0
-jedi==0.18.2
-jinja2==3.1.2
-jupyter-client==7.4.9
-jupyter-core==5.1.3
-kiwisolver==1.4.4
-macholib==1.15.2
-markupsafe==2.1.3
-matplotlib-inline==0.1.6
-matplotlib==3.7.2
-minigrid==2.3.0
-mpmath==1.3.0
-nest-asyncio==1.5.6
-networkx==3.1
-numpy==1.24.3
-packaging==23.0
-parso==0.8.3
-pathtools==0.1.2
-pexpect==4.8.0
-pickleshare==0.7.5
-pillow==10.0.0
-pip==21.2.4
-platformdirs==2.6.2
-prompt-toolkit==3.0.36
-protobuf==3.20.3
-psutil==5.9.4
-ptyprocess==0.7.0
-pure-eval==0.2.2
-pygame==2.4.0
-pygments==2.14.0
-pyparsing==3.0.9
-python-dateutil==2.8.2
-pyyaml==6.0
-pyzmq==25.0.0
-requests==2.31.0
-sentry-sdk==1.28.0
-setproctitle==1.3.2
-setuptools==58.0.4
-six==1.15.0
-smmap==5.0.0
-stack-data==0.6.2
-sympy==1.12
-tensorboardx==2.6
-torch-ac==1.4.0
-torch==2.0.1
-tornado==6.2
-traitlets==5.8.1
-typing-extensions==4.6.3
-urllib3==2.0.3
-wandb==0.15.5
-wcwidth==0.2.6
-wheel==0.37.0
-zipp==3.15.0
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-metadata.json b/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-metadata.json
deleted file mode 100644
index e814498..0000000
--- a/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-metadata.json
+++ /dev/null
@@ -1,42 +0,0 @@
-{
-    "os": "macOS-13.4-arm64-arm-64bit",
-    "python": "3.9.6",
-    "heartbeatAt": "2023-07-26T15:35:37.930861",
-    "startedAt": "2023-07-26T15:35:36.328689",
-    "docker": null,
-    "cuda": null,
-    "args": [
-        "--algo",
-        "ppo",
-        "--env",
-        "MiniGrid-MultiRoom-N7-S4-v0",
-        "--save-interval",
-        "10",
-        "--frames",
-        "80000"
-    ],
-    "state": "running",
-    "program": "-m scripts.train",
-    "git": {
-        "remote": "https://github.com/CorinaCaraconcea/diversity_study.git",
-        "commit": "bbd28515d7e4bbc2bcc39a9deff9cc255775ca99"
-    },
-    "email": "cori.caraconcea@gmail.com",
-    "root": "/Users/corinacaraconcea/Downloads/diversity_study",
-    "host": "Corinas-MacBook-Air.local",
-    "username": "corinacaraconcea",
-    "executable": "/Library/Developer/CommandLineTools/usr/bin/python3",
-    "cpu_count": 8,
-    "cpu_count_logical": 8,
-    "disk": {
-        "total": 228.27386474609375,
-        "used": 8.95040512084961
-    },
-    "gpuapple": {
-        "type": "arm",
-        "vendor": "Apple"
-    },
-    "memory": {
-        "total": 8.0
-    }
-}
diff --git a/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json b/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
deleted file mode 100644
index 622f7e1..0000000
--- a/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
+++ /dev/null
@@ -1 +0,0 @@
-{"external_return_per_episode": 0.0, "_timestamp": 1690385790.170806, "_runtime": 53.82121181488037, "_step": 39, "_wandb": {"runtime": 52}}
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_163536-y109zesf/logs/debug-internal.log b/rl-starter-files/wandb/run-20230726_163536-y109zesf/logs/debug-internal.log
deleted file mode 100644
index f543360..0000000
--- a/rl-starter-files/wandb/run-20230726_163536-y109zesf/logs/debug-internal.log
+++ /dev/null
@@ -1,422 +0,0 @@
-2023-07-26 16:35:36,350 INFO    StreamThr :78696 [internal.py:wandb_internal():86] W&B internal server running at pid: 78696, started at: 2023-07-26 16:35:36.350295
-2023-07-26 16:35:36,351 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: status
-2023-07-26 16:35:36,354 INFO    WriterThread:78696 [datastore.py:open_for_write():85] open: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/run-y109zesf.wandb
-2023-07-26 16:35:36,354 DEBUG   SenderThread:78696 [sender.py:send():369] send: header
-2023-07-26 16:35:36,371 DEBUG   SenderThread:78696 [sender.py:send():369] send: run
-2023-07-26 16:35:37,771 INFO    SenderThread:78696 [dir_watcher.py:__init__():211] watching files in: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files
-2023-07-26 16:35:37,771 INFO    SenderThread:78696 [sender.py:_start_run_threads():1100] run started: y109zesf with start time 1690385736.349594
-2023-07-26 16:35:37,775 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:37,776 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:37,780 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: check_version
-2023-07-26 16:35:37,781 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: check_version
-2023-07-26 16:35:37,919 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: run_start
-2023-07-26 16:35:37,929 DEBUG   HandlerThread:78696 [system_info.py:__init__():31] System info init
-2023-07-26 16:35:37,929 DEBUG   HandlerThread:78696 [system_info.py:__init__():46] System info init done
-2023-07-26 16:35:37,929 INFO    HandlerThread:78696 [system_monitor.py:start():181] Starting system monitor
-2023-07-26 16:35:37,929 INFO    SystemMonitor:78696 [system_monitor.py:_start():145] Starting system asset monitoring threads
-2023-07-26 16:35:37,930 INFO    HandlerThread:78696 [system_monitor.py:probe():201] Collecting system info
-2023-07-26 16:35:37,930 INFO    SystemMonitor:78696 [interfaces.py:start():190] Started cpu monitoring
-2023-07-26 16:35:37,930 DEBUG   HandlerThread:78696 [system_info.py:probe():195] Probing system
-2023-07-26 16:35:37,930 INFO    SystemMonitor:78696 [interfaces.py:start():190] Started disk monitoring
-2023-07-26 16:35:37,933 INFO    SystemMonitor:78696 [interfaces.py:start():190] Started gpuapple monitoring
-2023-07-26 16:35:37,934 INFO    SystemMonitor:78696 [interfaces.py:start():190] Started memory monitoring
-2023-07-26 16:35:37,935 INFO    SystemMonitor:78696 [interfaces.py:start():190] Started network monitoring
-2023-07-26 16:35:37,938 DEBUG   HandlerThread:78696 [system_info.py:_probe_git():180] Probing git
-2023-07-26 16:35:37,957 DEBUG   HandlerThread:78696 [system_info.py:_probe_git():188] Probing git done
-2023-07-26 16:35:37,957 DEBUG   HandlerThread:78696 [system_info.py:probe():240] Probing system done
-2023-07-26 16:35:37,957 DEBUG   HandlerThread:78696 [system_monitor.py:probe():210] {'os': 'macOS-13.4-arm64-arm-64bit', 'python': '3.9.6', 'heartbeatAt': '2023-07-26T15:35:37.930861', 'startedAt': '2023-07-26T15:35:36.328689', 'docker': None, 'cuda': None, 'args': ('--algo', 'ppo', '--env', 'MiniGrid-MultiRoom-N7-S4-v0', '--save-interval', '10', '--frames', '80000'), 'state': 'running', 'program': '-m scripts.train', 'git': {'remote': 'https://github.com/CorinaCaraconcea/diversity_study.git', 'commit': 'bbd28515d7e4bbc2bcc39a9deff9cc255775ca99'}, 'email': 'cori.caraconcea@gmail.com', 'root': '/Users/corinacaraconcea/Downloads/diversity_study', 'host': 'Corinas-MacBook-Air.local', 'username': 'corinacaraconcea', 'executable': '/Library/Developer/CommandLineTools/usr/bin/python3', 'cpu_count': 8, 'cpu_count_logical': 8, 'disk': {'total': 228.27386474609375, 'used': 8.95040512084961}, 'gpuapple': {'type': 'arm', 'vendor': 'Apple'}, 'memory': {'total': 8.0}}
-2023-07-26 16:35:37,957 INFO    HandlerThread:78696 [system_monitor.py:probe():211] Finished collecting system info
-2023-07-26 16:35:37,957 INFO    HandlerThread:78696 [system_monitor.py:probe():214] Publishing system info
-2023-07-26 16:35:37,957 DEBUG   HandlerThread:78696 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment
-2023-07-26 16:35:37,957 DEBUG   HandlerThread:78696 [system_info.py:_save_pip():67] Saving pip packages done
-2023-07-26 16:35:37,957 DEBUG   HandlerThread:78696 [system_info.py:_save_code():89] Saving code
-2023-07-26 16:35:37,958 WARNING HandlerThread:78696 [system_info.py:_save_code():91] unable to save code -- program entry not found
-2023-07-26 16:35:37,958 DEBUG   HandlerThread:78696 [system_info.py:_save_patches():127] Saving git patches
-2023-07-26 16:35:38,006 DEBUG   HandlerThread:78696 [system_info.py:_save_patches():169] Saving git patches done
-2023-07-26 16:35:38,006 INFO    HandlerThread:78696 [system_monitor.py:probe():216] Finished publishing system info
-2023-07-26 16:35:38,008 DEBUG   SenderThread:78696 [sender.py:send():369] send: files
-2023-07-26 16:35:38,008 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-metadata.json with policy now
-2023-07-26 16:35:38,009 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file diff.patch with policy now
-2023-07-26 16:35:38,013 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:35:38,014 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:35:38,234 DEBUG   SenderThread:78696 [sender.py:send():369] send: telemetry
-2023-07-26 16:35:38,488 INFO    wandb-upload_0:78696 [upload_job.py:push():133] Uploaded file /var/folders/n4/lk2x7f1j3g35spnvp796gmx40000gn/T/tmpc_ddk67iwandb/impmpdmy-wandb-metadata.json
-2023-07-26 16:35:38,775 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/requirements.txt
-2023-07-26 16:35:38,775 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:38,775 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/diff.patch
-2023-07-26 16:35:38,775 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-metadata.json
-2023-07-26 16:35:38,775 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:35:38,988 INFO    wandb-upload_1:78696 [upload_job.py:push():133] Uploaded file /var/folders/n4/lk2x7f1j3g35spnvp796gmx40000gn/T/tmpc_ddk67iwandb/jsexfjie-diff.patch
-2023-07-26 16:35:39,414 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:39,415 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:39,415 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:39,416 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:39,779 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:40,726 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:40,727 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:40,727 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:40,727 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:40,781 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:40,781 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:35:41,970 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:35:42,059 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:42,059 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:42,059 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:42,060 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:42,789 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:42,789 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:35:43,307 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:43,308 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:43,308 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:43,309 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:43,795 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:44,741 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:44,743 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:44,743 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:44,744 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:44,797 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:44,798 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:35:46,237 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:46,238 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:46,239 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:46,239 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:46,808 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:46,808 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:35:47,500 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:47,501 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:47,501 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:47,501 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:35:47,501 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:47,813 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:48,753 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:48,754 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:48,754 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:48,755 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:48,819 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:48,819 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:35:50,016 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:50,017 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:50,017 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:50,017 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:50,829 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:50,830 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:35:51,280 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:51,281 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:51,281 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:51,282 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:51,835 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:52,510 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:35:52,576 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:52,576 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:52,576 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:52,577 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:52,840 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:52,840 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:35:53,017 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:35:53,018 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:35:53,876 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:53,876 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:53,876 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:53,877 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:54,850 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:54,851 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:35:55,119 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:55,120 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:55,120 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:55,120 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:55,856 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:56,386 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:56,387 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:56,387 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:56,387 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:56,862 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:56,862 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:35:57,607 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:35:57,703 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:57,704 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:57,704 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:57,704 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:57,866 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:35:58,869 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:35:58,970 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:35:58,971 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:35:58,971 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:35:58,971 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:35:59,874 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:00,241 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:00,241 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:00,242 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:00,242 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:00,875 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:00,875 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:01,543 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:01,544 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:01,544 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:01,545 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:01,881 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:02,764 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:36:02,855 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:02,856 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:02,856 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:02,857 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:02,886 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:02,886 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:04,145 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:04,147 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:04,147 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:04,147 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:04,895 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:04,895 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:05,514 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:05,515 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:05,516 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:05,517 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:05,900 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:06,875 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:06,876 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:06,876 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:06,876 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:06,901 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:06,902 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:08,022 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:36:08,025 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:36:08,161 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:08,207 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:36:08,395 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:08,395 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:08,395 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:08,910 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:08,910 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:08,911 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/config.yaml
-2023-07-26 16:36:09,426 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:09,427 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:09,427 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:09,427 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:09,915 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:10,677 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:10,678 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:10,678 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:10,678 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:10,921 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:10,921 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:12,049 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:12,050 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:12,050 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:12,051 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:12,925 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:12,925 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:13,273 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:13,273 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:36:13,273 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:13,274 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:13,274 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:13,928 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:14,567 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:14,569 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:14,569 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:14,569 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:14,931 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:14,932 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:15,795 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:15,796 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:15,796 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:15,796 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:15,936 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:16,941 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:17,041 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:17,042 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:17,042 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:17,042 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:17,947 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:18,286 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:18,287 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:18,287 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:18,287 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:36:18,287 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:18,952 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:18,953 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:19,719 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:19,720 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:19,720 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:19,720 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:19,954 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:20,959 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:21,004 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:21,005 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:21,006 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:21,006 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:21,965 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:22,318 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:22,319 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:22,319 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:22,320 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:22,967 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:22,967 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:23,027 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:36:23,028 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:36:23,327 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:36:23,621 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:23,622 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:23,622 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:23,623 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:23,972 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:24,866 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:24,866 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:24,867 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:24,867 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:24,977 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:24,978 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:26,129 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:26,129 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:26,129 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:26,130 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:26,989 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:26,989 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:27,397 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:27,398 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:27,398 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:27,398 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:27,991 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:28,836 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:36:28,839 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:28,839 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:28,840 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:28,840 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:28,996 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:29,001 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:30,171 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:36:30,172 DEBUG   SenderThread:78696 [sender.py:send():369] send: history
-2023-07-26 16:36:30,172 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:36:30,172 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:30,175 DEBUG   SenderThread:78696 [sender.py:send():369] send: exit
-2023-07-26 16:36:30,176 INFO    SenderThread:78696 [sender.py:send_exit():574] handling exit code: 0
-2023-07-26 16:36:30,176 INFO    SenderThread:78696 [sender.py:send_exit():576] handling runtime: 52
-2023-07-26 16:36:30,176 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:30,176 INFO    SenderThread:78696 [sender.py:send_exit():582] send defer
-2023-07-26 16:36:30,176 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:30,176 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 0
-2023-07-26 16:36:30,176 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:30,176 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 0
-2023-07-26 16:36:30,176 INFO    SenderThread:78696 [sender.py:transition_state():602] send defer: 1
-2023-07-26 16:36:30,176 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:30,176 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 1
-2023-07-26 16:36:30,177 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:30,177 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 1
-2023-07-26 16:36:30,177 INFO    SenderThread:78696 [sender.py:transition_state():602] send defer: 2
-2023-07-26 16:36:30,177 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:30,177 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 2
-2023-07-26 16:36:30,177 INFO    HandlerThread:78696 [system_monitor.py:finish():190] Stopping system monitor
-2023-07-26 16:36:30,177 DEBUG   SystemMonitor:78696 [system_monitor.py:_start():159] Starting system metrics aggregation loop
-2023-07-26 16:36:30,177 DEBUG   SystemMonitor:78696 [system_monitor.py:_start():166] Finished system metrics aggregation loop
-2023-07-26 16:36:30,177 INFO    HandlerThread:78696 [interfaces.py:finish():202] Joined cpu monitor
-2023-07-26 16:36:30,177 DEBUG   SystemMonitor:78696 [system_monitor.py:_start():170] Publishing last batch of metrics
-2023-07-26 16:36:30,177 INFO    HandlerThread:78696 [interfaces.py:finish():202] Joined disk monitor
-2023-07-26 16:36:30,178 INFO    HandlerThread:78696 [interfaces.py:finish():202] Joined gpuapple monitor
-2023-07-26 16:36:30,178 INFO    HandlerThread:78696 [interfaces.py:finish():202] Joined memory monitor
-2023-07-26 16:36:30,178 INFO    HandlerThread:78696 [interfaces.py:finish():202] Joined network monitor
-2023-07-26 16:36:30,178 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:30,178 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 2
-2023-07-26 16:36:30,178 INFO    SenderThread:78696 [sender.py:transition_state():602] send defer: 3
-2023-07-26 16:36:30,178 DEBUG   SenderThread:78696 [sender.py:send():369] send: telemetry
-2023-07-26 16:36:30,178 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:30,178 DEBUG   SenderThread:78696 [sender.py:send():369] send: stats
-2023-07-26 16:36:30,178 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 3
-2023-07-26 16:36:30,178 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:30,178 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 3
-2023-07-26 16:36:30,178 INFO    SenderThread:78696 [sender.py:transition_state():602] send defer: 4
-2023-07-26 16:36:30,178 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:30,178 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 4
-2023-07-26 16:36:30,178 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:30,178 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 4
-2023-07-26 16:36:30,179 INFO    SenderThread:78696 [sender.py:transition_state():602] send defer: 5
-2023-07-26 16:36:30,179 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:30,179 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 5
-2023-07-26 16:36:30,179 DEBUG   SenderThread:78696 [sender.py:send():369] send: summary
-2023-07-26 16:36:30,179 INFO    SenderThread:78696 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:36:30,179 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:30,179 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 5
-2023-07-26 16:36:30,179 INFO    SenderThread:78696 [sender.py:transition_state():602] send defer: 6
-2023-07-26 16:36:30,179 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:30,179 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 6
-2023-07-26 16:36:30,180 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:30,180 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 6
-2023-07-26 16:36:30,186 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:36:30,506 INFO    SenderThread:78696 [sender.py:transition_state():602] send defer: 7
-2023-07-26 16:36:30,506 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:30,506 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 7
-2023-07-26 16:36:30,507 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:30,507 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 7
-2023-07-26 16:36:31,008 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:31,009 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:31,009 INFO    Thread-12 :78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/config.yaml
-2023-07-26 16:36:31,182 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: poll_exit
-2023-07-26 16:36:32,446 INFO    SenderThread:78696 [sender.py:transition_state():602] send defer: 8
-2023-07-26 16:36:32,448 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: poll_exit
-2023-07-26 16:36:32,448 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:32,449 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 8
-2023-07-26 16:36:32,450 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:32,450 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 8
-2023-07-26 16:36:32,450 INFO    SenderThread:78696 [job_builder.py:build():240] Attempting to build job artifact
-2023-07-26 16:36:32,451 INFO    SenderThread:78696 [job_builder.py:build():274] no source found
-2023-07-26 16:36:32,451 INFO    SenderThread:78696 [sender.py:transition_state():602] send defer: 9
-2023-07-26 16:36:32,452 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:32,452 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 9
-2023-07-26 16:36:32,452 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:32,452 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 9
-2023-07-26 16:36:32,452 INFO    SenderThread:78696 [dir_watcher.py:finish():359] shutting down directory watcher
-2023-07-26 16:36:33,017 INFO    SenderThread:78696 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:33,018 INFO    SenderThread:78696 [dir_watcher.py:finish():389] scan: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files
-2023-07-26 16:36:33,018 INFO    SenderThread:78696 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/diff.patch diff.patch
-2023-07-26 16:36:33,018 INFO    SenderThread:78696 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/requirements.txt requirements.txt
-2023-07-26 16:36:33,019 INFO    SenderThread:78696 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log output.log
-2023-07-26 16:36:33,019 INFO    SenderThread:78696 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/config.yaml config.yaml
-2023-07-26 16:36:33,019 INFO    SenderThread:78696 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json wandb-summary.json
-2023-07-26 16:36:33,029 INFO    SenderThread:78696 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-metadata.json wandb-metadata.json
-2023-07-26 16:36:33,029 INFO    SenderThread:78696 [sender.py:transition_state():602] send defer: 10
-2023-07-26 16:36:33,030 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:33,030 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 10
-2023-07-26 16:36:33,030 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:33,030 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 10
-2023-07-26 16:36:33,030 INFO    SenderThread:78696 [file_pusher.py:finish():159] shutting down file pusher
-2023-07-26 16:36:33,482 INFO    wandb-upload_0:78696 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/requirements.txt
-2023-07-26 16:36:33,561 INFO    wandb-upload_2:78696 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/config.yaml
-2023-07-26 16:36:33,573 INFO    wandb-upload_3:78696 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/wandb-summary.json
-2023-07-26 16:36:33,784 INFO    wandb-upload_1:78696 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/files/output.log
-2023-07-26 16:36:33,987 INFO    Thread-11 :78696 [sender.py:transition_state():602] send defer: 11
-2023-07-26 16:36:33,989 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:33,989 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 11
-2023-07-26 16:36:33,990 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:33,990 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 11
-2023-07-26 16:36:33,990 INFO    SenderThread:78696 [file_pusher.py:join():164] waiting for file pusher
-2023-07-26 16:36:33,990 INFO    SenderThread:78696 [sender.py:transition_state():602] send defer: 12
-2023-07-26 16:36:33,991 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:33,991 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 12
-2023-07-26 16:36:33,991 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:33,991 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 12
-2023-07-26 16:36:34,492 INFO    SenderThread:78696 [sender.py:transition_state():602] send defer: 13
-2023-07-26 16:36:34,493 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:34,493 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 13
-2023-07-26 16:36:34,494 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:34,494 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 13
-2023-07-26 16:36:34,494 INFO    SenderThread:78696 [sender.py:transition_state():602] send defer: 14
-2023-07-26 16:36:34,495 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:36:34,495 DEBUG   SenderThread:78696 [sender.py:send():369] send: final
-2023-07-26 16:36:34,495 INFO    HandlerThread:78696 [handler.py:handle_request_defer():170] handle defer: 14
-2023-07-26 16:36:34,495 DEBUG   SenderThread:78696 [sender.py:send():369] send: footer
-2023-07-26 16:36:34,495 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:36:34,495 INFO    SenderThread:78696 [sender.py:send_request_defer():598] handle sender defer: 14
-2023-07-26 16:36:34,496 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: poll_exit
-2023-07-26 16:36:34,496 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: poll_exit
-2023-07-26 16:36:34,497 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: server_info
-2023-07-26 16:36:34,497 DEBUG   SenderThread:78696 [sender.py:send_request():396] send_request: server_info
-2023-07-26 16:36:34,500 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: get_summary
-2023-07-26 16:36:34,501 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: sampled_history
-2023-07-26 16:36:34,776 INFO    MainThread:78696 [wandb_run.py:_footer_history_summary_info():3464] rendering history
-2023-07-26 16:36:34,778 INFO    MainThread:78696 [wandb_run.py:_footer_history_summary_info():3496] rendering summary
-2023-07-26 16:36:34,778 INFO    MainThread:78696 [wandb_run.py:_footer_sync_info():3423] logging synced files
-2023-07-26 16:36:34,780 DEBUG   HandlerThread:78696 [handler.py:handle_request():144] handle_request: shutdown
-2023-07-26 16:36:34,780 INFO    HandlerThread:78696 [handler.py:finish():854] shutting down handler
-2023-07-26 16:36:35,502 INFO    WriterThread:78696 [datastore.py:close():298] close: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/run-y109zesf.wandb
-2023-07-26 16:36:35,777 INFO    SenderThread:78696 [sender.py:finish():1526] shutting down sender
-2023-07-26 16:36:35,778 INFO    SenderThread:78696 [file_pusher.py:finish():159] shutting down file pusher
-2023-07-26 16:36:35,779 INFO    SenderThread:78696 [file_pusher.py:join():164] waiting for file pusher
diff --git a/rl-starter-files/wandb/run-20230726_163536-y109zesf/logs/debug.log b/rl-starter-files/wandb/run-20230726_163536-y109zesf/logs/debug.log
deleted file mode 100644
index c70739b..0000000
--- a/rl-starter-files/wandb/run-20230726_163536-y109zesf/logs/debug.log
+++ /dev/null
@@ -1,29 +0,0 @@
-2023-07-26 16:35:36,332 INFO    MainThread:78670 [wandb_setup.py:_flush():76] Current SDK version is 0.15.5
-2023-07-26 16:35:36,332 INFO    MainThread:78670 [wandb_setup.py:_flush():76] Configure stats pid to 78670
-2023-07-26 16:35:36,332 INFO    MainThread:78670 [wandb_setup.py:_flush():76] Loading settings from /Users/corinacaraconcea/.config/wandb/settings
-2023-07-26 16:35:36,332 INFO    MainThread:78670 [wandb_setup.py:_flush():76] Loading settings from /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/settings
-2023-07-26 16:35:36,332 INFO    MainThread:78670 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
-2023-07-26 16:35:36,332 INFO    MainThread:78670 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
-2023-07-26 16:35:36,332 WARNING MainThread:78670 [wandb_setup.py:_flush():76] Could not find program at -m scripts.train
-2023-07-26 16:35:36,332 INFO    MainThread:78670 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': None, 'program': '-m scripts.train'}
-2023-07-26 16:35:36,332 INFO    MainThread:78670 [wandb_init.py:_log_setup():507] Logging user logs to /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/logs/debug.log
-2023-07-26 16:35:36,332 INFO    MainThread:78670 [wandb_init.py:_log_setup():508] Logging internal logs to /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163536-y109zesf/logs/debug-internal.log
-2023-07-26 16:35:36,332 INFO    MainThread:78670 [wandb_init.py:init():547] calling init triggers
-2023-07-26 16:35:36,333 INFO    MainThread:78670 [wandb_init.py:init():554] wandb.init called with sweep_config: {}
-config: {'model': '', 'performance metric': 'extrinsic reward'}
-2023-07-26 16:35:36,333 INFO    MainThread:78670 [wandb_init.py:init():596] starting backend
-2023-07-26 16:35:36,333 INFO    MainThread:78670 [wandb_init.py:init():600] setting up manager
-2023-07-26 16:35:36,345 INFO    MainThread:78670 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
-2023-07-26 16:35:36,349 INFO    MainThread:78670 [wandb_init.py:init():606] backend started and connected
-2023-07-26 16:35:36,353 INFO    MainThread:78670 [wandb_init.py:init():705] updated telemetry
-2023-07-26 16:35:36,369 INFO    MainThread:78670 [wandb_init.py:init():738] communicating run to backend with 60.0 second timeout
-2023-07-26 16:35:37,779 INFO    MainThread:78670 [wandb_run.py:_on_init():2173] communicating current version
-2023-07-26 16:35:37,904 INFO    MainThread:78670 [wandb_run.py:_on_init():2182] got version response upgrade_message: "wandb version 0.15.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
-
-2023-07-26 16:35:37,905 INFO    MainThread:78670 [wandb_init.py:init():789] starting run threads in backend
-2023-07-26 16:35:38,011 INFO    MainThread:78670 [wandb_run.py:_console_start():2152] atexit reg
-2023-07-26 16:35:38,012 INFO    MainThread:78670 [wandb_run.py:_redirect():2007] redirect: SettingsConsole.WRAP_RAW
-2023-07-26 16:35:38,012 INFO    MainThread:78670 [wandb_run.py:_redirect():2072] Wrapping output streams.
-2023-07-26 16:35:38,012 INFO    MainThread:78670 [wandb_run.py:_redirect():2097] Redirects installed.
-2023-07-26 16:35:38,013 INFO    MainThread:78670 [wandb_init.py:init():830] run started, returning control to user process
-2023-07-26 16:36:35,878 WARNING MsgRouterThr:78670 [router.py:message_loop():77] message_loop has been closed
diff --git a/rl-starter-files/wandb/run-20230726_163536-y109zesf/run-y109zesf.wandb b/rl-starter-files/wandb/run-20230726_163536-y109zesf/run-y109zesf.wandb
deleted file mode 100644
index 8f194f3..0000000
Binary files a/rl-starter-files/wandb/run-20230726_163536-y109zesf/run-y109zesf.wandb and /dev/null differ
diff --git a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/config.yaml b/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/config.yaml
deleted file mode 100644
index 1a07756..0000000
--- a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/config.yaml
+++ /dev/null
@@ -1,32 +0,0 @@
-wandb_version: 1
-
-model:
-  desc: null
-  value: ''
-performance metric:
-  desc: null
-  value: extrinsic reward
-_wandb:
-  desc: null
-  value:
-    python_version: 3.9.6
-    cli_version: 0.15.5
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    start_time: 1690385957.470582
-    t:
-      1:
-      - 1
-      - 55
-      2:
-      - 1
-      - 55
-      3:
-      - 16
-      - 23
-      4: 3.9.6
-      5: 0.15.5
-      8:
-      - 4
-      - 5
diff --git a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/diff.patch b/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/diff.patch
deleted file mode 100644
index 193a9ba..0000000
--- a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/diff.patch
+++ /dev/null
@@ -1,45 +0,0 @@
-diff --git a/rl-starter-files/scripts/train.py b/rl-starter-files/scripts/train.py
-index 6b1b0c6..f2ad1eb 100644
---- a/rl-starter-files/scripts/train.py
-+++ b/rl-starter-files/scripts/train.py
-@@ -19,6 +19,10 @@ sys.path.insert(0, os.path.abspath('/Users/corinacaraconcea/Documents/UCL DSML/M
- import a2c
- import ppo
- 
-+from Minigrid.minigrid.__init__ import register_minigrid_envs
-+
-+register_minigrid_envs()
-+
- # Parse arguments
- 
- #The argparse module is a standard Python library for writing user-friendly command-line interfaces.
-@@ -313,13 +317,13 @@ if __name__ == "__main__":
- 
-         # Save status
- 
--        # if args.save_interval > 0 and update % args.save_interval == 0:
--        #     status_base = {"model_name": "ACmodel","num_frames": num_frames, "update": update,
--        #               "model_state": acmodel.state_dict(), "optimizer_state": algo.optimizer.state_dict()}
--        #     if hasattr(preprocess_obss, "vocab"):
--        #         status_base["vocab"] = preprocess_obss.vocab.vocab
--        #     utils.save_status(status_base,model_flag, model_dir)
--        #     txt_logger.info("Status saved")
-+        if args.save_interval > 0 and update % args.save_interval == 0:
-+            status_base = {"model_name": "ACmodel","num_frames": num_frames, "update": update,
-+                      "model_state": acmodel.state_dict(), "optimizer_state": algo.optimizer.state_dict()}
-+            if hasattr(preprocess_obss, "vocab"):
-+                status_base["vocab"] = preprocess_obss.vocab.vocab
-+            utils.save_status(status_base,model_flag, model_dir)
-+            txt_logger.info("Status saved")
- 
-         # Save status rnd
- 
-diff --git a/rl-starter-files/utils/env.py b/rl-starter-files/utils/env.py
-index fa4f36d..24b9b4b 100644
---- a/rl-starter-files/utils/env.py
-+++ b/rl-starter-files/utils/env.py
-@@ -5,3 +5,4 @@ def make_env(env_key, seed=None, render_mode=None):
-     env = gym.make(env_key, render_mode=render_mode)
-     env.reset(seed=seed)
-     return env
-+
diff --git a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log b/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
deleted file mode 100644
index 18bf93d..0000000
--- a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
+++ /dev/null
@@ -1,136 +0,0 @@
-log_done_counter 0
-U 1 | F 0000002048 | FPS 1470 | D 1 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 0.0 0.0 0 0 | H 1.941 | V 0.066 | pL 0.011 | vL 0.000 | ∇ 0.012
-log_done_counter 16
-U 2 | F 0000004096 | FPS 1581 | D 2 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.938 | V 0.063 | pL 0.015 | vL 0.000 | ∇ 0.005
-log_done_counter 16
-U 3 | F 0000006144 | FPS 1554 | D 4 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.935 | V 0.046 | pL 0.013 | vL 0.000 | ∇ 0.004
-log_done_counter 16
-U 4 | F 0000008192 | FPS 1544 | D 5 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.937 | V 0.037 | pL 0.011 | vL 0.000 | ∇ 0.004
-log_done_counter 16
-U 5 | F 0000010240 | FPS 1430 | D 6 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.938 | V 0.027 | pL 0.009 | vL 0.000 | ∇ 0.003
-log_done_counter 16
-U 6 | F 0000012288 | FPS 1642 | D 8 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.942 | V 0.021 | pL 0.007 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 7 | F 0000014336 | FPS 1639 | D 9 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.943 | V 0.015 | pL 0.005 | vL 0.000 | ∇ 0.002
-log_done_counter 16
-U 8 | F 0000016384 | FPS 1692 | D 10 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.942 | V 0.012 | pL 0.004 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 9 | F 0000018432 | FPS 1098 | D 12 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.940 | V 0.010 | pL 0.004 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 10 | F 0000020480 | FPS 1555 | D 13 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.941 | V 0.008 | pL 0.003 | vL 0.000 | ∇ 0.001
-Status saved
-log_done_counter 16
-U 11 | F 0000022528 | FPS 1551 | D 15 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.942 | V 0.005 | pL 0.002 | vL 0.000 | ∇ 0.000
-log_done_counter 0
-U 12 | F 0000024576 | FPS 1614 | D 16 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.942 | V 0.004 | pL 0.001 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 13 | F 0000026624 | FPS 1302 | D 17 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.943 | V 0.004 | pL 0.001 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 14 | F 0000028672 | FPS 1593 | D 19 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.943 | V 0.003 | pL 0.001 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 15 | F 0000030720 | FPS 1598 | D 20 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.943 | V 0.002 | pL 0.001 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 16 | F 0000032768 | FPS 1589 | D 21 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.943 | V 0.002 | pL 0.001 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 17 | F 0000034816 | FPS 1559 | D 23 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.944 | V 0.001 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 18 | F 0000036864 | FPS 1185 | D 24 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 19 | F 0000038912 | FPS 1535 | D 26 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 20 | F 0000040960 | FPS 1645 | D 27 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-Status saved
-log_done_counter 16
-U 21 | F 0000043008 | FPS 1621 | D 28 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 22 | F 0000045056 | FPS 1469 | D 30 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 23 | F 0000047104 | FPS 1058 | D 32 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 0
-U 24 | F 0000049152 | FPS 1363 | D 33 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 25 | F 0000051200 | FPS 1508 | D 34 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 26 | F 0000053248 | FPS 1632 | D 36 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 27 | F 0000055296 | FPS 1604 | D 37 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 28 | F 0000057344 | FPS 1598 | D 38 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 29 | F 0000059392 | FPS 1609 | D 40 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 30 | F 0000061440 | FPS 1504 | D 41 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-Status saved
-log_done_counter 16
-U 31 | F 0000063488 | FPS 1516 | D 42 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 32 | F 0000065536 | FPS 1580 | D 44 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 33 | F 0000067584 | FPS 1549 | D 45 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 34 | F 0000069632 | FPS 1615 | D 46 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 35 | F 0000071680 | FPS 1520 | D 47 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 0
-U 36 | F 0000073728 | FPS 1627 | D 49 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 37 | F 0000075776 | FPS 1540 | D 50 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 38 | F 0000077824 | FPS 1579 | D 51 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 39 | F 0000079872 | FPS 1609 | D 53 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 40 | F 0000081920 | FPS 1497 | D 54 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-Status saved
-log_done_counter 16
-U 41 | F 0000083968 | FPS 1559 | D 55 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 42 | F 0000086016 | FPS 1615 | D 57 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 43 | F 0000088064 | FPS 1614 | D 58 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 44 | F 0000090112 | FPS 1482 | D 59 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 45 | F 0000092160 | FPS 1505 | D 61 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 46 | F 0000094208 | FPS 1585 | D 62 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 0
-U 47 | F 0000096256 | FPS 1582 | D 63 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 48 | F 0000098304 | FPS 1589 | D 65 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V -0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 49 | F 0000100352 | FPS 1617 | D 66 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 50 | F 0000102400 | FPS 1426 | D 67 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-Status saved
-log_done_counter 16
-U 51 | F 0000104448 | FPS 1566 | D 69 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 52 | F 0000106496 | FPS 1628 | D 70 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V 0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 53 | F 0000108544 | FPS 1525 | D 71 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 54 | F 0000110592 | FPS 1553 | D 72 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 55 | F 0000112640 | FPS 1509 | D 74 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 56 | F 0000114688 | FPS 1514 | D 75 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 57 | F 0000116736 | FPS 1574 | D 76 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 58 | F 0000118784 | FPS 1555 | D 78 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 0
-U 59 | F 0000120832 | FPS 1587 | D 79 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 60 | F 0000122880 | FPS 1523 | D 80 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-Status saved
-log_done_counter 16
-U 61 | F 0000124928 | FPS 1584 | D 82 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V 0.000 | pL -0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 62 | F 0000126976 | FPS 1616 | D 83 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 63 | F 0000129024 | FPS 1583 | D 84 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 64 | F 0000131072 | FPS 1424 | D 86 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.945 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 65 | F 0000133120 | FPS 1695 | D 87 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.946 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
diff --git a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/requirements.txt b/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/requirements.txt
deleted file mode 100644
index 05458c5..0000000
--- a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/requirements.txt
+++ /dev/null
@@ -1,85 +0,0 @@
-altgraph==0.17.2
-appdirs==1.4.4
-appnope==0.1.3
-asttokens==2.2.1
-backcall==0.2.0
-certifi==2023.5.7
-charset-normalizer==3.2.0
-click==8.1.4
-cloudpickle==2.2.1
-comm==0.1.2
-contourpy==1.1.0
-cycler==0.11.0
-debugpy==1.6.5
-decorator==5.1.1
-docker-pycreds==0.4.0
-entrypoints==0.4
-executing==1.2.0
-farama-notifications==0.0.4
-filelock==3.12.2
-fonttools==4.40.0
-future==0.18.2
-gitdb==4.0.10
-gitpython==3.1.31
-gym-minigrid==1.2.2
-gym-notices==0.0.8
-gym==0.26.2
-gymnasium==0.28.1
-idna==3.4
-importlib-metadata==6.6.0
-importlib-resources==6.0.0
-ipykernel==6.20.2
-ipython==8.8.0
-jax-jumpy==1.0.0
-jedi==0.18.2
-jinja2==3.1.2
-jupyter-client==7.4.9
-jupyter-core==5.1.3
-kiwisolver==1.4.4
-macholib==1.15.2
-markupsafe==2.1.3
-matplotlib-inline==0.1.6
-matplotlib==3.7.2
-minigrid==2.3.0
-mpmath==1.3.0
-nest-asyncio==1.5.6
-networkx==3.1
-numpy==1.24.3
-packaging==23.0
-parso==0.8.3
-pathtools==0.1.2
-pexpect==4.8.0
-pickleshare==0.7.5
-pillow==10.0.0
-pip==21.2.4
-platformdirs==2.6.2
-prompt-toolkit==3.0.36
-protobuf==3.20.3
-psutil==5.9.4
-ptyprocess==0.7.0
-pure-eval==0.2.2
-pygame==2.4.0
-pygments==2.14.0
-pyparsing==3.0.9
-python-dateutil==2.8.2
-pyyaml==6.0
-pyzmq==25.0.0
-requests==2.31.0
-sentry-sdk==1.28.0
-setproctitle==1.3.2
-setuptools==58.0.4
-six==1.15.0
-smmap==5.0.0
-stack-data==0.6.2
-sympy==1.12
-tensorboardx==2.6
-torch-ac==1.4.0
-torch==2.0.1
-tornado==6.2
-traitlets==5.8.1
-typing-extensions==4.6.3
-urllib3==2.0.3
-wandb==0.15.5
-wcwidth==0.2.6
-wheel==0.37.0
-zipp==3.15.0
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-metadata.json b/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-metadata.json
deleted file mode 100644
index e0b8718..0000000
--- a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-metadata.json
+++ /dev/null
@@ -1,42 +0,0 @@
-{
-    "os": "macOS-13.4-arm64-arm-64bit",
-    "python": "3.9.6",
-    "heartbeatAt": "2023-07-26T15:39:18.092127",
-    "startedAt": "2023-07-26T15:39:17.454683",
-    "docker": null,
-    "cuda": null,
-    "args": [
-        "--algo",
-        "ppo",
-        "--env",
-        "MiniGrid-MultiRoom-N7-S4-v0",
-        "--save-interval",
-        "10",
-        "--frames",
-        "800000"
-    ],
-    "state": "running",
-    "program": "-m scripts.train",
-    "git": {
-        "remote": "https://github.com/CorinaCaraconcea/diversity_study.git",
-        "commit": "bbd28515d7e4bbc2bcc39a9deff9cc255775ca99"
-    },
-    "email": "cori.caraconcea@gmail.com",
-    "root": "/Users/corinacaraconcea/Downloads/diversity_study",
-    "host": "Corinas-MacBook-Air.local",
-    "username": "corinacaraconcea",
-    "executable": "/Library/Developer/CommandLineTools/usr/bin/python3",
-    "cpu_count": 8,
-    "cpu_count_logical": 8,
-    "disk": {
-        "total": 228.27386474609375,
-        "used": 8.95040512084961
-    },
-    "gpuapple": {
-        "type": "arm",
-        "vendor": "Apple"
-    },
-    "memory": {
-        "total": 8.0
-    }
-}
diff --git a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json b/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
deleted file mode 100644
index 9fbbeaa..0000000
--- a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
+++ /dev/null
@@ -1 +0,0 @@
-{"external_return_per_episode": 0.0, "_timestamp": 1690386045.6441169, "_runtime": 88.1735348701477, "_step": 64}
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/logs/debug-internal.log b/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/logs/debug-internal.log
deleted file mode 100644
index e0025ac..0000000
--- a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/logs/debug-internal.log
+++ /dev/null
@@ -1,463 +0,0 @@
-2023-07-26 16:39:17,471 INFO    StreamThr :79087 [internal.py:wandb_internal():86] W&B internal server running at pid: 79087, started at: 2023-07-26 16:39:17.471232
-2023-07-26 16:39:17,472 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status
-2023-07-26 16:39:17,474 INFO    WriterThread:79087 [datastore.py:open_for_write():85] open: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/run-wl1aqmtn.wandb
-2023-07-26 16:39:17,475 DEBUG   SenderThread:79087 [sender.py:send():369] send: header
-2023-07-26 16:39:17,488 DEBUG   SenderThread:79087 [sender.py:send():369] send: run
-2023-07-26 16:39:17,976 INFO    SenderThread:79087 [dir_watcher.py:__init__():211] watching files in: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files
-2023-07-26 16:39:17,976 INFO    SenderThread:79087 [sender.py:_start_run_threads():1100] run started: wl1aqmtn with start time 1690385957.470582
-2023-07-26 16:39:17,981 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:17,981 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:17,986 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: check_version
-2023-07-26 16:39:17,986 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: check_version
-2023-07-26 16:39:18,085 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: run_start
-2023-07-26 16:39:18,090 DEBUG   HandlerThread:79087 [system_info.py:__init__():31] System info init
-2023-07-26 16:39:18,091 DEBUG   HandlerThread:79087 [system_info.py:__init__():46] System info init done
-2023-07-26 16:39:18,091 INFO    HandlerThread:79087 [system_monitor.py:start():181] Starting system monitor
-2023-07-26 16:39:18,091 INFO    SystemMonitor:79087 [system_monitor.py:_start():145] Starting system asset monitoring threads
-2023-07-26 16:39:18,091 INFO    HandlerThread:79087 [system_monitor.py:probe():201] Collecting system info
-2023-07-26 16:39:18,091 INFO    SystemMonitor:79087 [interfaces.py:start():190] Started cpu monitoring
-2023-07-26 16:39:18,092 DEBUG   HandlerThread:79087 [system_info.py:probe():195] Probing system
-2023-07-26 16:39:18,092 INFO    SystemMonitor:79087 [interfaces.py:start():190] Started disk monitoring
-2023-07-26 16:39:18,093 INFO    SystemMonitor:79087 [interfaces.py:start():190] Started gpuapple monitoring
-2023-07-26 16:39:18,094 INFO    SystemMonitor:79087 [interfaces.py:start():190] Started memory monitoring
-2023-07-26 16:39:18,095 INFO    SystemMonitor:79087 [interfaces.py:start():190] Started network monitoring
-2023-07-26 16:39:18,099 DEBUG   HandlerThread:79087 [system_info.py:_probe_git():180] Probing git
-2023-07-26 16:39:18,116 DEBUG   HandlerThread:79087 [system_info.py:_probe_git():188] Probing git done
-2023-07-26 16:39:18,116 DEBUG   HandlerThread:79087 [system_info.py:probe():240] Probing system done
-2023-07-26 16:39:18,116 DEBUG   HandlerThread:79087 [system_monitor.py:probe():210] {'os': 'macOS-13.4-arm64-arm-64bit', 'python': '3.9.6', 'heartbeatAt': '2023-07-26T15:39:18.092127', 'startedAt': '2023-07-26T15:39:17.454683', 'docker': None, 'cuda': None, 'args': ('--algo', 'ppo', '--env', 'MiniGrid-MultiRoom-N7-S4-v0', '--save-interval', '10', '--frames', '800000'), 'state': 'running', 'program': '-m scripts.train', 'git': {'remote': 'https://github.com/CorinaCaraconcea/diversity_study.git', 'commit': 'bbd28515d7e4bbc2bcc39a9deff9cc255775ca99'}, 'email': 'cori.caraconcea@gmail.com', 'root': '/Users/corinacaraconcea/Downloads/diversity_study', 'host': 'Corinas-MacBook-Air.local', 'username': 'corinacaraconcea', 'executable': '/Library/Developer/CommandLineTools/usr/bin/python3', 'cpu_count': 8, 'cpu_count_logical': 8, 'disk': {'total': 228.27386474609375, 'used': 8.95040512084961}, 'gpuapple': {'type': 'arm', 'vendor': 'Apple'}, 'memory': {'total': 8.0}}
-2023-07-26 16:39:18,117 INFO    HandlerThread:79087 [system_monitor.py:probe():211] Finished collecting system info
-2023-07-26 16:39:18,117 INFO    HandlerThread:79087 [system_monitor.py:probe():214] Publishing system info
-2023-07-26 16:39:18,117 DEBUG   HandlerThread:79087 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment
-2023-07-26 16:39:18,117 DEBUG   HandlerThread:79087 [system_info.py:_save_pip():67] Saving pip packages done
-2023-07-26 16:39:18,117 DEBUG   HandlerThread:79087 [system_info.py:_save_code():89] Saving code
-2023-07-26 16:39:18,117 WARNING HandlerThread:79087 [system_info.py:_save_code():91] unable to save code -- program entry not found
-2023-07-26 16:39:18,117 DEBUG   HandlerThread:79087 [system_info.py:_save_patches():127] Saving git patches
-2023-07-26 16:39:18,165 DEBUG   HandlerThread:79087 [system_info.py:_save_patches():169] Saving git patches done
-2023-07-26 16:39:18,165 INFO    HandlerThread:79087 [system_monitor.py:probe():216] Finished publishing system info
-2023-07-26 16:39:18,167 DEBUG   SenderThread:79087 [sender.py:send():369] send: files
-2023-07-26 16:39:18,167 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-metadata.json with policy now
-2023-07-26 16:39:18,168 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file diff.patch with policy now
-2023-07-26 16:39:18,173 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:39:18,173 DEBUG   SenderThread:79087 [sender.py:send():369] send: telemetry
-2023-07-26 16:39:18,173 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:39:18,609 INFO    wandb-upload_0:79087 [upload_job.py:push():133] Uploaded file /var/folders/n4/lk2x7f1j3g35spnvp796gmx40000gn/T/tmpwoi098u0wandb/kt7wvjv5-wandb-metadata.json
-2023-07-26 16:39:18,734 INFO    wandb-upload_1:79087 [upload_job.py:push():133] Uploaded file /var/folders/n4/lk2x7f1j3g35spnvp796gmx40000gn/T/tmpwoi098u0wandb/jcambb9s-diff.patch
-2023-07-26 16:39:18,982 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/requirements.txt
-2023-07-26 16:39:18,982 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:18,982 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/diff.patch
-2023-07-26 16:39:18,982 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:18,982 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-metadata.json
-2023-07-26 16:39:19,566 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:19,567 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:19,567 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:19,567 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:19,987 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:20,866 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:20,867 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:20,867 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:20,867 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:20,992 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:20,992 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:22,186 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:22,187 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:22,187 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:22,187 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:23,001 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:23,001 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:23,406 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:39:23,517 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:23,519 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:23,519 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:23,519 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:24,004 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:24,955 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:24,956 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:24,956 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:24,956 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:25,007 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:25,007 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:26,206 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:26,207 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:26,207 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:26,209 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:27,018 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:27,018 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:27,459 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:27,460 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:27,460 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:27,460 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:28,023 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:28,674 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:28,676 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:28,676 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:28,676 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:39:28,676 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:29,029 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:29,029 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:30,555 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:30,557 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:30,557 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:30,558 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:31,036 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:31,037 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:31,878 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:31,878 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:31,879 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:31,879 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:32,042 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:33,047 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:33,179 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:39:33,179 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:39:33,208 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:33,456 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:33,457 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:33,457 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:34,053 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:34,463 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:39:34,481 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:34,483 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:34,483 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:34,485 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:35,057 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:35,057 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:36,063 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:36,065 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:36,065 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:36,065 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:37,067 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:37,067 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:37,352 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:37,352 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:37,353 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:37,353 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:38,070 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:38,637 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:38,638 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:38,640 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:38,641 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:39,075 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:39,075 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:39,875 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:39:39,929 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:39,930 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:39,930 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:39,931 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:40,080 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:41,085 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:41,248 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:41,249 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:41,249 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:41,250 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:42,090 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:42,982 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:42,983 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:42,983 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:42,983 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:43,093 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:43,093 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:44,321 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:44,322 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:44,322 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:44,322 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:45,103 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:45,103 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:45,545 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:39:45,569 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:45,570 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:45,570 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:45,570 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:46,108 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:46,839 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:46,840 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:46,840 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:46,840 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:47,114 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:47,114 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:48,180 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:39:48,180 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:39:48,244 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:48,436 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:48,437 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:48,437 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:49,125 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:49,125 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:50,207 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:50,209 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:50,209 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:50,210 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:50,581 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:39:51,135 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:51,135 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:51,135 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/config.yaml
-2023-07-26 16:39:51,716 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:51,718 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:51,718 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:51,718 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:52,140 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:53,077 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:53,078 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:53,078 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:53,078 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:53,145 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:53,146 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:54,335 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:54,336 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:54,337 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:54,337 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:55,156 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:55,156 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:55,614 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:55,616 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:55,616 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:55,617 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:55,827 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:39:56,161 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:56,899 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:56,900 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:56,901 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:56,901 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:57,167 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:57,167 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:58,175 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:58,176 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:58,176 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:58,176 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:39:59,173 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:39:59,174 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:39:59,542 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:39:59,545 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:39:59,545 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:39:59,545 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:00,179 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:00,835 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:40:00,900 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:00,901 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:00,901 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:00,902 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:01,184 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:01,184 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:02,200 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:02,201 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:02,201 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:02,201 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:03,185 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:40:03,185 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:03,185 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:40:03,186 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:03,525 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:03,525 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:03,526 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:03,526 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:04,190 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:04,796 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:04,797 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:04,797 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:04,797 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:05,196 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:05,196 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:06,044 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:40:06,148 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:06,149 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:06,149 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:06,150 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:06,201 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:07,207 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:07,411 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:07,412 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:07,413 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:07,413 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:08,212 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:08,744 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:08,745 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:08,745 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:08,745 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:09,217 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:09,217 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:10,044 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:10,045 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:10,045 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:10,046 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:10,219 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:11,224 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:11,280 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:40:11,320 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:11,321 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:11,321 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:11,321 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:12,229 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:12,691 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:12,692 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:12,692 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:12,693 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:13,231 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:13,231 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:14,011 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:14,012 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:14,012 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:14,012 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:14,237 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:15,243 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:15,283 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:15,285 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:15,285 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:15,285 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:16,248 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:16,509 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:40:16,555 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:16,555 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:16,556 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:16,556 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:17,253 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:17,254 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:17,942 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:17,945 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:17,945 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:17,946 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:18,100 DEBUG   SystemMonitor:79087 [system_monitor.py:_start():159] Starting system metrics aggregation loop
-2023-07-26 16:40:18,102 DEBUG   SenderThread:79087 [sender.py:send():369] send: telemetry
-2023-07-26 16:40:18,103 DEBUG   SenderThread:79087 [sender.py:send():369] send: stats
-2023-07-26 16:40:18,187 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:40:18,188 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:40:18,259 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:19,263 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:19,307 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:19,308 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:19,308 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:19,309 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:20,267 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:20,603 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:20,604 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:20,604 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:20,605 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:21,272 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:21,272 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:21,826 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:40:21,901 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:22,027 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:22,027 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:22,027 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:22,277 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:22,277 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/config.yaml
-2023-07-26 16:40:23,193 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:23,194 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:23,194 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:23,195 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:23,283 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:23,283 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:24,462 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:24,463 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:24,463 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:24,463 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:25,293 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:25,294 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:25,901 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:25,902 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:25,902 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:25,903 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:26,298 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:27,132 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:40:27,215 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:27,216 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:27,216 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:27,216 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:27,299 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:27,299 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:28,476 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:28,477 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:28,477 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:28,477 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:29,310 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:29,310 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:29,822 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:29,822 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:29,822 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:29,823 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:30,315 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:31,144 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:31,145 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:31,145 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:31,146 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:31,321 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:31,322 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:32,453 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:40:32,504 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:32,505 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:32,505 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:32,505 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:33,192 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:40:33,192 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:40:33,325 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:33,325 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:33,860 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:33,861 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:33,861 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:33,861 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:34,326 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:35,163 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:35,164 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:35,164 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:35,164 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:35,329 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:35,330 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:36,484 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:36,484 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:36,485 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:36,485 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:37,340 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:37,340 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:37,704 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:40:37,777 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:37,777 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:37,777 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:37,778 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:38,345 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:39,124 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:39,125 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:39,125 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:39,125 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:39,350 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:39,350 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:40,424 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:40,424 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:40,424 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:40,426 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:41,361 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:41,361 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:41,695 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:41,696 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:41,696 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:41,696 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:42,365 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:42,953 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:40:42,992 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:42,992 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:42,992 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:42,993 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:43,370 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:43,371 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:44,433 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:44,434 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:44,434 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:44,435 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:45,376 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:45,376 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:45,644 DEBUG   HandlerThread:79087 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:40:45,645 DEBUG   SenderThread:79087 [sender.py:send():369] send: history
-2023-07-26 16:40:45,645 DEBUG   SenderThread:79087 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:40:45,645 INFO    SenderThread:79087 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:40:46,381 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/wandb-summary.json
-2023-07-26 16:40:46,835 WARNING StreamThr :79087 [internal.py:is_dead():414] Internal process exiting, parent pid 79061 disappeared
-2023-07-26 16:40:46,835 ERROR   StreamThr :79087 [internal.py:wandb_internal():152] Internal process shutdown.
-2023-07-26 16:40:46,900 INFO    HandlerThread:79087 [handler.py:finish():854] shutting down handler
-2023-07-26 16:40:46,900 INFO    HandlerThread:79087 [system_monitor.py:finish():190] Stopping system monitor
-2023-07-26 16:40:46,900 DEBUG   SystemMonitor:79087 [system_monitor.py:_start():166] Finished system metrics aggregation loop
-2023-07-26 16:40:46,900 INFO    HandlerThread:79087 [interfaces.py:finish():202] Joined cpu monitor
-2023-07-26 16:40:46,900 DEBUG   SystemMonitor:79087 [system_monitor.py:_start():170] Publishing last batch of metrics
-2023-07-26 16:40:46,900 INFO    HandlerThread:79087 [interfaces.py:finish():202] Joined disk monitor
-2023-07-26 16:40:46,901 INFO    WriterThread:79087 [datastore.py:close():298] close: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/run-wl1aqmtn.wandb
-2023-07-26 16:40:46,901 INFO    SenderThread:79087 [sender.py:finish():1526] shutting down sender
-2023-07-26 16:40:46,901 INFO    HandlerThread:79087 [interfaces.py:finish():202] Joined gpuapple monitor
-2023-07-26 16:40:46,901 INFO    HandlerThread:79087 [interfaces.py:finish():202] Joined memory monitor
-2023-07-26 16:40:46,901 INFO    HandlerThread:79087 [interfaces.py:finish():202] Joined network monitor
-2023-07-26 16:40:47,385 INFO    Thread-12 :79087 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/files/output.log
-2023-07-26 16:40:48,460 INFO    MainThread:79087 [internal.py:handle_exit():76] Internal process exited
diff --git a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/logs/debug.log b/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/logs/debug.log
deleted file mode 100644
index 5de3e7d..0000000
--- a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/logs/debug.log
+++ /dev/null
@@ -1,28 +0,0 @@
-2023-07-26 16:39:17,457 INFO    MainThread:79061 [wandb_setup.py:_flush():76] Current SDK version is 0.15.5
-2023-07-26 16:39:17,457 INFO    MainThread:79061 [wandb_setup.py:_flush():76] Configure stats pid to 79061
-2023-07-26 16:39:17,457 INFO    MainThread:79061 [wandb_setup.py:_flush():76] Loading settings from /Users/corinacaraconcea/.config/wandb/settings
-2023-07-26 16:39:17,457 INFO    MainThread:79061 [wandb_setup.py:_flush():76] Loading settings from /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/settings
-2023-07-26 16:39:17,457 INFO    MainThread:79061 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
-2023-07-26 16:39:17,457 INFO    MainThread:79061 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
-2023-07-26 16:39:17,457 WARNING MainThread:79061 [wandb_setup.py:_flush():76] Could not find program at -m scripts.train
-2023-07-26 16:39:17,457 INFO    MainThread:79061 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': None, 'program': '-m scripts.train'}
-2023-07-26 16:39:17,457 INFO    MainThread:79061 [wandb_init.py:_log_setup():507] Logging user logs to /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/logs/debug.log
-2023-07-26 16:39:17,457 INFO    MainThread:79061 [wandb_init.py:_log_setup():508] Logging internal logs to /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/logs/debug-internal.log
-2023-07-26 16:39:17,457 INFO    MainThread:79061 [wandb_init.py:init():547] calling init triggers
-2023-07-26 16:39:17,457 INFO    MainThread:79061 [wandb_init.py:init():554] wandb.init called with sweep_config: {}
-config: {'model': '', 'performance metric': 'extrinsic reward'}
-2023-07-26 16:39:17,457 INFO    MainThread:79061 [wandb_init.py:init():596] starting backend
-2023-07-26 16:39:17,457 INFO    MainThread:79061 [wandb_init.py:init():600] setting up manager
-2023-07-26 16:39:17,467 INFO    MainThread:79061 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
-2023-07-26 16:39:17,470 INFO    MainThread:79061 [wandb_init.py:init():606] backend started and connected
-2023-07-26 16:39:17,474 INFO    MainThread:79061 [wandb_init.py:init():705] updated telemetry
-2023-07-26 16:39:17,486 INFO    MainThread:79061 [wandb_init.py:init():738] communicating run to backend with 60.0 second timeout
-2023-07-26 16:39:17,985 INFO    MainThread:79061 [wandb_run.py:_on_init():2173] communicating current version
-2023-07-26 16:39:18,071 INFO    MainThread:79061 [wandb_run.py:_on_init():2182] got version response upgrade_message: "wandb version 0.15.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
-
-2023-07-26 16:39:18,071 INFO    MainThread:79061 [wandb_init.py:init():789] starting run threads in backend
-2023-07-26 16:39:18,170 INFO    MainThread:79061 [wandb_run.py:_console_start():2152] atexit reg
-2023-07-26 16:39:18,170 INFO    MainThread:79061 [wandb_run.py:_redirect():2007] redirect: SettingsConsole.WRAP_RAW
-2023-07-26 16:39:18,170 INFO    MainThread:79061 [wandb_run.py:_redirect():2072] Wrapping output streams.
-2023-07-26 16:39:18,170 INFO    MainThread:79061 [wandb_run.py:_redirect():2097] Redirects installed.
-2023-07-26 16:39:18,171 INFO    MainThread:79061 [wandb_init.py:init():830] run started, returning control to user process
diff --git a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/run-wl1aqmtn.wandb b/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/run-wl1aqmtn.wandb
deleted file mode 100644
index 26b46c8..0000000
Binary files a/rl-starter-files/wandb/run-20230726_163917-wl1aqmtn/run-wl1aqmtn.wandb and /dev/null differ
diff --git a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/config.yaml b/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/config.yaml
deleted file mode 100644
index 8292fb3..0000000
--- a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/config.yaml
+++ /dev/null
@@ -1,32 +0,0 @@
-wandb_version: 1
-
-model:
-  desc: null
-  value: ''
-performance metric:
-  desc: null
-  value: extrinsic reward
-_wandb:
-  desc: null
-  value:
-    python_version: 3.9.6
-    cli_version: 0.15.5
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    start_time: 1690386356.919992
-    t:
-      1:
-      - 1
-      - 55
-      2:
-      - 1
-      - 55
-      3:
-      - 16
-      - 23
-      4: 3.9.6
-      5: 0.15.5
-      8:
-      - 4
-      - 5
diff --git a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/diff.patch b/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/diff.patch
deleted file mode 100644
index 2afbf26..0000000
--- a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/diff.patch
+++ /dev/null
@@ -1,59 +0,0 @@
-diff --git a/rl-starter-files/scripts/train.py b/rl-starter-files/scripts/train.py
-index 6b1b0c6..f2ad1eb 100644
---- a/rl-starter-files/scripts/train.py
-+++ b/rl-starter-files/scripts/train.py
-@@ -19,6 +19,10 @@ sys.path.insert(0, os.path.abspath('/Users/corinacaraconcea/Documents/UCL DSML/M
- import a2c
- import ppo
- 
-+from Minigrid.minigrid.__init__ import register_minigrid_envs
-+
-+register_minigrid_envs()
-+
- # Parse arguments
- 
- #The argparse module is a standard Python library for writing user-friendly command-line interfaces.
-@@ -313,13 +317,13 @@ if __name__ == "__main__":
- 
-         # Save status
- 
--        # if args.save_interval > 0 and update % args.save_interval == 0:
--        #     status_base = {"model_name": "ACmodel","num_frames": num_frames, "update": update,
--        #               "model_state": acmodel.state_dict(), "optimizer_state": algo.optimizer.state_dict()}
--        #     if hasattr(preprocess_obss, "vocab"):
--        #         status_base["vocab"] = preprocess_obss.vocab.vocab
--        #     utils.save_status(status_base,model_flag, model_dir)
--        #     txt_logger.info("Status saved")
-+        if args.save_interval > 0 and update % args.save_interval == 0:
-+            status_base = {"model_name": "ACmodel","num_frames": num_frames, "update": update,
-+                      "model_state": acmodel.state_dict(), "optimizer_state": algo.optimizer.state_dict()}
-+            if hasattr(preprocess_obss, "vocab"):
-+                status_base["vocab"] = preprocess_obss.vocab.vocab
-+            utils.save_status(status_base,model_flag, model_dir)
-+            txt_logger.info("Status saved")
- 
-         # Save status rnd
- 
-diff --git a/rl-starter-files/scripts/visualize.py b/rl-starter-files/scripts/visualize.py
-index dd28d0b..e51ea82 100644
---- a/rl-starter-files/scripts/visualize.py
-+++ b/rl-starter-files/scripts/visualize.py
-@@ -4,6 +4,9 @@ import numpy
- import utils
- from utils import device
- 
-+from Minigrid.minigrid.__init__ import register_minigrid_envs
-+
-+register_minigrid_envs()
- 
- # Parse arguments
- 
-diff --git a/rl-starter-files/utils/env.py b/rl-starter-files/utils/env.py
-index fa4f36d..24b9b4b 100644
---- a/rl-starter-files/utils/env.py
-+++ b/rl-starter-files/utils/env.py
-@@ -5,3 +5,4 @@ def make_env(env_key, seed=None, render_mode=None):
-     env = gym.make(env_key, render_mode=render_mode)
-     env.reset(seed=seed)
-     return env
-+
diff --git a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log b/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
deleted file mode 100644
index 62a11a4..0000000
--- a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
+++ /dev/null
@@ -1,84 +0,0 @@
-log_done_counter 19
-U 1 | F 0000002048 | FPS 1462 | D 1 | rR:μσmM 0.18 0.28 0.00 0.77 | F:μσmM 84.1 26.1 26.0 100.0 | H 1.932 | V 0.123 | pL 0.011 | vL 0.006 | ∇ 0.023
-log_done_counter 26
-U 2 | F 0000004096 | FPS 1643 | D 2 | rR:μσmM 0.32 0.28 0.00 0.82 | F:μσmM 71.7 26.4 20.0 100.0 | H 1.921 | V 0.152 | pL -0.018 | vL 0.010 | ∇ 0.027
-log_done_counter 31
-U 3 | F 0000006144 | FPS 1603 | D 3 | rR:μσmM 0.33 0.30 0.00 0.93 | F:μσmM 70.2 29.3 8.0 100.0 | H 1.920 | V 0.152 | pL -0.017 | vL 0.012 | ∇ 0.038
-log_done_counter 30
-U 4 | F 0000008192 | FPS 1620 | D 5 | rR:μσmM 0.42 0.31 0.00 0.92 | F:μσmM 61.3 30.7 9.0 100.0 | H 1.882 | V 0.156 | pL -0.048 | vL 0.018 | ∇ 0.041
-log_done_counter 41
-U 5 | F 0000010240 | FPS 1632 | D 6 | rR:μσmM 0.54 0.28 0.00 0.95 | F:μσmM 49.9 29.0 6.0 100.0 | H 1.845 | V 0.247 | pL -0.064 | vL 0.023 | ∇ 0.079
-log_done_counter 73
-U 6 | F 0000012288 | FPS 1599 | D 7 | rR:μσmM 0.71 0.23 0.00 0.95 | F:μσmM 32.3 25.2 6.0 100.0 | H 1.765 | V 0.387 | pL -0.174 | vL 0.037 | ∇ 0.107
-log_done_counter 93
-U 7 | F 0000014336 | FPS 1623 | D 9 | rR:μσmM 0.79 0.14 0.36 0.95 | F:μσmM 23.4 15.1 6.0 71.0 | H 1.656 | V 0.543 | pL -0.172 | vL 0.023 | ∇ 0.084
-log_done_counter 132
-U 8 | F 0000016384 | FPS 1603 | D 10 | rR:μσmM 0.85 0.10 0.33 0.95 | F:μσmM 16.6 11.4 6.0 74.0 | H 1.530 | V 0.681 | pL -0.134 | vL 0.013 | ∇ 0.117
-log_done_counter 168
-U 9 | F 0000018432 | FPS 1578 | D 11 | rR:μσmM 0.89 0.06 0.64 0.95 | F:μσmM 12.4 6.8 5.0 40.0 | H 1.386 | V 0.781 | pL -0.091 | vL 0.008 | ∇ 0.082
-log_done_counter 208
-U 10 | F 0000020480 | FPS 1592 | D 12 | rR:μσmM 0.91 0.04 0.72 0.95 | F:μσmM 9.9 4.2 5.0 31.0 | H 1.202 | V 0.851 | pL -0.038 | vL 0.002 | ∇ 0.040
-Status saved
-log_done_counter 266
-U 11 | F 0000022528 | FPS 1590 | D 14 | rR:μσmM 0.93 0.03 0.76 0.95 | F:μσmM 7.9 3.0 5.0 27.0 | H 0.843 | V 0.886 | pL -0.029 | vL 0.001 | ∇ 0.032
-log_done_counter 306
-U 12 | F 0000024576 | FPS 1560 | D 15 | rR:μσmM 0.94 0.01 0.86 0.95 | F:μσmM 6.7 1.6 5.0 16.0 | H 0.523 | V 0.909 | pL -0.002 | vL 0.000 | ∇ 0.009
-log_done_counter 351
-U 13 | F 0000026624 | FPS 1564 | D 16 | rR:μσmM 0.95 0.01 0.90 0.95 | F:μσmM 5.8 1.0 5.0 11.0 | H 0.266 | V 0.923 | pL -0.009 | vL 0.000 | ∇ 0.010
-log_done_counter 397
-U 14 | F 0000028672 | FPS 1580 | D 18 | rR:μσmM 0.95 0.00 0.92 0.95 | F:μσmM 5.2 0.5 5.0 9.0 | H 0.153 | V 0.933 | pL -0.004 | vL 0.000 | ∇ 0.007
-log_done_counter 397
-U 15 | F 0000030720 | FPS 1547 | D 19 | rR:μσmM 0.95 0.00 0.94 0.95 | F:μσmM 5.1 0.4 5.0 7.0 | H 0.109 | V 0.934 | pL -0.003 | vL 0.000 | ∇ 0.004
-log_done_counter 403
-U 16 | F 0000032768 | FPS 1578 | D 20 | rR:μσmM 0.95 0.00 0.94 0.95 | F:μσmM 5.1 0.3 5.0 7.0 | H 0.085 | V 0.935 | pL -0.000 | vL 0.000 | ∇ 0.009
-log_done_counter 405
-U 17 | F 0000034816 | FPS 1569 | D 22 | rR:μσmM 0.95 0.00 0.94 0.95 | F:μσmM 5.1 0.3 5.0 7.0 | H 0.066 | V 0.935 | pL 0.001 | vL 0.000 | ∇ 0.006
-log_done_counter 405
-U 18 | F 0000036864 | FPS 1568 | D 23 | rR:μσmM 0.95 0.00 0.94 0.95 | F:μσmM 5.0 0.2 5.0 7.0 | H 0.054 | V 0.935 | pL -0.002 | vL 0.000 | ∇ 0.006
-log_done_counter 407
-U 19 | F 0000038912 | FPS 1338 | D 24 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.2 5.0 6.0 | H 0.047 | V 0.935 | pL -0.002 | vL 0.000 | ∇ 0.004
-log_done_counter 406
-U 20 | F 0000040960 | FPS 1546 | D 26 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.2 5.0 6.0 | H 0.048 | V 0.935 | pL -0.002 | vL 0.000 | ∇ 0.004
-Status saved
-log_done_counter 408
-U 21 | F 0000043008 | FPS 1591 | D 27 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.2 5.0 6.0 | H 0.039 | V 0.935 | pL -0.003 | vL 0.000 | ∇ 0.006
-log_done_counter 406
-U 22 | F 0000045056 | FPS 1561 | D 28 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.037 | V 0.935 | pL -0.003 | vL 0.000 | ∇ 0.012
-log_done_counter 412
-U 23 | F 0000047104 | FPS 1567 | D 30 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.031 | V 0.936 | pL 0.000 | vL 0.000 | ∇ 0.007
-log_done_counter 405
-U 24 | F 0000049152 | FPS 1586 | D 31 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.027 | V 0.936 | pL 0.002 | vL 0.000 | ∇ 0.016
-log_done_counter 409
-U 25 | F 0000051200 | FPS 1597 | D 32 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.024 | V 0.936 | pL 0.004 | vL 0.000 | ∇ 0.009
-log_done_counter 408
-U 26 | F 0000053248 | FPS 1480 | D 34 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.021 | V 0.935 | pL -0.000 | vL 0.000 | ∇ 0.018
-log_done_counter 411
-U 27 | F 0000055296 | FPS 1581 | D 35 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.020 | V 0.936 | pL 0.006 | vL 0.000 | ∇ 0.009
-log_done_counter 407
-U 28 | F 0000057344 | FPS 1573 | D 36 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.020 | V 0.936 | pL 0.003 | vL 0.000 | ∇ 0.002
-log_done_counter 408
-U 29 | F 0000059392 | FPS 1564 | D 38 | rR:μσmM 0.95 0.00 0.93 0.95 | F:μσmM 5.0 0.2 5.0 8.0 | H 0.017 | V 0.934 | pL 0.002 | vL 0.000 | ∇ 0.054
-log_done_counter 407
-U 30 | F 0000061440 | FPS 1638 | D 39 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.015 | V 0.937 | pL 0.015 | vL 0.000 | ∇ 0.010
-Status saved
-log_done_counter 410
-U 31 | F 0000063488 | FPS 1560 | D 40 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.013 | V 0.936 | pL 0.005 | vL 0.000 | ∇ 0.006
-log_done_counter 411
-U 32 | F 0000065536 | FPS 1542 | D 41 | rR:μσmM 0.95 0.00 0.94 0.95 | F:μσmM 5.0 0.1 5.0 7.0 | H 0.012 | V 0.937 | pL 0.003 | vL 0.000 | ∇ 0.014
-log_done_counter 404
-U 33 | F 0000067584 | FPS 1476 | D 43 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.012 | V 0.935 | pL -0.004 | vL 0.000 | ∇ 0.013
-log_done_counter 414
-U 34 | F 0000069632 | FPS 1637 | D 44 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.011 | V 0.936 | pL 0.005 | vL 0.000 | ∇ 0.023
-log_done_counter 405
-U 35 | F 0000071680 | FPS 1465 | D 45 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.0 5.0 6.0 | H 0.012 | V 0.937 | pL 0.007 | vL 0.000 | ∇ 0.008
-log_done_counter 412
-U 36 | F 0000073728 | FPS 1555 | D 47 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.0 5.0 6.0 | H 0.012 | V 0.936 | pL 0.003 | vL 0.000 | ∇ 0.005
-log_done_counter 410
-U 37 | F 0000075776 | FPS 1542 | D 48 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.012 | V 0.936 | pL 0.001 | vL 0.000 | ∇ 0.006
-log_done_counter 407
-U 38 | F 0000077824 | FPS 1592 | D 49 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.011 | V 0.936 | pL -0.001 | vL 0.000 | ∇ 0.005
-log_done_counter 413
-U 39 | F 0000079872 | FPS 1648 | D 51 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.0 5.0 6.0 | H 0.012 | V 0.936 | pL -0.002 | vL 0.000 | ∇ 0.037
-log_done_counter 404
-U 40 | F 0000081920 | FPS 1330 | D 52 | rR:μσmM 0.95 0.00 0.95 0.95 | F:μσmM 5.0 0.1 5.0 6.0 | H 0.011 | V 0.935 | pL -0.009 | vL 0.000 | ∇ 0.004
-Status saved
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/requirements.txt b/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/requirements.txt
deleted file mode 100644
index 05458c5..0000000
--- a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/requirements.txt
+++ /dev/null
@@ -1,85 +0,0 @@
-altgraph==0.17.2
-appdirs==1.4.4
-appnope==0.1.3
-asttokens==2.2.1
-backcall==0.2.0
-certifi==2023.5.7
-charset-normalizer==3.2.0
-click==8.1.4
-cloudpickle==2.2.1
-comm==0.1.2
-contourpy==1.1.0
-cycler==0.11.0
-debugpy==1.6.5
-decorator==5.1.1
-docker-pycreds==0.4.0
-entrypoints==0.4
-executing==1.2.0
-farama-notifications==0.0.4
-filelock==3.12.2
-fonttools==4.40.0
-future==0.18.2
-gitdb==4.0.10
-gitpython==3.1.31
-gym-minigrid==1.2.2
-gym-notices==0.0.8
-gym==0.26.2
-gymnasium==0.28.1
-idna==3.4
-importlib-metadata==6.6.0
-importlib-resources==6.0.0
-ipykernel==6.20.2
-ipython==8.8.0
-jax-jumpy==1.0.0
-jedi==0.18.2
-jinja2==3.1.2
-jupyter-client==7.4.9
-jupyter-core==5.1.3
-kiwisolver==1.4.4
-macholib==1.15.2
-markupsafe==2.1.3
-matplotlib-inline==0.1.6
-matplotlib==3.7.2
-minigrid==2.3.0
-mpmath==1.3.0
-nest-asyncio==1.5.6
-networkx==3.1
-numpy==1.24.3
-packaging==23.0
-parso==0.8.3
-pathtools==0.1.2
-pexpect==4.8.0
-pickleshare==0.7.5
-pillow==10.0.0
-pip==21.2.4
-platformdirs==2.6.2
-prompt-toolkit==3.0.36
-protobuf==3.20.3
-psutil==5.9.4
-ptyprocess==0.7.0
-pure-eval==0.2.2
-pygame==2.4.0
-pygments==2.14.0
-pyparsing==3.0.9
-python-dateutil==2.8.2
-pyyaml==6.0
-pyzmq==25.0.0
-requests==2.31.0
-sentry-sdk==1.28.0
-setproctitle==1.3.2
-setuptools==58.0.4
-six==1.15.0
-smmap==5.0.0
-stack-data==0.6.2
-sympy==1.12
-tensorboardx==2.6
-torch-ac==1.4.0
-torch==2.0.1
-tornado==6.2
-traitlets==5.8.1
-typing-extensions==4.6.3
-urllib3==2.0.3
-wandb==0.15.5
-wcwidth==0.2.6
-wheel==0.37.0
-zipp==3.15.0
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-metadata.json b/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-metadata.json
deleted file mode 100644
index 4a4ab9e..0000000
--- a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-metadata.json
+++ /dev/null
@@ -1,44 +0,0 @@
-{
-    "os": "macOS-13.4-arm64-arm-64bit",
-    "python": "3.9.6",
-    "heartbeatAt": "2023-07-26T15:45:57.827530",
-    "startedAt": "2023-07-26T15:45:56.899107",
-    "docker": null,
-    "cuda": null,
-    "args": [
-        "--algo",
-        "ppo",
-        "--env",
-        "MiniGrid-Empty-5x5-v0",
-        "--model",
-        "Empty",
-        "--save-interval",
-        "10",
-        "--frames",
-        "80000"
-    ],
-    "state": "running",
-    "program": "-m scripts.train",
-    "git": {
-        "remote": "https://github.com/CorinaCaraconcea/diversity_study.git",
-        "commit": "bbd28515d7e4bbc2bcc39a9deff9cc255775ca99"
-    },
-    "email": "cori.caraconcea@gmail.com",
-    "root": "/Users/corinacaraconcea/Downloads/diversity_study",
-    "host": "Corinas-MacBook-Air.local",
-    "username": "corinacaraconcea",
-    "executable": "/Library/Developer/CommandLineTools/usr/bin/python3",
-    "cpu_count": 8,
-    "cpu_count_logical": 8,
-    "disk": {
-        "total": 228.27386474609375,
-        "used": 8.95040512084961
-    },
-    "gpuapple": {
-        "type": "arm",
-        "vendor": "Apple"
-    },
-    "memory": {
-        "total": 8.0
-    }
-}
diff --git a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json b/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
deleted file mode 100644
index a1c480a..0000000
--- a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
+++ /dev/null
@@ -1 +0,0 @@
-{"external_return_per_episode": 0.9549331516027451, "_timestamp": 1690386410.61625, "_runtime": 53.69625806808472, "_step": 39, "_wandb": {"runtime": 52}}
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/logs/debug-internal.log b/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/logs/debug-internal.log
deleted file mode 100644
index 88a8e5c..0000000
--- a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/logs/debug-internal.log
+++ /dev/null
@@ -1,428 +0,0 @@
-2023-07-26 16:45:56,920 INFO    StreamThr :79885 [internal.py:wandb_internal():86] W&B internal server running at pid: 79885, started at: 2023-07-26 16:45:56.920305
-2023-07-26 16:45:56,921 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: status
-2023-07-26 16:45:56,925 INFO    WriterThread:79885 [datastore.py:open_for_write():85] open: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/run-hbzzliz3.wandb
-2023-07-26 16:45:56,926 DEBUG   SenderThread:79885 [sender.py:send():369] send: header
-2023-07-26 16:45:56,944 DEBUG   SenderThread:79885 [sender.py:send():369] send: run
-2023-07-26 16:45:57,585 INFO    SenderThread:79885 [dir_watcher.py:__init__():211] watching files in: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files
-2023-07-26 16:45:57,585 INFO    SenderThread:79885 [sender.py:_start_run_threads():1100] run started: hbzzliz3 with start time 1690386356.919992
-2023-07-26 16:45:57,587 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:45:57,587 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:45:57,589 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: check_version
-2023-07-26 16:45:57,590 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: check_version
-2023-07-26 16:45:57,818 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: run_start
-2023-07-26 16:45:57,826 DEBUG   HandlerThread:79885 [system_info.py:__init__():31] System info init
-2023-07-26 16:45:57,826 DEBUG   HandlerThread:79885 [system_info.py:__init__():46] System info init done
-2023-07-26 16:45:57,826 INFO    HandlerThread:79885 [system_monitor.py:start():181] Starting system monitor
-2023-07-26 16:45:57,826 INFO    SystemMonitor:79885 [system_monitor.py:_start():145] Starting system asset monitoring threads
-2023-07-26 16:45:57,826 INFO    HandlerThread:79885 [system_monitor.py:probe():201] Collecting system info
-2023-07-26 16:45:57,827 INFO    SystemMonitor:79885 [interfaces.py:start():190] Started cpu monitoring
-2023-07-26 16:45:57,827 DEBUG   HandlerThread:79885 [system_info.py:probe():195] Probing system
-2023-07-26 16:45:57,827 INFO    SystemMonitor:79885 [interfaces.py:start():190] Started disk monitoring
-2023-07-26 16:45:57,829 INFO    SystemMonitor:79885 [interfaces.py:start():190] Started gpuapple monitoring
-2023-07-26 16:45:57,831 INFO    SystemMonitor:79885 [interfaces.py:start():190] Started memory monitoring
-2023-07-26 16:45:57,831 INFO    SystemMonitor:79885 [interfaces.py:start():190] Started network monitoring
-2023-07-26 16:45:57,835 DEBUG   HandlerThread:79885 [system_info.py:_probe_git():180] Probing git
-2023-07-26 16:45:57,854 DEBUG   HandlerThread:79885 [system_info.py:_probe_git():188] Probing git done
-2023-07-26 16:45:57,855 DEBUG   HandlerThread:79885 [system_info.py:probe():240] Probing system done
-2023-07-26 16:45:57,855 DEBUG   HandlerThread:79885 [system_monitor.py:probe():210] {'os': 'macOS-13.4-arm64-arm-64bit', 'python': '3.9.6', 'heartbeatAt': '2023-07-26T15:45:57.827530', 'startedAt': '2023-07-26T15:45:56.899107', 'docker': None, 'cuda': None, 'args': ('--algo', 'ppo', '--env', 'MiniGrid-Empty-5x5-v0', '--model', 'Empty', '--save-interval', '10', '--frames', '80000'), 'state': 'running', 'program': '-m scripts.train', 'git': {'remote': 'https://github.com/CorinaCaraconcea/diversity_study.git', 'commit': 'bbd28515d7e4bbc2bcc39a9deff9cc255775ca99'}, 'email': 'cori.caraconcea@gmail.com', 'root': '/Users/corinacaraconcea/Downloads/diversity_study', 'host': 'Corinas-MacBook-Air.local', 'username': 'corinacaraconcea', 'executable': '/Library/Developer/CommandLineTools/usr/bin/python3', 'cpu_count': 8, 'cpu_count_logical': 8, 'disk': {'total': 228.27386474609375, 'used': 8.95040512084961}, 'gpuapple': {'type': 'arm', 'vendor': 'Apple'}, 'memory': {'total': 8.0}}
-2023-07-26 16:45:57,855 INFO    HandlerThread:79885 [system_monitor.py:probe():211] Finished collecting system info
-2023-07-26 16:45:57,855 INFO    HandlerThread:79885 [system_monitor.py:probe():214] Publishing system info
-2023-07-26 16:45:57,855 DEBUG   HandlerThread:79885 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment
-2023-07-26 16:45:57,855 DEBUG   HandlerThread:79885 [system_info.py:_save_pip():67] Saving pip packages done
-2023-07-26 16:45:57,855 DEBUG   HandlerThread:79885 [system_info.py:_save_code():89] Saving code
-2023-07-26 16:45:57,855 WARNING HandlerThread:79885 [system_info.py:_save_code():91] unable to save code -- program entry not found
-2023-07-26 16:45:57,855 DEBUG   HandlerThread:79885 [system_info.py:_save_patches():127] Saving git patches
-2023-07-26 16:45:57,906 DEBUG   HandlerThread:79885 [system_info.py:_save_patches():169] Saving git patches done
-2023-07-26 16:45:57,907 INFO    HandlerThread:79885 [system_monitor.py:probe():216] Finished publishing system info
-2023-07-26 16:45:57,910 DEBUG   SenderThread:79885 [sender.py:send():369] send: files
-2023-07-26 16:45:57,910 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-metadata.json with policy now
-2023-07-26 16:45:57,910 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file diff.patch with policy now
-2023-07-26 16:45:57,918 DEBUG   SenderThread:79885 [sender.py:send():369] send: telemetry
-2023-07-26 16:45:57,918 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:45:57,919 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:45:58,443 INFO    wandb-upload_0:79885 [upload_job.py:push():133] Uploaded file /var/folders/n4/lk2x7f1j3g35spnvp796gmx40000gn/T/tmpp3l7sfefwandb/qt5gunv7-wandb-metadata.json
-2023-07-26 16:45:58,537 INFO    wandb-upload_1:79885 [upload_job.py:push():133] Uploaded file /var/folders/n4/lk2x7f1j3g35spnvp796gmx40000gn/T/tmpp3l7sfefwandb/wpjf598c-diff.patch
-2023-07-26 16:45:58,590 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/requirements.txt
-2023-07-26 16:45:58,590 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:45:58,590 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-metadata.json
-2023-07-26 16:45:58,590 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:45:58,590 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/diff.patch
-2023-07-26 16:45:59,319 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:45:59,320 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:45:59,320 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:45:59,320 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:45:59,594 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:00,570 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:00,572 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:00,572 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:00,573 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:00,595 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:00,595 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:01,851 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:01,852 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:01,852 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:01,852 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:02,066 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:46:02,606 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:02,606 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:03,119 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:03,120 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:03,120 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:03,121 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:03,611 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:04,376 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:04,377 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:04,377 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:04,377 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:04,616 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:04,616 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:05,661 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:05,662 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:05,662 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:05,662 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:06,627 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:06,627 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:06,933 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:06,934 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:06,934 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:06,934 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:07,140 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:46:07,632 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:08,206 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:08,207 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:08,207 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:08,208 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:08,637 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:08,637 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:09,507 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:09,507 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:09,507 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:09,508 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:09,642 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:10,648 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:10,796 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:10,797 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:10,797 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:10,798 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:11,653 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:12,092 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:12,093 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:12,093 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:12,093 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:12,306 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:46:12,659 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:12,659 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:12,918 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:46:12,918 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:46:13,408 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:13,408 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:13,409 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:13,409 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:13,664 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:14,667 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:14,720 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:14,721 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:14,721 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:14,721 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:15,672 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:16,020 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:16,021 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:16,021 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:16,021 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:16,678 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:16,678 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:17,346 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:17,347 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:17,347 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:17,347 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:46:17,348 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:17,683 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:18,648 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:18,649 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:18,649 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:18,649 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:18,687 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:18,688 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:19,956 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:19,957 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:19,957 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:19,957 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:20,696 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:20,696 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:21,266 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:21,267 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:21,267 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:21,267 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:21,701 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:22,583 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:46:22,706 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:22,799 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:22,800 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:22,800 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:22,801 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:23,712 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:24,127 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:24,128 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:24,128 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:24,129 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:24,717 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:24,718 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:25,421 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:25,422 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:25,422 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:25,422 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:25,723 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:26,728 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:26,736 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:26,737 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:26,737 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:26,738 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:27,733 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:27,918 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:46:27,919 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:46:28,046 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:28,189 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:46:28,626 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:28,626 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:28,627 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:28,739 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:28,739 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:28,739 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/config.yaml
-2023-07-26 16:46:29,341 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:29,342 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:29,342 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:29,343 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:29,744 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:30,627 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:30,627 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:30,627 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:30,628 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:30,747 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:30,747 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:32,013 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:32,015 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:32,015 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:32,015 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:32,758 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:32,758 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:33,312 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:33,313 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:33,313 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:33,313 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:33,763 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:34,532 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:46:34,618 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:34,618 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:34,618 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:34,619 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:34,764 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:34,764 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:35,930 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:35,932 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:35,932 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:35,933 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:36,774 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:36,775 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:37,185 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:37,185 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:37,185 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:37,186 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:37,780 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:38,503 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:38,504 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:38,504 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:38,504 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:38,785 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:38,785 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:39,724 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:46:39,835 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:39,836 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:39,836 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:39,836 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:40,798 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:40,800 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:41,227 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:41,228 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:41,228 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:41,229 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:41,799 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:42,482 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:42,482 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:42,483 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:42,483 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:42,805 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:42,805 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:42,924 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:46:42,924 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:46:43,884 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:43,885 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:43,885 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:43,886 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:44,815 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:44,815 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:45,117 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:46:45,205 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:45,206 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:45,206 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:45,206 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:45,820 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:46,537 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:46,538 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:46,538 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:46,538 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:46,825 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:46,826 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:47,827 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:47,828 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:47,829 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:47,829 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:47,830 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:48,833 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:49,073 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:49,074 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:49,074 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:49,074 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:49,839 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:50,384 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:46:50,617 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:46:50,618 DEBUG   SenderThread:79885 [sender.py:send():369] send: history
-2023-07-26 16:46:50,618 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:46:50,619 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:50,626 DEBUG   SenderThread:79885 [sender.py:send():369] send: exit
-2023-07-26 16:46:50,626 INFO    SenderThread:79885 [sender.py:send_exit():574] handling exit code: 0
-2023-07-26 16:46:50,626 INFO    SenderThread:79885 [sender.py:send_exit():576] handling runtime: 52
-2023-07-26 16:46:50,626 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:50,627 INFO    SenderThread:79885 [sender.py:send_exit():582] send defer
-2023-07-26 16:46:50,627 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:50,627 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 0
-2023-07-26 16:46:50,627 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:50,627 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 0
-2023-07-26 16:46:50,627 INFO    SenderThread:79885 [sender.py:transition_state():602] send defer: 1
-2023-07-26 16:46:50,627 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:50,627 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 1
-2023-07-26 16:46:50,627 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:50,627 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 1
-2023-07-26 16:46:50,627 INFO    SenderThread:79885 [sender.py:transition_state():602] send defer: 2
-2023-07-26 16:46:50,627 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:50,627 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 2
-2023-07-26 16:46:50,627 INFO    HandlerThread:79885 [system_monitor.py:finish():190] Stopping system monitor
-2023-07-26 16:46:50,627 DEBUG   SystemMonitor:79885 [system_monitor.py:_start():159] Starting system metrics aggregation loop
-2023-07-26 16:46:50,627 INFO    HandlerThread:79885 [interfaces.py:finish():202] Joined cpu monitor
-2023-07-26 16:46:50,627 DEBUG   SystemMonitor:79885 [system_monitor.py:_start():166] Finished system metrics aggregation loop
-2023-07-26 16:46:50,627 INFO    HandlerThread:79885 [interfaces.py:finish():202] Joined disk monitor
-2023-07-26 16:46:50,627 DEBUG   SystemMonitor:79885 [system_monitor.py:_start():170] Publishing last batch of metrics
-2023-07-26 16:46:50,627 INFO    HandlerThread:79885 [interfaces.py:finish():202] Joined gpuapple monitor
-2023-07-26 16:46:50,628 INFO    HandlerThread:79885 [interfaces.py:finish():202] Joined memory monitor
-2023-07-26 16:46:50,628 INFO    HandlerThread:79885 [interfaces.py:finish():202] Joined network monitor
-2023-07-26 16:46:50,629 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:50,629 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 2
-2023-07-26 16:46:50,629 INFO    SenderThread:79885 [sender.py:transition_state():602] send defer: 3
-2023-07-26 16:46:50,629 DEBUG   SenderThread:79885 [sender.py:send():369] send: telemetry
-2023-07-26 16:46:50,629 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:50,629 DEBUG   SenderThread:79885 [sender.py:send():369] send: stats
-2023-07-26 16:46:50,629 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 3
-2023-07-26 16:46:50,629 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:50,629 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 3
-2023-07-26 16:46:50,629 INFO    SenderThread:79885 [sender.py:transition_state():602] send defer: 4
-2023-07-26 16:46:50,629 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:50,629 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 4
-2023-07-26 16:46:50,629 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:50,629 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 4
-2023-07-26 16:46:50,629 INFO    SenderThread:79885 [sender.py:transition_state():602] send defer: 5
-2023-07-26 16:46:50,629 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:50,629 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 5
-2023-07-26 16:46:50,630 DEBUG   SenderThread:79885 [sender.py:send():369] send: summary
-2023-07-26 16:46:50,630 INFO    SenderThread:79885 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:46:50,630 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:50,630 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 5
-2023-07-26 16:46:50,630 INFO    SenderThread:79885 [sender.py:transition_state():602] send defer: 6
-2023-07-26 16:46:50,630 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:50,630 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 6
-2023-07-26 16:46:50,630 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:50,630 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 6
-2023-07-26 16:46:50,636 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:46:50,845 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:50,845 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:50,968 INFO    SenderThread:79885 [sender.py:transition_state():602] send defer: 7
-2023-07-26 16:46:50,969 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:50,969 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 7
-2023-07-26 16:46:50,970 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:50,972 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 7
-2023-07-26 16:46:51,632 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: poll_exit
-2023-07-26 16:46:51,846 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/config.yaml
-2023-07-26 16:46:52,374 INFO    SenderThread:79885 [sender.py:transition_state():602] send defer: 8
-2023-07-26 16:46:52,374 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: poll_exit
-2023-07-26 16:46:52,374 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:52,376 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 8
-2023-07-26 16:46:52,377 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:52,377 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 8
-2023-07-26 16:46:52,378 INFO    SenderThread:79885 [job_builder.py:build():240] Attempting to build job artifact
-2023-07-26 16:46:52,379 INFO    SenderThread:79885 [job_builder.py:build():274] no source found
-2023-07-26 16:46:52,379 INFO    SenderThread:79885 [sender.py:transition_state():602] send defer: 9
-2023-07-26 16:46:52,379 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:52,379 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 9
-2023-07-26 16:46:52,380 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:52,380 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 9
-2023-07-26 16:46:52,380 INFO    SenderThread:79885 [dir_watcher.py:finish():359] shutting down directory watcher
-2023-07-26 16:46:52,634 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: poll_exit
-2023-07-26 16:46:52,848 INFO    Thread-12 :79885 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:52,868 INFO    SenderThread:79885 [dir_watcher.py:finish():389] scan: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files
-2023-07-26 16:46:52,869 INFO    SenderThread:79885 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/diff.patch diff.patch
-2023-07-26 16:46:52,869 INFO    SenderThread:79885 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/requirements.txt requirements.txt
-2023-07-26 16:46:52,869 INFO    SenderThread:79885 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log output.log
-2023-07-26 16:46:52,869 INFO    SenderThread:79885 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/config.yaml config.yaml
-2023-07-26 16:46:52,872 INFO    SenderThread:79885 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json wandb-summary.json
-2023-07-26 16:46:52,874 INFO    SenderThread:79885 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-metadata.json wandb-metadata.json
-2023-07-26 16:46:52,874 INFO    SenderThread:79885 [sender.py:transition_state():602] send defer: 10
-2023-07-26 16:46:52,875 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: poll_exit
-2023-07-26 16:46:52,875 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:52,878 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 10
-2023-07-26 16:46:52,880 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:52,880 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 10
-2023-07-26 16:46:52,880 INFO    SenderThread:79885 [file_pusher.py:finish():159] shutting down file pusher
-2023-07-26 16:46:53,293 INFO    wandb-upload_0:79885 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/requirements.txt
-2023-07-26 16:46:53,310 INFO    wandb-upload_2:79885 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/config.yaml
-2023-07-26 16:46:53,430 INFO    wandb-upload_1:79885 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/output.log
-2023-07-26 16:46:53,510 INFO    wandb-upload_3:79885 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/files/wandb-summary.json
-2023-07-26 16:46:53,637 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: poll_exit
-2023-07-26 16:46:53,638 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: poll_exit
-2023-07-26 16:46:53,716 INFO    Thread-11 :79885 [sender.py:transition_state():602] send defer: 11
-2023-07-26 16:46:53,716 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:53,717 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 11
-2023-07-26 16:46:53,717 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:53,717 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 11
-2023-07-26 16:46:53,718 INFO    SenderThread:79885 [file_pusher.py:join():164] waiting for file pusher
-2023-07-26 16:46:53,718 INFO    SenderThread:79885 [sender.py:transition_state():602] send defer: 12
-2023-07-26 16:46:53,718 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:53,718 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 12
-2023-07-26 16:46:53,718 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:53,719 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 12
-2023-07-26 16:46:53,928 INFO    SenderThread:79885 [sender.py:transition_state():602] send defer: 13
-2023-07-26 16:46:53,929 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:53,930 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 13
-2023-07-26 16:46:53,931 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:53,931 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 13
-2023-07-26 16:46:53,932 INFO    SenderThread:79885 [sender.py:transition_state():602] send defer: 14
-2023-07-26 16:46:53,932 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:46:53,932 INFO    HandlerThread:79885 [handler.py:handle_request_defer():170] handle defer: 14
-2023-07-26 16:46:53,933 DEBUG   SenderThread:79885 [sender.py:send():369] send: final
-2023-07-26 16:46:53,933 DEBUG   SenderThread:79885 [sender.py:send():369] send: footer
-2023-07-26 16:46:53,934 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:46:53,934 INFO    SenderThread:79885 [sender.py:send_request_defer():598] handle sender defer: 14
-2023-07-26 16:46:53,939 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: poll_exit
-2023-07-26 16:46:53,939 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: poll_exit
-2023-07-26 16:46:53,939 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: server_info
-2023-07-26 16:46:53,939 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: get_summary
-2023-07-26 16:46:53,939 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: sampled_history
-2023-07-26 16:46:53,941 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: poll_exit
-2023-07-26 16:46:53,941 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: poll_exit
-2023-07-26 16:46:53,941 DEBUG   SenderThread:79885 [sender.py:send_request():396] send_request: server_info
-2023-07-26 16:46:54,223 INFO    MainThread:79885 [wandb_run.py:_footer_history_summary_info():3464] rendering history
-2023-07-26 16:46:54,224 INFO    MainThread:79885 [wandb_run.py:_footer_history_summary_info():3496] rendering summary
-2023-07-26 16:46:54,225 INFO    MainThread:79885 [wandb_run.py:_footer_sync_info():3423] logging synced files
-2023-07-26 16:46:54,228 DEBUG   HandlerThread:79885 [handler.py:handle_request():144] handle_request: shutdown
-2023-07-26 16:46:54,228 INFO    HandlerThread:79885 [handler.py:finish():854] shutting down handler
-2023-07-26 16:46:54,946 INFO    WriterThread:79885 [datastore.py:close():298] close: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/run-hbzzliz3.wandb
-2023-07-26 16:46:55,228 INFO    SenderThread:79885 [sender.py:finish():1526] shutting down sender
-2023-07-26 16:46:55,229 INFO    SenderThread:79885 [file_pusher.py:finish():159] shutting down file pusher
-2023-07-26 16:46:55,229 INFO    SenderThread:79885 [file_pusher.py:join():164] waiting for file pusher
diff --git a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/logs/debug.log b/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/logs/debug.log
deleted file mode 100644
index 91053c8..0000000
--- a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/logs/debug.log
+++ /dev/null
@@ -1,29 +0,0 @@
-2023-07-26 16:45:56,902 INFO    MainThread:79859 [wandb_setup.py:_flush():76] Current SDK version is 0.15.5
-2023-07-26 16:45:56,902 INFO    MainThread:79859 [wandb_setup.py:_flush():76] Configure stats pid to 79859
-2023-07-26 16:45:56,902 INFO    MainThread:79859 [wandb_setup.py:_flush():76] Loading settings from /Users/corinacaraconcea/.config/wandb/settings
-2023-07-26 16:45:56,902 INFO    MainThread:79859 [wandb_setup.py:_flush():76] Loading settings from /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/settings
-2023-07-26 16:45:56,902 INFO    MainThread:79859 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
-2023-07-26 16:45:56,902 INFO    MainThread:79859 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
-2023-07-26 16:45:56,902 WARNING MainThread:79859 [wandb_setup.py:_flush():76] Could not find program at -m scripts.train
-2023-07-26 16:45:56,902 INFO    MainThread:79859 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': None, 'program': '-m scripts.train'}
-2023-07-26 16:45:56,902 INFO    MainThread:79859 [wandb_init.py:_log_setup():507] Logging user logs to /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/logs/debug.log
-2023-07-26 16:45:56,902 INFO    MainThread:79859 [wandb_init.py:_log_setup():508] Logging internal logs to /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/logs/debug-internal.log
-2023-07-26 16:45:56,903 INFO    MainThread:79859 [wandb_init.py:init():547] calling init triggers
-2023-07-26 16:45:56,903 INFO    MainThread:79859 [wandb_init.py:init():554] wandb.init called with sweep_config: {}
-config: {'model': '', 'performance metric': 'extrinsic reward'}
-2023-07-26 16:45:56,903 INFO    MainThread:79859 [wandb_init.py:init():596] starting backend
-2023-07-26 16:45:56,903 INFO    MainThread:79859 [wandb_init.py:init():600] setting up manager
-2023-07-26 16:45:56,915 INFO    MainThread:79859 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
-2023-07-26 16:45:56,919 INFO    MainThread:79859 [wandb_init.py:init():606] backend started and connected
-2023-07-26 16:45:56,925 INFO    MainThread:79859 [wandb_init.py:init():705] updated telemetry
-2023-07-26 16:45:56,942 INFO    MainThread:79859 [wandb_init.py:init():738] communicating run to backend with 60.0 second timeout
-2023-07-26 16:45:57,589 INFO    MainThread:79859 [wandb_run.py:_on_init():2173] communicating current version
-2023-07-26 16:45:57,799 INFO    MainThread:79859 [wandb_run.py:_on_init():2182] got version response upgrade_message: "wandb version 0.15.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
-
-2023-07-26 16:45:57,799 INFO    MainThread:79859 [wandb_init.py:init():789] starting run threads in backend
-2023-07-26 16:45:57,915 INFO    MainThread:79859 [wandb_run.py:_console_start():2152] atexit reg
-2023-07-26 16:45:57,915 INFO    MainThread:79859 [wandb_run.py:_redirect():2007] redirect: SettingsConsole.WRAP_RAW
-2023-07-26 16:45:57,915 INFO    MainThread:79859 [wandb_run.py:_redirect():2072] Wrapping output streams.
-2023-07-26 16:45:57,915 INFO    MainThread:79859 [wandb_run.py:_redirect():2097] Redirects installed.
-2023-07-26 16:45:57,917 INFO    MainThread:79859 [wandb_init.py:init():830] run started, returning control to user process
-2023-07-26 16:46:55,354 WARNING MsgRouterThr:79859 [router.py:message_loop():77] message_loop has been closed
diff --git a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/run-hbzzliz3.wandb b/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/run-hbzzliz3.wandb
deleted file mode 100644
index 46dde9b..0000000
Binary files a/rl-starter-files/wandb/run-20230726_164556-hbzzliz3/run-hbzzliz3.wandb and /dev/null differ
diff --git a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/config.yaml b/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/config.yaml
deleted file mode 100644
index 476967f..0000000
--- a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/config.yaml
+++ /dev/null
@@ -1,32 +0,0 @@
-wandb_version: 1
-
-model:
-  desc: null
-  value: ''
-performance metric:
-  desc: null
-  value: extrinsic reward
-_wandb:
-  desc: null
-  value:
-    python_version: 3.9.6
-    cli_version: 0.15.5
-    framework: torch
-    is_jupyter_run: false
-    is_kaggle_kernel: false
-    start_time: 1690386917.421957
-    t:
-      1:
-      - 1
-      - 55
-      2:
-      - 1
-      - 55
-      3:
-      - 16
-      - 23
-      4: 3.9.6
-      5: 0.15.5
-      8:
-      - 4
-      - 5
diff --git a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/diff.patch b/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/diff.patch
deleted file mode 100644
index 2f82b2f..0000000
--- a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/diff.patch
+++ /dev/null
@@ -1,81 +0,0 @@
-diff --git a/rl-starter-files/scripts/train.py b/rl-starter-files/scripts/train.py
-index 6b1b0c6..51ef539 100644
---- a/rl-starter-files/scripts/train.py
-+++ b/rl-starter-files/scripts/train.py
-@@ -19,6 +19,10 @@ sys.path.insert(0, os.path.abspath('/Users/corinacaraconcea/Documents/UCL DSML/M
- import a2c
- import ppo
- 
-+from Minigrid.minigrid.__init__ import register_minigrid_envs
-+
-+register_minigrid_envs()
-+
- # Parse arguments
- 
- #The argparse module is a standard Python library for writing user-friendly command-line interfaces.
-@@ -70,7 +74,7 @@ parser.add_argument("--optim-alpha", type=float, default=0.99,
-                     help="RMSprop optimizer alpha (default: 0.99)")
- parser.add_argument("--clip-eps", type=float, default=0.2,
-                     help="clipping epsilon for PPO (default: 0.2)")
--parser.add_argument("--recurrence", type=int, default=2,
-+parser.add_argument("--recurrence", type=int, default=1,
-                     help="number of time-steps gradient is backpropagated (default: 1). If > 1, a LSTM is added to the model to have memory.")
- parser.add_argument("--text", action="store_true", default=False,
-                     help="add a GRU to the model to handle text input")
-@@ -313,15 +317,15 @@ if __name__ == "__main__":
- 
-         # Save status
- 
--        # if args.save_interval > 0 and update % args.save_interval == 0:
--        #     status_base = {"model_name": "ACmodel","num_frames": num_frames, "update": update,
--        #               "model_state": acmodel.state_dict(), "optimizer_state": algo.optimizer.state_dict()}
--        #     if hasattr(preprocess_obss, "vocab"):
--        #         status_base["vocab"] = preprocess_obss.vocab.vocab
--        #     utils.save_status(status_base,model_flag, model_dir)
--        #     txt_logger.info("Status saved")
-+        if args.save_interval > 0 and update % args.save_interval == 0:
-+            status_base = {"model_name": "ACmodel","num_frames": num_frames, "update": update,
-+                      "model_state": acmodel.state_dict(), "optimizer_state": algo.optimizer.state_dict()}
-+            if hasattr(preprocess_obss, "vocab"):
-+                status_base["vocab"] = preprocess_obss.vocab.vocab
-+            utils.save_status(status_base,model_flag, model_dir)
-+            txt_logger.info("Status saved")
- 
--        # Save status rnd
-+        # Save status rn
- 
-         # if args.save_interval > 0 and update % args.save_interval == 0:
-         #     status_rnd = {"model_name": "RNDmodel","num_frames": num_frames, "update": update,
-diff --git a/rl-starter-files/scripts/visualize.py b/rl-starter-files/scripts/visualize.py
-index dd28d0b..fb3150a 100644
---- a/rl-starter-files/scripts/visualize.py
-+++ b/rl-starter-files/scripts/visualize.py
-@@ -4,6 +4,9 @@ import numpy
- import utils
- from utils import device
- 
-+from Minigrid.minigrid.__init__ import register_minigrid_envs
-+
-+register_minigrid_envs()
- 
- # Parse arguments
- 
-@@ -49,7 +52,8 @@ print("Environment loaded\n")
- # Load agent
- 
- model_dir = utils.get_model_dir(args.model)
--agent = utils.Agent(env.observation_space, env.action_space, model_dir,
-+print("model directory path", model_dir)
-+agent = utils.Agent(env.observation_space, env.action_space, "" , model_dir,
-                     argmax=args.argmax, use_memory=args.memory, use_text=args.text)
- print("Agent loaded\n")
- 
-diff --git a/rl-starter-files/utils/env.py b/rl-starter-files/utils/env.py
-index fa4f36d..24b9b4b 100644
---- a/rl-starter-files/utils/env.py
-+++ b/rl-starter-files/utils/env.py
-@@ -5,3 +5,4 @@ def make_env(env_key, seed=None, render_mode=None):
-     env = gym.make(env_key, render_mode=render_mode)
-     env.reset(seed=seed)
-     return env
-+
diff --git a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log b/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
deleted file mode 100644
index 3a14291..0000000
--- a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
+++ /dev/null
@@ -1,84 +0,0 @@
-log_done_counter 0
-U 1 | F 0000002048 | FPS 1636 | D 1 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 0.0 0.0 0 0 | H 1.904 | V -0.093 | pL -0.015 | vL 0.001 | ∇ 0.034
-log_done_counter 16
-U 2 | F 0000004096 | FPS 1739 | D 2 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.867 | V -0.076 | pL -0.020 | vL 0.000 | ∇ 0.015
-log_done_counter 16
-U 3 | F 0000006144 | FPS 1758 | D 3 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.878 | V -0.057 | pL -0.017 | vL 0.000 | ∇ 0.007
-log_done_counter 16
-U 4 | F 0000008192 | FPS 1719 | D 4 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.841 | V -0.042 | pL -0.013 | vL 0.000 | ∇ 0.006
-log_done_counter 16
-U 5 | F 0000010240 | FPS 1581 | D 6 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.863 | V -0.032 | pL -0.011 | vL 0.000 | ∇ 0.007
-log_done_counter 16
-U 6 | F 0000012288 | FPS 1753 | D 7 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.883 | V -0.023 | pL -0.008 | vL 0.000 | ∇ 0.006
-log_done_counter 16
-U 7 | F 0000014336 | FPS 1790 | D 8 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.900 | V -0.018 | pL -0.006 | vL 0.000 | ∇ 0.005
-log_done_counter 16
-U 8 | F 0000016384 | FPS 1831 | D 9 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.912 | V -0.014 | pL -0.005 | vL 0.000 | ∇ 0.003
-log_done_counter 16
-U 9 | F 0000018432 | FPS 1774 | D 10 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.911 | V -0.009 | pL -0.003 | vL 0.000 | ∇ 0.002
-log_done_counter 16
-U 10 | F 0000020480 | FPS 1796 | D 11 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.922 | V -0.007 | pL -0.003 | vL 0.000 | ∇ 0.002
-Status saved
-log_done_counter 16
-U 11 | F 0000022528 | FPS 1765 | D 13 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.930 | V -0.004 | pL -0.002 | vL 0.000 | ∇ 0.002
-log_done_counter 0
-U 12 | F 0000024576 | FPS 1754 | D 14 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.937 | V -0.004 | pL -0.001 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 13 | F 0000026624 | FPS 1768 | D 15 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.939 | V -0.003 | pL -0.001 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 14 | F 0000028672 | FPS 1686 | D 16 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.940 | V -0.002 | pL -0.001 | vL 0.000 | ∇ 0.002
-log_done_counter 16
-U 15 | F 0000030720 | FPS 1762 | D 17 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.940 | V -0.002 | pL -0.001 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 16 | F 0000032768 | FPS 1779 | D 18 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.937 | V -0.002 | pL -0.001 | vL 0.000 | ∇ 0.002
-log_done_counter 16
-U 17 | F 0000034816 | FPS 1781 | D 20 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.939 | V -0.002 | pL -0.001 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 18 | F 0000036864 | FPS 1775 | D 21 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.938 | V -0.002 | pL -0.001 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 19 | F 0000038912 | FPS 1788 | D 22 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.936 | V -0.001 | pL -0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 20 | F 0000040960 | FPS 1763 | D 23 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.938 | V -0.001 | pL -0.000 | vL 0.000 | ∇ 0.001
-Status saved
-log_done_counter 16
-U 21 | F 0000043008 | FPS 1738 | D 24 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.937 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 22 | F 0000045056 | FPS 1841 | D 25 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.935 | V -0.000 | pL 0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 23 | F 0000047104 | FPS 1829 | D 26 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.933 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 0
-U 24 | F 0000049152 | FPS 1729 | D 28 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.936 | V -0.000 | pL 0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 25 | F 0000051200 | FPS 1767 | D 29 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.938 | V -0.001 | pL -0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 26 | F 0000053248 | FPS 1751 | D 30 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.939 | V -0.000 | pL -0.000 | vL 0.000 | ∇ 0.002
-log_done_counter 16
-U 27 | F 0000055296 | FPS 1745 | D 31 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.939 | V 0.001 | pL 0.001 | vL 0.000 | ∇ 0.002
-log_done_counter 16
-U 28 | F 0000057344 | FPS 1603 | D 32 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.934 | V 0.002 | pL 0.001 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 29 | F 0000059392 | FPS 1741 | D 34 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.938 | V 0.001 | pL 0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 30 | F 0000061440 | FPS 1839 | D 35 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.938 | V 0.001 | pL 0.000 | vL 0.000 | ∇ 0.001
-Status saved
-log_done_counter 16
-U 31 | F 0000063488 | FPS 1743 | D 36 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.939 | V 0.001 | pL 0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 32 | F 0000065536 | FPS 1653 | D 37 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.938 | V 0.001 | pL 0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 33 | F 0000067584 | FPS 1647 | D 38 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.939 | V 0.001 | pL 0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 34 | F 0000069632 | FPS 1826 | D 39 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.938 | V 0.001 | pL 0.000 | vL 0.000 | ∇ 0.000
-log_done_counter 16
-U 35 | F 0000071680 | FPS 1577 | D 41 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.940 | V 0.001 | pL 0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 0
-U 36 | F 0000073728 | FPS 1482 | D 42 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.941 | V 0.001 | pL 0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 37 | F 0000075776 | FPS 1644 | D 43 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.940 | V 0.001 | pL 0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 38 | F 0000077824 | FPS 1885 | D 45 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.940 | V 0.001 | pL 0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 39 | F 0000079872 | FPS 1812 | D 46 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.941 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.001
-log_done_counter 16
-U 40 | F 0000081920 | FPS 1498 | D 47 | rR:μσmM 0.00 0.00 0.00 0.00 | F:μσmM 140.0 0.0 140.0 140.0 | H 1.942 | V 0.000 | pL 0.000 | vL 0.000 | ∇ 0.000
-Status saved
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/requirements.txt b/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/requirements.txt
deleted file mode 100644
index 05458c5..0000000
--- a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/requirements.txt
+++ /dev/null
@@ -1,85 +0,0 @@
-altgraph==0.17.2
-appdirs==1.4.4
-appnope==0.1.3
-asttokens==2.2.1
-backcall==0.2.0
-certifi==2023.5.7
-charset-normalizer==3.2.0
-click==8.1.4
-cloudpickle==2.2.1
-comm==0.1.2
-contourpy==1.1.0
-cycler==0.11.0
-debugpy==1.6.5
-decorator==5.1.1
-docker-pycreds==0.4.0
-entrypoints==0.4
-executing==1.2.0
-farama-notifications==0.0.4
-filelock==3.12.2
-fonttools==4.40.0
-future==0.18.2
-gitdb==4.0.10
-gitpython==3.1.31
-gym-minigrid==1.2.2
-gym-notices==0.0.8
-gym==0.26.2
-gymnasium==0.28.1
-idna==3.4
-importlib-metadata==6.6.0
-importlib-resources==6.0.0
-ipykernel==6.20.2
-ipython==8.8.0
-jax-jumpy==1.0.0
-jedi==0.18.2
-jinja2==3.1.2
-jupyter-client==7.4.9
-jupyter-core==5.1.3
-kiwisolver==1.4.4
-macholib==1.15.2
-markupsafe==2.1.3
-matplotlib-inline==0.1.6
-matplotlib==3.7.2
-minigrid==2.3.0
-mpmath==1.3.0
-nest-asyncio==1.5.6
-networkx==3.1
-numpy==1.24.3
-packaging==23.0
-parso==0.8.3
-pathtools==0.1.2
-pexpect==4.8.0
-pickleshare==0.7.5
-pillow==10.0.0
-pip==21.2.4
-platformdirs==2.6.2
-prompt-toolkit==3.0.36
-protobuf==3.20.3
-psutil==5.9.4
-ptyprocess==0.7.0
-pure-eval==0.2.2
-pygame==2.4.0
-pygments==2.14.0
-pyparsing==3.0.9
-python-dateutil==2.8.2
-pyyaml==6.0
-pyzmq==25.0.0
-requests==2.31.0
-sentry-sdk==1.28.0
-setproctitle==1.3.2
-setuptools==58.0.4
-six==1.15.0
-smmap==5.0.0
-stack-data==0.6.2
-sympy==1.12
-tensorboardx==2.6
-torch-ac==1.4.0
-torch==2.0.1
-tornado==6.2
-traitlets==5.8.1
-typing-extensions==4.6.3
-urllib3==2.0.3
-wandb==0.15.5
-wcwidth==0.2.6
-wheel==0.37.0
-zipp==3.15.0
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-metadata.json b/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-metadata.json
deleted file mode 100644
index 3c365d4..0000000
--- a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-metadata.json
+++ /dev/null
@@ -1,44 +0,0 @@
-{
-    "os": "macOS-13.4-arm64-arm-64bit",
-    "python": "3.9.6",
-    "heartbeatAt": "2023-07-26T15:55:18.073958",
-    "startedAt": "2023-07-26T15:55:17.408823",
-    "docker": null,
-    "cuda": null,
-    "args": [
-        "--algo",
-        "ppo",
-        "--env",
-        "MiniGrid-MultiRoom-N7-S4-v0",
-        "--model",
-        "Multiroom",
-        "--save-interval",
-        "10",
-        "--frames",
-        "80000"
-    ],
-    "state": "running",
-    "program": "-m scripts.train",
-    "git": {
-        "remote": "https://github.com/CorinaCaraconcea/diversity_study.git",
-        "commit": "bbd28515d7e4bbc2bcc39a9deff9cc255775ca99"
-    },
-    "email": "cori.caraconcea@gmail.com",
-    "root": "/Users/corinacaraconcea/Downloads/diversity_study",
-    "host": "Corinas-MacBook-Air.local",
-    "username": "corinacaraconcea",
-    "executable": "/Library/Developer/CommandLineTools/usr/bin/python3",
-    "cpu_count": 8,
-    "cpu_count_logical": 8,
-    "disk": {
-        "total": 228.27386474609375,
-        "used": 8.95040512084961
-    },
-    "gpuapple": {
-        "type": "arm",
-        "vendor": "Apple"
-    },
-    "memory": {
-        "total": 8.0
-    }
-}
diff --git a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json b/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
deleted file mode 100644
index e630e24..0000000
--- a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
+++ /dev/null
@@ -1 +0,0 @@
-{"external_return_per_episode": 0.0, "_timestamp": 1690386965.6772301, "_runtime": 48.25527310371399, "_step": 39, "_wandb": {"runtime": 47}}
\ No newline at end of file
diff --git a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/logs/debug-internal.log b/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/logs/debug-internal.log
deleted file mode 100644
index 9d30d53..0000000
--- a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/logs/debug-internal.log
+++ /dev/null
@@ -1,421 +0,0 @@
-2023-07-26 16:55:17,422 INFO    StreamThr :80902 [internal.py:wandb_internal():86] W&B internal server running at pid: 80902, started at: 2023-07-26 16:55:17.422256
-2023-07-26 16:55:17,423 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: status
-2023-07-26 16:55:17,429 INFO    WriterThread:80902 [datastore.py:open_for_write():85] open: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/run-22z3wkhd.wandb
-2023-07-26 16:55:17,430 DEBUG   SenderThread:80902 [sender.py:send():369] send: header
-2023-07-26 16:55:17,449 DEBUG   SenderThread:80902 [sender.py:send():369] send: run
-2023-07-26 16:55:17,939 INFO    SenderThread:80902 [dir_watcher.py:__init__():211] watching files in: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files
-2023-07-26 16:55:17,939 INFO    SenderThread:80902 [sender.py:_start_run_threads():1100] run started: 22z3wkhd with start time 1690386917.421957
-2023-07-26 16:55:17,940 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:17,941 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:17,943 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: check_version
-2023-07-26 16:55:17,943 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: check_version
-2023-07-26 16:55:18,067 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: run_start
-2023-07-26 16:55:18,072 DEBUG   HandlerThread:80902 [system_info.py:__init__():31] System info init
-2023-07-26 16:55:18,073 DEBUG   HandlerThread:80902 [system_info.py:__init__():46] System info init done
-2023-07-26 16:55:18,073 INFO    HandlerThread:80902 [system_monitor.py:start():181] Starting system monitor
-2023-07-26 16:55:18,073 INFO    SystemMonitor:80902 [system_monitor.py:_start():145] Starting system asset monitoring threads
-2023-07-26 16:55:18,073 INFO    HandlerThread:80902 [system_monitor.py:probe():201] Collecting system info
-2023-07-26 16:55:18,073 INFO    SystemMonitor:80902 [interfaces.py:start():190] Started cpu monitoring
-2023-07-26 16:55:18,073 DEBUG   HandlerThread:80902 [system_info.py:probe():195] Probing system
-2023-07-26 16:55:18,073 INFO    SystemMonitor:80902 [interfaces.py:start():190] Started disk monitoring
-2023-07-26 16:55:18,075 INFO    SystemMonitor:80902 [interfaces.py:start():190] Started gpuapple monitoring
-2023-07-26 16:55:18,076 INFO    SystemMonitor:80902 [interfaces.py:start():190] Started memory monitoring
-2023-07-26 16:55:18,076 INFO    SystemMonitor:80902 [interfaces.py:start():190] Started network monitoring
-2023-07-26 16:55:18,079 DEBUG   HandlerThread:80902 [system_info.py:_probe_git():180] Probing git
-2023-07-26 16:55:18,095 DEBUG   HandlerThread:80902 [system_info.py:_probe_git():188] Probing git done
-2023-07-26 16:55:18,095 DEBUG   HandlerThread:80902 [system_info.py:probe():240] Probing system done
-2023-07-26 16:55:18,095 DEBUG   HandlerThread:80902 [system_monitor.py:probe():210] {'os': 'macOS-13.4-arm64-arm-64bit', 'python': '3.9.6', 'heartbeatAt': '2023-07-26T15:55:18.073958', 'startedAt': '2023-07-26T15:55:17.408823', 'docker': None, 'cuda': None, 'args': ('--algo', 'ppo', '--env', 'MiniGrid-MultiRoom-N7-S4-v0', '--model', 'Multiroom', '--save-interval', '10', '--frames', '80000'), 'state': 'running', 'program': '-m scripts.train', 'git': {'remote': 'https://github.com/CorinaCaraconcea/diversity_study.git', 'commit': 'bbd28515d7e4bbc2bcc39a9deff9cc255775ca99'}, 'email': 'cori.caraconcea@gmail.com', 'root': '/Users/corinacaraconcea/Downloads/diversity_study', 'host': 'Corinas-MacBook-Air.local', 'username': 'corinacaraconcea', 'executable': '/Library/Developer/CommandLineTools/usr/bin/python3', 'cpu_count': 8, 'cpu_count_logical': 8, 'disk': {'total': 228.27386474609375, 'used': 8.95040512084961}, 'gpuapple': {'type': 'arm', 'vendor': 'Apple'}, 'memory': {'total': 8.0}}
-2023-07-26 16:55:18,095 INFO    HandlerThread:80902 [system_monitor.py:probe():211] Finished collecting system info
-2023-07-26 16:55:18,095 INFO    HandlerThread:80902 [system_monitor.py:probe():214] Publishing system info
-2023-07-26 16:55:18,095 DEBUG   HandlerThread:80902 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment
-2023-07-26 16:55:18,096 DEBUG   HandlerThread:80902 [system_info.py:_save_pip():67] Saving pip packages done
-2023-07-26 16:55:18,096 DEBUG   HandlerThread:80902 [system_info.py:_save_code():89] Saving code
-2023-07-26 16:55:18,096 WARNING HandlerThread:80902 [system_info.py:_save_code():91] unable to save code -- program entry not found
-2023-07-26 16:55:18,096 DEBUG   HandlerThread:80902 [system_info.py:_save_patches():127] Saving git patches
-2023-07-26 16:55:18,141 DEBUG   HandlerThread:80902 [system_info.py:_save_patches():169] Saving git patches done
-2023-07-26 16:55:18,141 INFO    HandlerThread:80902 [system_monitor.py:probe():216] Finished publishing system info
-2023-07-26 16:55:18,144 DEBUG   SenderThread:80902 [sender.py:send():369] send: files
-2023-07-26 16:55:18,144 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-metadata.json with policy now
-2023-07-26 16:55:18,144 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file diff.patch with policy now
-2023-07-26 16:55:18,148 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:55:18,149 DEBUG   SenderThread:80902 [sender.py:send():369] send: telemetry
-2023-07-26 16:55:18,149 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:55:18,674 INFO    wandb-upload_0:80902 [upload_job.py:push():133] Uploaded file /var/folders/n4/lk2x7f1j3g35spnvp796gmx40000gn/T/tmp5kd234nrwandb/76cq4twi-wandb-metadata.json
-2023-07-26 16:55:18,678 INFO    wandb-upload_1:80902 [upload_job.py:push():133] Uploaded file /var/folders/n4/lk2x7f1j3g35spnvp796gmx40000gn/T/tmp5kd234nrwandb/ssy2i1d5-diff.patch
-2023-07-26 16:55:18,945 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:18,946 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-metadata.json
-2023-07-26 16:55:18,946 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:18,946 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/requirements.txt
-2023-07-26 16:55:18,946 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_created():272] file/dir created: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/diff.patch
-2023-07-26 16:55:19,400 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:19,401 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:19,401 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:19,402 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:19,949 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:20,582 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:20,586 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:20,586 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:20,587 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:20,955 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:20,955 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:21,751 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:21,751 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:21,751 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:21,752 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:21,955 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:22,945 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:22,945 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:22,946 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:22,946 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:55:22,946 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:22,960 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:22,961 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:24,243 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:24,244 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:24,244 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:24,245 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:24,971 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:24,972 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:25,415 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:25,415 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:25,416 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:25,416 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:25,977 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:26,562 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:26,563 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:26,563 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:26,563 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:26,982 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:26,982 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:27,684 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:27,684 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:27,684 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:27,685 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:27,987 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:28,841 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:28,842 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:28,842 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:28,842 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:55:28,842 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:28,989 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:28,989 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:29,984 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:29,985 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:29,985 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:29,985 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:29,992 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:30,998 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:31,152 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:31,153 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:31,153 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:31,153 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:32,003 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:32,323 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:32,323 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:32,324 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:32,324 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:33,008 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:33,009 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:33,150 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:55:33,150 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:55:33,484 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:33,485 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:33,485 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:33,486 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:34,014 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:34,701 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:34,702 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:34,702 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:34,702 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:55:34,702 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:35,019 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:35,019 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:35,866 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:35,867 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:35,867 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:35,867 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:36,024 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:37,021 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:37,022 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:37,022 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:37,022 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:37,026 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:37,026 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:38,174 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:38,174 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:38,174 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:38,175 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:39,037 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:39,037 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:39,330 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:39,331 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:39,331 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:39,332 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:40,042 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:40,479 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:40,480 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:40,480 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:40,480 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:55:40,480 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:41,047 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:41,047 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:41,644 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:41,645 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:41,645 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:41,646 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:42,053 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:42,827 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:42,828 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:42,828 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:42,828 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:43,056 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:43,056 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:43,943 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:43,944 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:43,944 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:43,945 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:44,059 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:45,064 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:45,065 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:45,066 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:45,066 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:45,066 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:46,070 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:46,254 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:46,255 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:46,255 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:46,255 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:55:46,256 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:47,075 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:47,075 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:47,438 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:47,439 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:47,439 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:47,440 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:48,081 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:48,155 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:55:48,155 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:55:48,589 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:48,590 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:48,590 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:48,590 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:49,086 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:49,087 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:49,765 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:49,766 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:49,767 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:49,767 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:50,088 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:51,048 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:51,050 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:51,050 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:51,051 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:51,090 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:51,090 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:51,312 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:55:52,093 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/config.yaml
-2023-07-26 16:55:52,230 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:52,231 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:52,231 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:52,231 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:53,099 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:53,099 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:53,347 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:53,348 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:53,348 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:53,348 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:54,104 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:54,528 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:54,528 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:54,529 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:54,529 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:55,109 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:55,109 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:55,771 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:55,773 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:55,773 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:55,774 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:56,116 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:57,018 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:57,019 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:57,019 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:57,020 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:55:57,020 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:57,120 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:57,120 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:58,143 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:58,144 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:58,144 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:58,145 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:55:59,128 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:55:59,129 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:55:59,447 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:55:59,449 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:55:59,449 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:55:59,449 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:56:00,133 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:56:00,834 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:56:00,836 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:56:00,836 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:56:00,837 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:56:01,137 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:56:01,139 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:56:02,084 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:56:02,085 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:56:02,085 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:56:02,085 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:56:02,085 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:56:02,142 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:56:03,146 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:56:03,160 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: stop_status
-2023-07-26 16:56:03,160 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: stop_status
-2023-07-26 16:56:03,172 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:56:03,360 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:56:03,360 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:56:03,361 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:56:04,151 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:56:04,307 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:56:04,308 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:56:04,308 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:56:04,308 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:56:05,156 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:56:05,156 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:56:05,677 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: partial_history
-2023-07-26 16:56:05,679 DEBUG   SenderThread:80902 [sender.py:send():369] send: history
-2023-07-26 16:56:05,679 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: summary_record
-2023-07-26 16:56:05,679 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:56:05,691 DEBUG   SenderThread:80902 [sender.py:send():369] send: exit
-2023-07-26 16:56:05,691 INFO    SenderThread:80902 [sender.py:send_exit():574] handling exit code: 0
-2023-07-26 16:56:05,693 INFO    SenderThread:80902 [sender.py:send_exit():576] handling runtime: 47
-2023-07-26 16:56:05,694 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:56:05,694 INFO    SenderThread:80902 [sender.py:send_exit():582] send defer
-2023-07-26 16:56:05,694 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:05,694 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 0
-2023-07-26 16:56:05,694 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:05,694 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 0
-2023-07-26 16:56:05,694 INFO    SenderThread:80902 [sender.py:transition_state():602] send defer: 1
-2023-07-26 16:56:05,694 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:05,694 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 1
-2023-07-26 16:56:05,694 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:05,694 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 1
-2023-07-26 16:56:05,694 INFO    SenderThread:80902 [sender.py:transition_state():602] send defer: 2
-2023-07-26 16:56:05,695 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:05,695 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 2
-2023-07-26 16:56:05,695 INFO    HandlerThread:80902 [system_monitor.py:finish():190] Stopping system monitor
-2023-07-26 16:56:05,695 DEBUG   SystemMonitor:80902 [system_monitor.py:_start():159] Starting system metrics aggregation loop
-2023-07-26 16:56:05,695 INFO    HandlerThread:80902 [interfaces.py:finish():202] Joined cpu monitor
-2023-07-26 16:56:05,695 DEBUG   SystemMonitor:80902 [system_monitor.py:_start():166] Finished system metrics aggregation loop
-2023-07-26 16:56:05,695 INFO    HandlerThread:80902 [interfaces.py:finish():202] Joined disk monitor
-2023-07-26 16:56:05,695 DEBUG   SystemMonitor:80902 [system_monitor.py:_start():170] Publishing last batch of metrics
-2023-07-26 16:56:05,695 INFO    HandlerThread:80902 [interfaces.py:finish():202] Joined gpuapple monitor
-2023-07-26 16:56:05,697 INFO    HandlerThread:80902 [interfaces.py:finish():202] Joined memory monitor
-2023-07-26 16:56:05,697 INFO    HandlerThread:80902 [interfaces.py:finish():202] Joined network monitor
-2023-07-26 16:56:05,698 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:05,698 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 2
-2023-07-26 16:56:05,698 INFO    SenderThread:80902 [sender.py:transition_state():602] send defer: 3
-2023-07-26 16:56:05,698 DEBUG   SenderThread:80902 [sender.py:send():369] send: telemetry
-2023-07-26 16:56:05,698 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:05,698 DEBUG   SenderThread:80902 [sender.py:send():369] send: stats
-2023-07-26 16:56:05,698 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 3
-2023-07-26 16:56:05,698 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:05,698 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 3
-2023-07-26 16:56:05,698 INFO    SenderThread:80902 [sender.py:transition_state():602] send defer: 4
-2023-07-26 16:56:05,698 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:05,698 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 4
-2023-07-26 16:56:05,698 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:05,698 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 4
-2023-07-26 16:56:05,698 INFO    SenderThread:80902 [sender.py:transition_state():602] send defer: 5
-2023-07-26 16:56:05,698 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:05,698 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 5
-2023-07-26 16:56:05,699 DEBUG   SenderThread:80902 [sender.py:send():369] send: summary
-2023-07-26 16:56:05,699 INFO    SenderThread:80902 [sender.py:_save_file():1354] saving file wandb-summary.json with policy end
-2023-07-26 16:56:05,699 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:05,699 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 5
-2023-07-26 16:56:05,699 INFO    SenderThread:80902 [sender.py:transition_state():602] send defer: 6
-2023-07-26 16:56:05,699 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:05,699 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 6
-2023-07-26 16:56:05,699 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:05,699 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 6
-2023-07-26 16:56:05,701 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: status_report
-2023-07-26 16:56:05,901 INFO    SenderThread:80902 [sender.py:transition_state():602] send defer: 7
-2023-07-26 16:56:05,901 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:05,901 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 7
-2023-07-26 16:56:05,902 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:05,902 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 7
-2023-07-26 16:56:06,158 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:56:06,159 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/config.yaml
-2023-07-26 16:56:06,600 INFO    SenderThread:80902 [sender.py:transition_state():602] send defer: 8
-2023-07-26 16:56:06,602 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:06,603 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 8
-2023-07-26 16:56:06,603 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:06,603 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 8
-2023-07-26 16:56:06,604 INFO    SenderThread:80902 [job_builder.py:build():240] Attempting to build job artifact
-2023-07-26 16:56:06,605 INFO    SenderThread:80902 [job_builder.py:build():274] no source found
-2023-07-26 16:56:06,605 INFO    SenderThread:80902 [sender.py:transition_state():602] send defer: 9
-2023-07-26 16:56:06,605 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:06,605 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 9
-2023-07-26 16:56:06,606 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:06,606 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 9
-2023-07-26 16:56:06,606 INFO    SenderThread:80902 [dir_watcher.py:finish():359] shutting down directory watcher
-2023-07-26 16:56:06,697 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: poll_exit
-2023-07-26 16:56:07,165 INFO    Thread-12 :80902 [dir_watcher.py:_on_file_modified():289] file/dir modified: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:56:07,168 INFO    SenderThread:80902 [dir_watcher.py:finish():389] scan: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files
-2023-07-26 16:56:07,169 INFO    SenderThread:80902 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/diff.patch diff.patch
-2023-07-26 16:56:07,170 INFO    SenderThread:80902 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/requirements.txt requirements.txt
-2023-07-26 16:56:07,171 INFO    SenderThread:80902 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log output.log
-2023-07-26 16:56:07,176 INFO    SenderThread:80902 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/config.yaml config.yaml
-2023-07-26 16:56:07,180 INFO    SenderThread:80902 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json wandb-summary.json
-2023-07-26 16:56:07,184 INFO    SenderThread:80902 [dir_watcher.py:finish():403] scan save: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-metadata.json wandb-metadata.json
-2023-07-26 16:56:07,184 INFO    SenderThread:80902 [sender.py:transition_state():602] send defer: 10
-2023-07-26 16:56:07,186 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: poll_exit
-2023-07-26 16:56:07,187 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:07,194 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 10
-2023-07-26 16:56:07,195 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:07,195 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 10
-2023-07-26 16:56:07,196 INFO    SenderThread:80902 [file_pusher.py:finish():159] shutting down file pusher
-2023-07-26 16:56:07,604 INFO    wandb-upload_2:80902 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/config.yaml
-2023-07-26 16:56:07,604 INFO    wandb-upload_1:80902 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/output.log
-2023-07-26 16:56:07,674 INFO    wandb-upload_0:80902 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/requirements.txt
-2023-07-26 16:56:07,706 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: poll_exit
-2023-07-26 16:56:07,707 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: poll_exit
-2023-07-26 16:56:07,780 INFO    wandb-upload_3:80902 [upload_job.py:push():133] Uploaded file /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/files/wandb-summary.json
-2023-07-26 16:56:07,985 INFO    Thread-11 :80902 [sender.py:transition_state():602] send defer: 11
-2023-07-26 16:56:07,986 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:07,987 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 11
-2023-07-26 16:56:07,988 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:07,988 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 11
-2023-07-26 16:56:07,988 INFO    SenderThread:80902 [file_pusher.py:join():164] waiting for file pusher
-2023-07-26 16:56:07,988 INFO    SenderThread:80902 [sender.py:transition_state():602] send defer: 12
-2023-07-26 16:56:07,988 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:07,988 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 12
-2023-07-26 16:56:07,989 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:07,989 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 12
-2023-07-26 16:56:08,159 INFO    SenderThread:80902 [sender.py:transition_state():602] send defer: 13
-2023-07-26 16:56:08,160 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:08,160 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 13
-2023-07-26 16:56:08,161 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:08,161 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 13
-2023-07-26 16:56:08,163 INFO    SenderThread:80902 [sender.py:transition_state():602] send defer: 14
-2023-07-26 16:56:08,164 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: defer
-2023-07-26 16:56:08,165 DEBUG   SenderThread:80902 [sender.py:send():369] send: final
-2023-07-26 16:56:08,165 INFO    HandlerThread:80902 [handler.py:handle_request_defer():170] handle defer: 14
-2023-07-26 16:56:08,165 DEBUG   SenderThread:80902 [sender.py:send():369] send: footer
-2023-07-26 16:56:08,165 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: defer
-2023-07-26 16:56:08,165 INFO    SenderThread:80902 [sender.py:send_request_defer():598] handle sender defer: 14
-2023-07-26 16:56:08,170 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: poll_exit
-2023-07-26 16:56:08,171 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: poll_exit
-2023-07-26 16:56:08,171 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: server_info
-2023-07-26 16:56:08,171 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: get_summary
-2023-07-26 16:56:08,171 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: sampled_history
-2023-07-26 16:56:08,174 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: poll_exit
-2023-07-26 16:56:08,174 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: poll_exit
-2023-07-26 16:56:08,175 DEBUG   SenderThread:80902 [sender.py:send_request():396] send_request: server_info
-2023-07-26 16:56:08,452 INFO    MainThread:80902 [wandb_run.py:_footer_history_summary_info():3464] rendering history
-2023-07-26 16:56:08,453 INFO    MainThread:80902 [wandb_run.py:_footer_history_summary_info():3496] rendering summary
-2023-07-26 16:56:08,454 INFO    MainThread:80902 [wandb_run.py:_footer_sync_info():3423] logging synced files
-2023-07-26 16:56:08,456 DEBUG   HandlerThread:80902 [handler.py:handle_request():144] handle_request: shutdown
-2023-07-26 16:56:08,456 INFO    HandlerThread:80902 [handler.py:finish():854] shutting down handler
-2023-07-26 16:56:09,174 INFO    WriterThread:80902 [datastore.py:close():298] close: /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/run-22z3wkhd.wandb
-2023-07-26 16:56:09,452 INFO    SenderThread:80902 [sender.py:finish():1526] shutting down sender
-2023-07-26 16:56:09,452 INFO    SenderThread:80902 [file_pusher.py:finish():159] shutting down file pusher
-2023-07-26 16:56:09,452 INFO    SenderThread:80902 [file_pusher.py:join():164] waiting for file pusher
diff --git a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/logs/debug.log b/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/logs/debug.log
deleted file mode 100644
index 616b074..0000000
--- a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/logs/debug.log
+++ /dev/null
@@ -1,29 +0,0 @@
-2023-07-26 16:55:17,411 INFO    MainThread:80873 [wandb_setup.py:_flush():76] Current SDK version is 0.15.5
-2023-07-26 16:55:17,411 INFO    MainThread:80873 [wandb_setup.py:_flush():76] Configure stats pid to 80873
-2023-07-26 16:55:17,411 INFO    MainThread:80873 [wandb_setup.py:_flush():76] Loading settings from /Users/corinacaraconcea/.config/wandb/settings
-2023-07-26 16:55:17,411 INFO    MainThread:80873 [wandb_setup.py:_flush():76] Loading settings from /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/settings
-2023-07-26 16:55:17,411 INFO    MainThread:80873 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
-2023-07-26 16:55:17,411 INFO    MainThread:80873 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
-2023-07-26 16:55:17,411 WARNING MainThread:80873 [wandb_setup.py:_flush():76] Could not find program at -m scripts.train
-2023-07-26 16:55:17,411 INFO    MainThread:80873 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': None, 'program': '-m scripts.train'}
-2023-07-26 16:55:17,411 INFO    MainThread:80873 [wandb_init.py:_log_setup():507] Logging user logs to /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/logs/debug.log
-2023-07-26 16:55:17,411 INFO    MainThread:80873 [wandb_init.py:_log_setup():508] Logging internal logs to /Users/corinacaraconcea/Downloads/diversity_study/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/logs/debug-internal.log
-2023-07-26 16:55:17,412 INFO    MainThread:80873 [wandb_init.py:init():547] calling init triggers
-2023-07-26 16:55:17,412 INFO    MainThread:80873 [wandb_init.py:init():554] wandb.init called with sweep_config: {}
-config: {'model': '', 'performance metric': 'extrinsic reward'}
-2023-07-26 16:55:17,412 INFO    MainThread:80873 [wandb_init.py:init():596] starting backend
-2023-07-26 16:55:17,412 INFO    MainThread:80873 [wandb_init.py:init():600] setting up manager
-2023-07-26 16:55:17,418 INFO    MainThread:80873 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
-2023-07-26 16:55:17,421 INFO    MainThread:80873 [wandb_init.py:init():606] backend started and connected
-2023-07-26 16:55:17,427 INFO    MainThread:80873 [wandb_init.py:init():705] updated telemetry
-2023-07-26 16:55:17,447 INFO    MainThread:80873 [wandb_init.py:init():738] communicating run to backend with 60.0 second timeout
-2023-07-26 16:55:17,942 INFO    MainThread:80873 [wandb_run.py:_on_init():2173] communicating current version
-2023-07-26 16:55:18,058 INFO    MainThread:80873 [wandb_run.py:_on_init():2182] got version response upgrade_message: "wandb version 0.15.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
-
-2023-07-26 16:55:18,058 INFO    MainThread:80873 [wandb_init.py:init():789] starting run threads in backend
-2023-07-26 16:55:18,146 INFO    MainThread:80873 [wandb_run.py:_console_start():2152] atexit reg
-2023-07-26 16:55:18,147 INFO    MainThread:80873 [wandb_run.py:_redirect():2007] redirect: SettingsConsole.WRAP_RAW
-2023-07-26 16:55:18,147 INFO    MainThread:80873 [wandb_run.py:_redirect():2072] Wrapping output streams.
-2023-07-26 16:55:18,147 INFO    MainThread:80873 [wandb_run.py:_redirect():2097] Redirects installed.
-2023-07-26 16:55:18,147 INFO    MainThread:80873 [wandb_init.py:init():830] run started, returning control to user process
-2023-07-26 16:56:09,647 WARNING MsgRouterThr:80873 [router.py:message_loop():77] message_loop has been closed
diff --git a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/run-22z3wkhd.wandb b/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/run-22z3wkhd.wandb
deleted file mode 100644
index 86a8100..0000000
Binary files a/rl-starter-files/wandb/run-20230726_165517-22z3wkhd/run-22z3wkhd.wandb and /dev/null differ
diff --git a/torch_ac_v2/torch_ac_v2/__init__.py b/torch_ac_v2/torch_ac_v2/__init__.py
index 71e5c0c..3140085 100644
--- a/torch_ac_v2/torch_ac_v2/__init__.py
+++ b/torch_ac_v2/torch_ac_v2/__init__.py
@@ -1,4 +1,4 @@
-from torch_ac_v2.algos import A2CAlgo, PPOAlgo
-from torch_ac_v2.model import ACModel, RecurrentACModel
-from torch_ac_v2.utils import DictList
-from .format import default_preprocess_obss
\ No newline at end of file
+# from torch_ac_v2.torch_ac_v2.algos import A2CAlgo, PPOAlgo
+# from torch_ac_v2.torch_ac_v2.model import ACModel, RecurrentACModel
+# from torch_ac_v2.torch_ac_v2.utils import DictList
+# from torch_ac_v2.torch_ac_v2.format import default_preprocess_obss
\ No newline at end of file
diff --git a/torch_ac_v2/torch_ac_v2/algos/__init__.py b/torch_ac_v2/torch_ac_v2/algos/__init__.py
index e7e93ab..99fd1ea 100644
--- a/torch_ac_v2/torch_ac_v2/algos/__init__.py
+++ b/torch_ac_v2/torch_ac_v2/algos/__init__.py
@@ -1,3 +1,4 @@
-from torch_ac_v2.algos.a2c import A2CAlgo
-from torch_ac_v2.algos.ppo import PPOAlgo
-from torch_ac_v2.algos.base2 import BaseAlgo
\ No newline at end of file
+# from torch_ac_v2.torch_ac_v2.algos.a2c import A2CAlgo
+from torch_ac_v2.torch_ac_v2.algos.ppo import PPOAlgo
+from torch_ac_v2.torch_ac_v2.algos.base2 import BaseAlgo
+from torch_ac_v2.torch_ac_v2.format import *
\ No newline at end of file
diff --git a/torch_ac_v2/torch_ac_v2/algos/base2.py b/torch_ac_v2/torch_ac_v2/algos/base2.py
index 2cb8e03..7230487 100644
--- a/torch_ac_v2/torch_ac_v2/algos/base2.py
+++ b/torch_ac_v2/torch_ac_v2/algos/base2.py
@@ -6,16 +6,13 @@ import math
 import numpy as np
 import torch.nn.functional as F
 
-sys.path.insert(0, '/cluster/project7/diversity_rl/diversity_study/torch_ac_v2/torch_ac_v2')
 
-import format
-from format import default_preprocess_obss
+from torch_ac_v2.torch_ac_v2.format import default_preprocess_obss
 
-sys.path.insert(0, '/cluster/project7/diversity_rl/diversity_study/torch_ac_v2/torch_ac_v2/utils')
 
-from dictlist import DictList
-from penv import ParallelEnv
-from count_module import CountModule,TrajectoryCountModule, DIAYN_reward, DIAYN_discriminator, RNDModel, WindowTrajectory,RNDTrajectoryModel
+from torch_ac_v2.torch_ac_v2.utils.dictlist import DictList
+from torch_ac_v2.torch_ac_v2.utils.penv import ParallelEnv
+from torch_ac_v2.torch_ac_v2.utils.count_module import CountModule,TrajectoryCountModule, DIAYN_reward, DIAYN_discriminator, RNDModel, WindowTrajectory,RNDTrajectoryModel
 
 class BaseAlgo(ABC):
     """The base class for RL algorithms."""
diff --git a/torch_ac_v2/torch_ac_v2/algos/ppo.py b/torch_ac_v2/torch_ac_v2/algos/ppo.py
index 0b0d667..e25dce1 100644
--- a/torch_ac_v2/torch_ac_v2/algos/ppo.py
+++ b/torch_ac_v2/torch_ac_v2/algos/ppo.py
@@ -3,10 +3,10 @@ import torch
 import torch.nn.functional as F
 from torch import optim, nn
 
-from base2 import BaseAlgo
+from .base2 import BaseAlgo
 
-from clip_grads import global_grad_norm_
-from count_module import CountModule,TrajectoryCountModule, DIAYN_reward, DIAYN_discriminator
+from torch_ac_v2.torch_ac_v2.utils.clip_grads import global_grad_norm_
+from torch_ac_v2.torch_ac_v2.utils.count_module import CountModule,TrajectoryCountModule, DIAYN_reward, DIAYN_discriminator
 
 class PPOAlgo(BaseAlgo):
     """The Proximal Policy Optimization algorithm
diff --git a/torch_ac_v2/torch_ac_v2/utils/__init__.py b/torch_ac_v2/torch_ac_v2/utils/__init__.py
index f35fefc..21855ba 100644
--- a/torch_ac_v2/torch_ac_v2/utils/__init__.py
+++ b/torch_ac_v2/torch_ac_v2/utils/__init__.py
@@ -1,3 +1,3 @@
-from torch_ac_v2.utils.dictlist import DictList
-from torch_ac_v2.utils.penv import ParallelEnv
-from torch_ac_v2.utils.count_module import *
\ No newline at end of file
+# from torch_ac_v2.utils.dictlist import DictList
+# from torch_ac_v2.utils.penv import ParallelEnv
+# from torch_ac_v2.utils.count_module import *
\ No newline at end of file
